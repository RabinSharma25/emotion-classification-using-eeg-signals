{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RabinSharma25/emotion-classification-using-eeg-signals/blob/main/rabin2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pwwbhMy0pssx"
      },
      "outputs": [],
      "source": [
        "#import the required libraries\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "#for feature extraction\n",
        "from scipy.signal import welch\n",
        "from scipy.integrate import simps\n",
        "\n",
        "#classifier libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7ZUAXilSp_n9"
      },
      "outputs": [],
      "source": [
        "def read_data(filename):\n",
        "    x = pickle._Unpickler(open(filename, 'rb'))\n",
        "    x.encoding = 'latin1'\n",
        "    p = x.load()\n",
        "    return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYK5hgFMqFNy",
        "outputId": "dc342c26-6cba-451c-983e-b11e7ed8016c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['s01.dat', 's02.dat', 's03.dat', 's04.dat', 's05.dat', 's06.dat', 's07.dat', 's08.dat', 's09.dat', 's10.dat', 's11.dat', 's12.dat', 's13.dat', 's14.dat', 's15.dat', 's16.dat', 's17.dat', 's18.dat', 's19.dat', 's20.dat', 's21.dat', 's22.dat', 's23.dat', 's24.dat', 's25.dat', 's26.dat', 's27.dat', 's28.dat', 's29.dat', 's30.dat', 's31.dat', 's32.dat']\n"
          ]
        }
      ],
      "source": [
        "#creating the file names of the dataset to load it\n",
        "files = []\n",
        "for n in range (1, 33):\n",
        "    s = 's'\n",
        "    if n < 10:\n",
        "        s += '0'\n",
        "    s += str(n)\n",
        "    s+=str(\".dat\")\n",
        "    files.append(s)\n",
        "print(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ru2cxT3qrtI",
        "outputId": "b48bd5ae-aabd-4385-9cf5-b0d4e4469b82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 32x40 = 1280 trials for 32 participants\n",
        "labels = []\n",
        "data = []\n",
        "drive.mount('/content/drive')\n",
        "for i in files:\n",
        "  filename = \"/content/drive/My Drive/major-project/major-project-dataset/\" + i\n",
        "  trial = read_data(filename)\n",
        "  labels.append(trial['labels'])\n",
        "  data.append(trial['data'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwIUirXzuY_3",
        "outputId": "55e752f7-6a29-4351-db46-f33f492f1bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels:  (32, 40, 4)\n",
            "Data:  (32, 40, 40, 8064)\n"
          ]
        }
      ],
      "source": [
        "# Lets see the shapes of the raw data\n",
        "labels = np.array(labels)\n",
        "data = np.array(data)\n",
        "print(\"Labels: \", labels.shape) # participants x videos x labels\n",
        "print(\"Data: \", data.shape) # participants x videos x channels x data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6JhtYReeudzh"
      },
      "outputs": [],
      "source": [
        "# Re-shape arrays into desired shapes\n",
        "labels = labels.flatten()\n",
        "labels = labels.reshape(1280, 4)\n",
        "\n",
        "data = data.flatten()\n",
        "data = data.reshape(1280, 40, 8064)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw4kk4WasX14",
        "outputId": "348eeda6-87de-4e3d-ce4e-6af623088500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels:  (1280, 4)\n",
            "Data:  (1280, 40, 8064)\n"
          ]
        }
      ],
      "source": [
        "# Double-check the new arrays\n",
        "#Here trial = participants x vidoes = 32 x 40 = 1280\n",
        "\n",
        "print(\"Labels: \", labels.shape) # trial x label\n",
        "print(\"Data: \", data.shape) # trial x channel x data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "puNQxQcOx0Gq",
        "outputId": "713eb840-8b38-4eb2-a6f9-d5785a195ed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "printing the labels dataframe\n",
            "\n",
            "         0     1     2     3\n",
            "0     7.71  7.60  6.90  7.83\n",
            "1     8.10  7.31  7.28  8.47\n",
            "2     8.58  7.54  9.00  7.08\n",
            "3     4.94  6.01  6.12  8.06\n",
            "4     6.96  3.92  7.19  6.05\n",
            "...    ...   ...   ...   ...\n",
            "1275  3.91  6.96  5.82  3.12\n",
            "1276  2.81  6.13  6.06  1.04\n",
            "1277  3.05  7.01  5.10  1.10\n",
            "1278  3.99  7.17  4.85  1.00\n",
            "1279  7.15  4.03  9.00  1.88\n",
            "\n",
            "[1280 rows x 4 columns]\n",
            "\n",
            "\n",
            "Describing the labels dataframe\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0            1            2            3\n",
              "count  1280.000000  1280.000000  1280.000000  1280.000000\n",
              "mean      5.254313     5.156711     5.382750     5.518133\n",
              "std       2.130816     2.020499     2.096321     2.282780\n",
              "min       1.000000     1.000000     1.000000     1.000000\n",
              "25%       3.867500     3.762500     3.932500     3.960000\n",
              "50%       5.040000     5.230000     5.240000     6.050000\n",
              "75%       7.050000     6.950000     7.040000     7.090000\n",
              "max       9.000000     9.000000     9.000000     9.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40706021-c19d-4a72-b07d-aeba5d192410\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1280.000000</td>\n",
              "      <td>1280.000000</td>\n",
              "      <td>1280.000000</td>\n",
              "      <td>1280.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.254313</td>\n",
              "      <td>5.156711</td>\n",
              "      <td>5.382750</td>\n",
              "      <td>5.518133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.130816</td>\n",
              "      <td>2.020499</td>\n",
              "      <td>2.096321</td>\n",
              "      <td>2.282780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.867500</td>\n",
              "      <td>3.762500</td>\n",
              "      <td>3.932500</td>\n",
              "      <td>3.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.040000</td>\n",
              "      <td>5.230000</td>\n",
              "      <td>5.240000</td>\n",
              "      <td>6.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.050000</td>\n",
              "      <td>6.950000</td>\n",
              "      <td>7.040000</td>\n",
              "      <td>7.090000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40706021-c19d-4a72-b07d-aeba5d192410')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-40706021-c19d-4a72-b07d-aeba5d192410 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-40706021-c19d-4a72-b07d-aeba5d192410');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c28e60bf-7c5d-4297-9584-55e5d3d687d5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c28e60bf-7c5d-4297-9584-55e5d3d687d5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c28e60bf-7c5d-4297-9584-55e5d3d687d5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"labelsDf\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.87147400594165,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.2543125,\n          5.04,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.88279505775586,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.1567109375,\n          5.23,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.85389766830843,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.38275,\n          5.24,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.79289858765816,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.5181328125,\n          6.05,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#creating the dataframes for the labels\n",
        "labelsDf = pd.DataFrame(labels)\n",
        "print(\"printing the labels dataframe\\n\")\n",
        "print(labelsDf)\n",
        "print(\"\\n\\nDescribing the labels dataframe\")\n",
        "labelsDf.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SGS2ghM3uYC",
        "outputId": "cf470210-1d81-4072-c912-863c4011e27a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 0            1            2            3\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000\n",
            "mean      5.254313     5.156711     5.382750     5.518133\n",
            "std       2.130816     2.020499     2.096321     2.282780\n",
            "min       1.000000     1.000000     1.000000     1.000000\n",
            "25%       3.867500     3.762500     3.932500     3.960000\n",
            "50%       5.040000     5.230000     5.240000     6.050000\n",
            "75%       7.050000     6.950000     7.040000     7.090000\n",
            "max       9.000000     9.000000     9.000000     9.000000\n"
          ]
        }
      ],
      "source": [
        "#giving names to the label columns\n",
        "df_labels= pd.DataFrame({'valence': labels[:,0], 'arousal': labels[:,1], 'dominance': labels[:,2], 'liking': labels[:,3]})\n",
        "print(labelsDf.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3boVQ1FE4var",
        "outputId": "06b07f18-eda8-4fe4-ecfc-ee412f6f1b07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      valence  arousal\n",
            "0        7.71     7.60\n",
            "1        8.10     7.31\n",
            "2        8.58     7.54\n",
            "3        4.94     6.01\n",
            "4        6.96     3.92\n",
            "...       ...      ...\n",
            "1275     3.91     6.96\n",
            "1276     2.81     6.13\n",
            "1277     3.05     7.01\n",
            "1278     3.99     7.17\n",
            "1279     7.15     4.03\n",
            "\n",
            "[1280 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "#Dropping the Dominance and Liking columns\n",
        "df_labels=df_labels.drop('dominance',axis=1)\n",
        "df_labels=df_labels.drop('liking',axis=1)\n",
        "# print(df_labels.describe())\n",
        "print(df_labels)\n",
        "# df = df.drop('B', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pet3Pska6SDA"
      },
      "source": [
        "# Separte Valence and Arousal to HAHV, LAHV, HALV, LALV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhIWzOBq6QSq",
        "outputId": "6be4f1e3-9a2e-4309-ee37-7fc8a5e5b32b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.23\n",
            "5.04\n",
            "      HAHV  LAHV  HALV  LALV\n",
            "0        1     0     0     0\n",
            "1        1     0     0     0\n",
            "2        1     0     0     0\n",
            "3        0     0     1     0\n",
            "4        0     1     0     0\n",
            "...    ...   ...   ...   ...\n",
            "1275     0     0     1     0\n",
            "1276     0     0     1     0\n",
            "1277     0     0     1     0\n",
            "1278     0     0     1     0\n",
            "1279     0     1     0     0\n",
            "\n",
            "[1280 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# # Create a sample DataFrame with 'valence' and 'arousal' columns\n",
        "# np.random.seed(0)\n",
        "# valence = np.random.uniform(1, 9, 1280)\n",
        "# arousal = np.random.uniform(1, 9, 1280)\n",
        "# data = {'valence': valence, 'arousal': arousal}\n",
        "# df_valence_arousal = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the median value of arousal and valence column\n",
        "arousal_median = df_labels['arousal'].median()\n",
        "print(arousal_median)\n",
        "valence_median = df_labels['valence'].median()\n",
        "print(valence_median)\n",
        "\n",
        "# Create a new DataFrame with the desired columns\n",
        "df_result = pd.DataFrame(index=range(1280), columns=['HAHV', 'LAHV', 'HALV', 'LALV'])\n",
        "df_result[['HAHV', 'LAHV', 'HALV', 'LALV']] = 0\n",
        "\n",
        "# Apply the conditions\n",
        "df_result.loc[(df_labels['valence'] >= valence_median) & (df_labels['arousal'] >= arousal_median), 'HAHV'] = 1\n",
        "df_result.loc[(df_labels['arousal'] < arousal_median) & (df_labels['valence'] >= valence_median), 'LAHV'] = 1\n",
        "df_result.loc[(df_labels['arousal'] >= arousal_median) & (df_labels['valence'] < valence_median), 'HALV'] = 1\n",
        "df_result.loc[(df_labels['valence'] < valence_median) & (df_labels['arousal'] < arousal_median), 'LALV'] = 1\n",
        "\n",
        "# Show the first few rows of the result DataFrame\n",
        "# df_result.tail()\n",
        "print(df_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcYaudZZDylG"
      },
      "source": [
        "Verify the data in 4 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tc9aAzbD7U3",
        "outputId": "bf72d3f4-ff80-4de9-f3c1-bd3788f2a502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of 1s in HAHV: 358\n",
            "Number of 1s in LAHV: 322\n",
            "Number of 1s in HALV: 282\n",
            "Number of 1s in LALV: 318\n",
            "Total = 1280\n"
          ]
        }
      ],
      "source": [
        "# Check the number of 1s in each individual column\n",
        "count_HAHV = df_result['HAHV'].sum()\n",
        "count_LAHV = df_result['LAHV'].sum()\n",
        "count_HALV = df_result['HALV'].sum()\n",
        "count_LALV = df_result['LALV'].sum()\n",
        "\n",
        "print(f\"Number of 1s in HAHV: {count_HAHV}\")\n",
        "print(f\"Number of 1s in LAHV: {count_LAHV}\")\n",
        "print(f\"Number of 1s in HALV: {count_HALV}\")\n",
        "print(f\"Number of 1s in LALV: {count_LALV}\")\n",
        "\n",
        "print(f\"Total = {count_HAHV+count_LAHV+count_HALV+count_LALV}\") # the total must be 1280\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Pjhzu_pQlWDv"
      },
      "outputs": [],
      "source": [
        "# Dataset with only Valence column\n",
        "df_val = df_labels['valence']\n",
        "# Dataset with only Arousal column\n",
        "df_aro = df_labels['arousal']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "u8H4KOWLll-C"
      },
      "outputs": [],
      "source": [
        "# Function to check if each trial has positive or negative valence\n",
        "def positive_valence(trial):\n",
        "    return 1 if labels[trial,0] >= np.median(labels[:,0]) else 0\n",
        "# Function to check if each trial has high or low arousal\n",
        "def high_arousal(trial):\n",
        "    return 1 if labels[trial,1] >= np.median(labels[:,1]) else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37Gsz-Z_lp_2",
        "outputId": "e441dc4e-2c67-40af-e736-130793105c80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       High Valence  High Arousal\n",
            "count   1280.000000   1280.000000\n",
            "mean       0.531250      0.500000\n",
            "std        0.499218      0.500195\n",
            "min        0.000000      0.000000\n",
            "25%        0.000000      0.000000\n",
            "50%        1.000000      0.500000\n",
            "75%        1.000000      1.000000\n",
            "max        1.000000      1.000000\n",
            "      High Valence  High Arousal\n",
            "0                1             1\n",
            "1                1             1\n",
            "2                1             1\n",
            "3                0             1\n",
            "4                1             0\n",
            "...            ...           ...\n",
            "1275             0             1\n",
            "1276             0             1\n",
            "1277             0             1\n",
            "1278             0             1\n",
            "1279             1             0\n",
            "\n",
            "[1280 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Convert all ratings to boolean values\n",
        "labels_encoded = []\n",
        "for i in range (len(labels)):\n",
        "    labels_encoded.append([positive_valence(i), high_arousal(i)])\n",
        "labels_encoded = np.reshape(labels_encoded, (1280, 2))\n",
        "df_labels = pd.DataFrame(data=labels_encoded, columns=[\"High Valence\", \"High Arousal\"])\n",
        "print(df_labels.describe())\n",
        "print(df_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BrMAjqult5R",
        "outputId": "7024bea8-82c2-4f21-82e4-958d0042dd58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       0\n",
            "4       1\n",
            "       ..\n",
            "1275    0\n",
            "1276    0\n",
            "1277    0\n",
            "1278    0\n",
            "1279    1\n",
            "Name: High Valence, Length: 1280, dtype: int64\n",
            "(1280,)\n"
          ]
        }
      ],
      "source": [
        "# Dataset with only Valence column\n",
        "df_valence = df_labels['High Valence']\n",
        "# Dataset with only Arousal column\n",
        "df_arousal = df_labels['High Arousal']\n",
        "print(df_valence)\n",
        "print(df_valence.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh0IevZcnKtX"
      },
      "source": [
        "# FEATURE EXTRACTION USING WELCH'S METHOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QGtC7nRipvA8"
      },
      "outputs": [],
      "source": [
        "eeg_channels = np.array([\"Fp1\", \"AF3\", \"F3\", \"F7\", \"FC5\", \"FC1\", \"C3\", \"T7\", \"CP5\", \"CP1\", \"P3\", \"P7\", \"PO3\", \"O1\", \"Oz\", \"Pz\", \"Fp2\", \"AF4\", \"Fz\", \"F4\", \"F8\", \"FC6\", \"FC2\", \"Cz\", \"C4\", \"T8\", \"CP6\", \"CP2\", \"P4\", \"P8\", \"PO4\", \"O2\"])\n",
        "peripheral_channels = np.array([\"hEOG\", \"vEOG\", \"zEMG\", \"tEMG\", \"GSR\", \"Respiration belt\", \"Plethysmograph\", \"Temperature\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyC_7IWLp93t",
        "outputId": "23c5caf9-5538-49f5-9a8e-6d28a90351a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1280, 32, 8064)\n"
          ]
        }
      ],
      "source": [
        "eeg_data = []\n",
        "for i in range (len(data)):\n",
        "  for j in range (len(eeg_channels)):\n",
        "    eeg_data.append(data[i,j])\n",
        "eeg_data = np.reshape(eeg_data, (len(data), len(eeg_channels), len(data[0,0])))\n",
        "print(eeg_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5P3G0PWqEsM",
        "outputId": "d563b058-1678-4b46-cb08-72a1ae83c24e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1280, 8, 8064)\n"
          ]
        }
      ],
      "source": [
        "peripheral_data = []\n",
        "for i in range (len(data)):\n",
        "  for j in range (32,len(data[0])):\n",
        "    peripheral_data.append(data[i,j])\n",
        "peripheral_data = np.reshape(peripheral_data, (len(data), len(peripheral_channels), len(data[0,0])))\n",
        "print(peripheral_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Xc9rTRGHnYKt"
      },
      "outputs": [],
      "source": [
        "def bandpower(data, sf, band, window_sec=None, relative=False):\n",
        "    band = np.asarray(band)\n",
        "    low, high = band\n",
        "\n",
        "    # Define window length\n",
        "    if window_sec is not None:\n",
        "        nperseg = window_sec * sf\n",
        "    else:\n",
        "        nperseg = (2 / low) * sf\n",
        "\n",
        "    # Compute the modified periodogram (Welch)\n",
        "    freqs, psd = welch(data, sf, nperseg=nperseg)\n",
        "\n",
        "    # Frequency resolution\n",
        "    freq_res = freqs[1] - freqs[0]\n",
        "\n",
        "    # Find closest indices of band in frequency vector\n",
        "    idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
        "\n",
        "    # Integral approximation of the spectrum using Simpson's rule.\n",
        "    bp = simps(psd[idx_band], dx=freq_res)\n",
        "\n",
        "    if relative:\n",
        "        bp /= simps(psd, dx=freq_res)\n",
        "    return bp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mIxttAuQnrel"
      },
      "outputs": [],
      "source": [
        "def get_band_power(trial, channel, band):\n",
        "  bd = (0,0)\n",
        "\n",
        "  if (band == \"theta\"): # drownsiness, emotional connection, intuition, creativity\n",
        "    bd = (4,8)\n",
        "  elif (band == \"alpha\"): # reflection, relaxation\n",
        "    bd = (8,12)\n",
        "  elif (band == \"beta\"): # concentration, problem solving, memory\n",
        "    bd = (12,30)\n",
        "  elif (band == \"gamma\"): # cognition, perception, learning, multi-tasking\n",
        "    bd = (30,64)\n",
        "\n",
        "  return bandpower(eeg_data[trial,channel], 128, bd)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpNyS4s8n9Q3",
        "outputId": "9eccf45f-e01c-4f7d-b8a3-ed947ba28188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.434119660168186\n",
            "5.369595513295193\n",
            "6.286556266834863\n",
            "0.9879159580139809\n"
          ]
        }
      ],
      "source": [
        "print(get_band_power(0,31,\"theta\"))\n",
        "print(get_band_power(0,31,\"alpha\"))\n",
        "print(get_band_power(0,31,\"beta\"))\n",
        "print(get_band_power(0,31,\"gamma\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8psQHMB9xqpj"
      },
      "source": [
        "# Process new datasets with 6 EEG regions and 4 band power values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "r0y_hNHIxoxi"
      },
      "outputs": [],
      "source": [
        "# Transform 1280x 32 x 8064 => 1280 x 128\n",
        "eeg_band_arr = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"theta\"))\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"alpha\"))\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"beta\"))\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"gamma\"))\n",
        "eeg_band_arr = np.reshape(eeg_band_arr, (1280, 128))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "HVksA4V2ypUD"
      },
      "outputs": [],
      "source": [
        "frontal = np.array([\"F3\", \"FC1\", \"Fz\", \"F4\", \"FC2\"])\n",
        "parietal = np.array([\"P3\", \"P7\", \"Pz\", \"P4\", \"P8\"])\n",
        "occipital = np.array([\"O1\", \"Oz\", \"O2\", \"PO3\", \"PO4\"])\n",
        "central = np.array([\"CP5\", \"CP1\", \"Cz\", \"C4\", \"C3\", \"CP6\", \"CP2\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YQbtKTRzmdG",
        "outputId": "f627f7a9-6457-4201-9af0-397af79b7023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Fp1           AF3            F3            F7           FC5  \\\n",
            "count   1280.000000   1280.000000   1280.000000   1280.000000   1280.000000   \n",
            "mean     517.431002    974.493856    795.093910   1515.004071    746.435950   \n",
            "std     1165.295163   3147.555132   3020.711666   4990.544508   2188.101734   \n",
            "min        2.698928      1.995398      1.820656      3.283107      1.311200   \n",
            "25%       23.306027     17.117475     18.392335     30.827191     14.023436   \n",
            "50%       65.468048     82.102529     60.241953     91.266539     48.704968   \n",
            "75%      331.636624    304.949248    175.394835    248.308696    218.358248   \n",
            "max    15524.135098  38122.870846  39431.320394  49272.793208  20182.668545   \n",
            "\n",
            "               FC1            C3           T7           CP5          CP1  ...  \\\n",
            "count  1280.000000   1280.000000  1280.000000   1280.000000  1280.000000  ...   \n",
            "mean    345.936665    486.095113   354.004358    664.656754   276.667812  ...   \n",
            "std     717.328768   1497.636647   641.432373   2146.857585   498.823733  ...   \n",
            "min       2.025214      1.200156     3.418167      1.857737     1.340340  ...   \n",
            "25%      17.383454     18.273844    43.838157     19.178089    28.281757  ...   \n",
            "50%      55.561232     46.451432   128.629588     61.998792    60.330974  ...   \n",
            "75%     281.828747    234.342275   348.249862    312.653366   237.040645  ...   \n",
            "max    8542.244175  26021.167025  7023.985761  23255.512271  5972.589469  ...   \n",
            "\n",
            "                FC2            Cz            C4            T8           CP6  \\\n",
            "count   1280.000000   1280.000000   1280.000000   1280.000000   1280.000000   \n",
            "mean     669.953166    518.975872    471.905917    763.990397    544.785103   \n",
            "std     1714.340609   1407.210210   1896.584105   2236.655420   1563.878765   \n",
            "min        2.809501      1.637028      1.713283      2.133474      1.496299   \n",
            "25%       14.927239     23.440039      9.724978     25.143155     18.202863   \n",
            "50%       66.078472     67.044674     24.318235     90.110040     77.517763   \n",
            "75%      214.293557    305.766182    109.715681    386.232875    297.742897   \n",
            "max    18617.218099  16408.471958  24826.365142  28038.714329  19908.437378   \n",
            "\n",
            "               CP2            P4           P8           PO4            O2  \n",
            "count  1280.000000   1280.000000  1280.000000   1280.000000   1280.000000  \n",
            "mean    303.158814    527.491149   222.759444    780.700914    327.242856  \n",
            "std     650.093432   1429.084909   451.119818   1802.083002   1080.707954  \n",
            "min       1.439077      1.791296     1.641482      1.995230      3.681268  \n",
            "25%      26.754006     18.110041    18.064264     23.491991     19.333926  \n",
            "50%      88.083088     62.269206    90.914662     69.772647     49.630345  \n",
            "75%     257.959593    246.195582   225.463786    495.202699    113.117403  \n",
            "max    7210.746793  17568.065100  5487.311705  17167.017710  12314.030522  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "eeg_theta = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_theta.append(get_band_power(i,j,\"theta\"))\n",
        "eeg_theta = np.reshape(eeg_theta, (1280, 32))\n",
        "\n",
        "df_theta = pd.DataFrame(data = eeg_theta, columns=eeg_channels)\n",
        "print(df_theta.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1uT6ZlnzqL-",
        "outputId": "6027237f-1bc1-41c5-94f4-0bd96c53ef1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Fp1           AF3            F3            F7          FC5  \\\n",
            "count  1280.000000   1280.000000   1280.000000   1280.000000  1280.000000   \n",
            "mean    173.544174    333.184883    285.545436    573.725974   249.793720   \n",
            "std     378.371554   1058.758333   1036.330438   1943.692827   702.436934   \n",
            "min       2.770151      1.793012      1.724442      2.793554     0.975527   \n",
            "25%      14.082681     10.737435     10.012318     15.888935    10.074042   \n",
            "50%      33.713172     34.992442     30.026795     38.178299    20.079100   \n",
            "75%     125.508396    114.334883     73.488279     93.987498    74.040939   \n",
            "max    5627.906982  12380.702125  12764.724842  20843.070851  6575.781434   \n",
            "\n",
            "               FC1           C3           T7          CP5          CP1  ...  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  ...   \n",
            "mean    138.011594   170.423962   124.101183   232.750895    97.610644  ...   \n",
            "std     275.218934   497.507620   200.171342   735.717912   166.430024  ...   \n",
            "min       1.682977     1.963403     2.545447     2.251935     1.682386  ...   \n",
            "25%       9.228670    10.197058    21.452775    11.461012    13.367379  ...   \n",
            "50%      24.929907    22.318468    51.473641    25.364340    26.229818  ...   \n",
            "75%     117.988147    83.518174   129.890552   110.822931    91.941255  ...   \n",
            "max    3030.077791  9215.549575  2142.437275  7894.273428  2148.109415  ...   \n",
            "\n",
            "               FC2           Cz            C4           T8          CP6  \\\n",
            "count  1280.000000  1280.000000   1280.000000  1280.000000  1280.000000   \n",
            "mean    228.331178   199.941306    193.380344   276.638039   213.620700   \n",
            "std     569.202821   578.947819    812.031964   782.782127   661.135030   \n",
            "min       2.390011     1.315395      1.227024     1.636114     2.181082   \n",
            "25%       8.715210    12.127290      6.665166    15.980086    11.300805   \n",
            "50%      26.880000    29.827367     14.169702    34.252038    31.722499   \n",
            "75%      95.964685   102.480314     40.800135   142.704220   106.673844   \n",
            "max    6038.451512  6881.486185  10501.570698  9022.269308  8394.200372   \n",
            "\n",
            "               CP2           P4           P8          PO4           O2  \n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  \n",
            "mean    112.138023   181.507936    89.003586   269.572920   126.053116  \n",
            "std     236.260122   482.163785   186.841170   597.330120   400.465505  \n",
            "min       1.520363     2.158950     1.212432     2.002769     3.617116  \n",
            "25%      15.797490    11.564300    10.971965    13.489443    10.548845  \n",
            "50%      37.807211    28.494994    38.758864    29.247807    23.906708  \n",
            "75%      86.070815    92.261617    88.107272   162.117585    45.294454  \n",
            "max    2368.537880  5666.733316  2323.499853  5542.263376  3966.714864  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "# Transform 880 x 32 x 8064 => 880 x 32\n",
        "eeg_alpha = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_alpha.append(get_band_power(i,j,\"alpha\"))\n",
        "eeg_alpha = np.reshape(eeg_alpha, (1280, 32))\n",
        "\n",
        "df_alpha = pd.DataFrame(data = eeg_alpha, columns=eeg_channels)\n",
        "print(df_alpha.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUNGxdRLzvAW",
        "outputId": "836e7504-40b3-4382-860a-eb28db8c9e0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Fp1          AF3           F3            F7          FC5  \\\n",
            "count  1280.000000  1280.000000  1280.000000   1280.000000  1280.000000   \n",
            "mean     92.200266   200.684361   193.372441    341.951096   140.642394   \n",
            "std     176.162562   668.027842   668.771074   1274.679748   386.740178   \n",
            "min       4.486703     2.650970     2.784376      3.363422     2.788531   \n",
            "25%      17.999409    13.190613    10.170223     17.951892    11.341571   \n",
            "50%      34.413828    29.155242    28.120517     33.617573    22.402198   \n",
            "75%      80.774739   107.619088    59.807546     62.087123    53.162211   \n",
            "max    3528.485435  5784.160193  5841.475721  14848.700463  3094.687504   \n",
            "\n",
            "               FC1           C3           T7          CP5          CP1  ...  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  ...   \n",
            "mean     99.397187    96.901859    77.540922   137.387625    55.047411  ...   \n",
            "std     197.556641   247.621839    90.107877   409.366974    85.846400  ...   \n",
            "min       3.145262     2.991550     2.477519     2.886994     2.237445  ...   \n",
            "25%       8.919796     9.331138    23.668656    11.097811     9.370318  ...   \n",
            "50%      17.625226    19.698019    44.350493    22.622621    18.748879  ...   \n",
            "75%      79.066898    46.494215    93.087474    58.273844    51.308093  ...   \n",
            "max    1702.542675  5187.441594   634.645675  4094.116788  1238.024108  ...   \n",
            "\n",
            "               FC2           Cz           C4           T8          CP6  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000   \n",
            "mean    130.756212   131.961699   136.536661   178.534190   144.021213   \n",
            "std     338.843374   409.481195   603.902680   506.405387   484.806320   \n",
            "min       3.037555     1.816169     2.079646     2.429178     2.524762   \n",
            "25%       9.115906    10.803851     7.350435    17.466794    11.400277   \n",
            "50%      17.479204    25.300435    12.926731    30.157902    23.679679   \n",
            "75%      75.259937    54.745901    25.609433    93.320360    64.338413   \n",
            "max    2786.622358  4842.537927  7489.480637  4064.418656  5955.637009   \n",
            "\n",
            "               CP2           P4           P8          PO4           O2  \n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  \n",
            "mean     74.751315   103.971557    62.850280   148.868580    90.837375  \n",
            "std     165.803855   288.941591   134.177873   329.650542   275.150372  \n",
            "min       2.272088     2.914214     3.059450     2.461123     5.084168  \n",
            "25%      13.014515    11.560334    12.312069    13.732279    11.291516  \n",
            "50%      24.705624    20.439224    27.763129    23.940855    19.688820  \n",
            "75%      53.062550    67.593128    64.187473    99.947093    36.076683  \n",
            "max    1265.234960  2533.794744  1653.743590  2516.334382  2454.759737  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "# Transform 880 x 32 x 8064 => 880 x 32\n",
        "eeg_beta = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_beta.append(get_band_power(i,j,\"beta\"))\n",
        "eeg_beta = np.reshape(eeg_beta, (1280, 32))\n",
        "\n",
        "df_beta = pd.DataFrame(data = eeg_beta, columns=eeg_channels)\n",
        "print(df_beta.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJP58i-60AEV",
        "outputId": "4e551a91-ced0-420c-ca45-5e40b606fc96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Fp1          AF3           F3           F7          FC5  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000   \n",
            "mean     50.663247   150.492372   149.210824   122.775294    91.633571   \n",
            "std     135.591365   645.635199   632.049548   496.744509   340.562025   \n",
            "min       1.069233     1.119910     0.791859     1.177512     0.712624   \n",
            "25%       8.292302     5.605668     4.352724     7.591098     5.172920   \n",
            "50%      18.329100    14.069330    11.828027    15.919877    12.648067   \n",
            "75%      39.995543    43.454610    28.586812    36.456420    38.094737   \n",
            "max    3213.255538  6060.539788  5758.756812  6348.177208  3472.515858   \n",
            "\n",
            "               FC1           C3           T7          CP5          CP1  ...  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  ...   \n",
            "mean     60.487715    56.236468    43.792285    77.048369    29.250057  ...   \n",
            "std     139.230040   180.285647    62.089299   267.809883    68.503827  ...   \n",
            "min       0.694928     0.684210     0.562676     0.788359     0.509259  ...   \n",
            "25%       2.666459     3.534375    10.492723     3.837095     3.156311  ...   \n",
            "50%       5.313502     9.056340    23.540152     9.532963     7.735783  ...   \n",
            "75%      41.027482    29.838450    54.382720    22.302862    18.604669  ...   \n",
            "max    1413.985901  4376.356658   809.935644  2294.561961  1011.985310  ...   \n",
            "\n",
            "               FC2           Cz           C4           T8          CP6  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000   \n",
            "mean     79.191679    56.547283    55.989289   117.745424    64.340498   \n",
            "std     306.464243   167.968314   239.143748   428.381018   199.387966   \n",
            "min       0.692350     0.395680     0.697486     1.027260     0.609425   \n",
            "25%       2.893590     3.800780     2.286229     7.221083     3.850387   \n",
            "50%       7.535055     8.493068     4.640151    17.921722    10.563661   \n",
            "75%      26.896601    20.882885    13.538524    39.981006    30.943717   \n",
            "max    2829.052404  1892.813293  3054.309237  3954.519861  2405.614840   \n",
            "\n",
            "               CP2           P4           P8          PO4           O2  \n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  \n",
            "mean     46.943309    68.100629    29.805883    82.197819    55.821892  \n",
            "std     142.501802   265.168885    57.843154   272.880509   203.288109  \n",
            "min       0.478152     0.761387     0.804002     0.838747     0.877576  \n",
            "25%       3.849956     3.690054     4.513405     4.620006     4.380690  \n",
            "50%       8.646393     7.300040    10.911662    10.430337     6.994829  \n",
            "75%      22.614200    28.908609    26.489674    42.960182    14.567389  \n",
            "max    1426.462453  2446.765512   647.533599  2505.826127  1794.801694  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "# Transform 880 x 32 x 8064 => 880 x 32\n",
        "eeg_gamma = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_gamma.append(get_band_power(i,j,\"gamma\"))\n",
        "eeg_gamma = np.reshape(eeg_gamma, (1280, 32))\n",
        "\n",
        "df_gamma = pd.DataFrame(data = eeg_gamma, columns=eeg_channels)\n",
        "print(df_gamma.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "kmTpi6Qc02Bu"
      },
      "outputs": [],
      "source": [
        "# Split the data into training/testing sets\n",
        "def split_train_test(x, y):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
        "  return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "cOCvaWDba3pa"
      },
      "outputs": [],
      "source": [
        "# Feature scaling\n",
        "def feature_scaling(train, test):\n",
        "  sc = StandardScaler()\n",
        "  train = sc.fit_transform(train)\n",
        "  test = sc.transform(test)\n",
        "  return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "EHrmKN1nf8ys"
      },
      "outputs": [],
      "source": [
        "band_names = np.array([\"theta\", \"alpha\", \"beta\", \"gamma\"])\n",
        "channel_names = np.array([\"frontal\",  \"central\", \"parietal\", \"occipital\"])\n",
        "label_names = np.array([\"valence\", \"arousal\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "tYVZwPvFgATk"
      },
      "outputs": [],
      "source": [
        "# Testing different kernels (linear, sigmoid, rbf, poly) to select the most optimal one\n",
        "clf_svm = SVC(kernel = 'rbf',random_state = 42, probability=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "t4pznSOZgHmK"
      },
      "outputs": [],
      "source": [
        "# Testing different k (odd) numbers, algorithm (auto, ball_tree, kd_tree) and weight (uniform, distance) to select the most optimal one\n",
        "clf_knn = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "7gi_aMFOgL08"
      },
      "outputs": [],
      "source": [
        "clf_dtree=DecisionTreeClassifier(max_depth=20,min_samples_split=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "T9hH4fktgPOX"
      },
      "outputs": [],
      "source": [
        "clf_rf=RandomForestClassifier(n_estimators=50,max_depth=20,min_samples_split=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "7lJ9wwn0gUmH"
      },
      "outputs": [],
      "source": [
        "clf_nb= GaussianNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "h-f5ay_0gYey"
      },
      "outputs": [],
      "source": [
        "# Testing different learning rate (alpha), solver (adam, sgd, lbfgs) and activation (relu, tanh, logistic) to select the most optimal one\n",
        "clf_mlp = MLPClassifier(solver='adam', activation='tanh', alpha=0.3, max_iter=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "vOCq_XttoT4e"
      },
      "outputs": [],
      "source": [
        "clf_adaboost = AdaBoostClassifier(n_estimators=50, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "xJMuk2lWq8v6"
      },
      "outputs": [],
      "source": [
        "clf_xgb = xgb.XGBClassifier(learning_rate=0.1, max_depth=3, n_estimators=100, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "KFc0oT1XMHGv"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "clf_lgbm = lgb.LGBMClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "G_SB4HCTNIWQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "clf_gpc = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0), random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "xQ_4Dt-2N5t8"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "clf_perceptron = Perceptron(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pheOwL8PlYt",
        "outputId": "31aba06f-3fcd-47a5-bba3-6c44ee09ca32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.3.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "import catboost as cb\n",
        "clf_catboost = cb.CatBoostClassifier(iterations=1000, depth=6, learning_rate=0.1, loss_function='Logloss', verbose=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define cnn model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "def create_cnn_model(data_np):\n",
        "    model = Sequential([\n",
        "        Input(shape=(data_np.shape[1], 1)),  # Adjusted to match data_np shape\n",
        "        Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.2),\n",
        "        Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.2),\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(2, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate_cnn(df_x, df_y):\n",
        "    # Convert dataframes to numpy arrays\n",
        "    data_np = df_x.values\n",
        "    labels_np = df_y.values\n",
        "\n",
        "    # Reshape data for CNN: (number of samples, height, width, channels)\n",
        "    # Here, height=1, width=number of features, channels=1\n",
        "    data_reshaped = data_np.reshape((data_np.shape[0], data_np.shape[1], 1))\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    labels_encoded = to_categorical(labels_np)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_reshaped, labels_encoded, test_size=0.20, random_state=42)\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = create_cnn_model(data_np)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "    return test_loss, test_accuracy\n"
      ],
      "metadata": {
        "id": "tIwd_l6MD6dw"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define ann model\n",
        "def create_ann_model(data_scaled):\n",
        "    model = Sequential([\n",
        "        Dense(64, input_dim=data_scaled.shape[1], activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(2, activation='softmax')  # Assuming two classes: 0 and 1\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_and_evaluate_ann(df_x, df_y):\n",
        "    # Convert dataframes to numpy arrays\n",
        "    data_np = df_x.values\n",
        "    labels_np = df_y.values\n",
        "\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    data_scaled = scaler.fit_transform(data_np)\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    labels_encoded = to_categorical(labels_np)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_scaled, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = create_ann_model(data_np)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "    return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "C81EuQgrZIim"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define lstm model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "def create_lstm_model(data_np):\n",
        "    model = Sequential([\n",
        "    LSTM(20, input_shape=(data_np.shape[1], 1)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')  # Assuming two classes: 0 and 1\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate_lstm(df_x, df_y):\n",
        "    # Convert dataframes to numpy arrays\n",
        "    data_np = df_x.values\n",
        "    labels_np = df_y.values\n",
        "\n",
        "    # Reshape data for LSTM: (samples, time_steps, features)\n",
        "    # Here, each row is treated as a sequence with a single time step\n",
        "    data_reshaped = data_np.reshape((data_np.shape[0], data_np.shape[1], 1))\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    labels_encoded = to_categorical(labels_np)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_reshaped, labels_encoded, test_size=0.2, random_state=42)\n",
        "    # Define the CNN model\n",
        "    model = create_lstm_model(data_np)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7hC14PKCbZUM"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "i28DLITPgfgJ"
      },
      "outputs": [],
      "source": [
        "models = []\n",
        "models.append(('SVM', clf_svm))\n",
        "models.append(('k-NN', clf_knn))\n",
        "models.append(('DT', clf_dtree))\n",
        "models.append(('RF', clf_rf))\n",
        "models.append(('NB', clf_nb))\n",
        "models.append(('MLP', clf_mlp))\n",
        "models.append(('AB', clf_adaboost))\n",
        "models.append(('XGB', clf_xgb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "L_WzJMzsjrL4"
      },
      "outputs": [],
      "source": [
        "def run_clf_cv(band, channel, label, clf):\n",
        "  if (band == \"theta\"):\n",
        "    df_x = df_theta\n",
        "  elif (band == \"alpha\"):\n",
        "    df_x = df_alpha\n",
        "  elif (band == \"beta\"):\n",
        "    df_x = df_beta\n",
        "  elif (band == \"gamma\"):\n",
        "    df_x = df_gamma\n",
        "\n",
        "  if (channel == \"frontal\"):\n",
        "    df_x = df_x[frontal]\n",
        "  elif (channel == \"central\"):\n",
        "    df_x = df_x[central]\n",
        "  elif (channel == \"parietal\"):\n",
        "    df_x = df_x[parietal]\n",
        "  elif (channel == \"occipital\"):\n",
        "    df_x = df_x[occipital]\n",
        "\n",
        "  # df_y = df_arousal if (label == \"arousal\") else df_valence\n",
        "  # print(df_y.shape)\n",
        "  # df_y = df_result[\"HAHV\"]\n",
        "  # df_y = df_result\n",
        "  # df_y = df_y.flatten\n",
        "  # print(f\"the shape of df_y is {df_y.shape}\")\n",
        "  # print(f\"the shape of df_x is {df_x.shape}\")\n",
        "  if (label == \"HAHV\"):\n",
        "    df_y = df_result[\"HAHV\"]\n",
        "  elif (label == \"LAHV\"):\n",
        "    df_y = df_result[\"LAHV\"]\n",
        "  elif (label == \"HALV\"):\n",
        "    df_y = df_result[\"HALV\"]\n",
        "  elif (label == \"LALV\"):\n",
        "    df_y = df_result[\"LALV\"]\n",
        "\n",
        "  # print(f\"the shape of df_y is {df_y.shape}\")\n",
        "  # print(f\"the shape of df_x is {df_x.shape}\")\n",
        "  # Train-test split\n",
        "\n",
        "  # save he dataframes in csv format for analysis\n",
        "  # if (band == \"gamma\" and channel == \"frontal\" and label == \"HALV\"):\n",
        "  #   df_y.to_csv('labels.csv', index=False)\n",
        "  #   print(\"DataFrame saved to 'labels.csv'\")\n",
        "  #   df_x.to_csv('data.csv', index=False)\n",
        "  #   print(\"DataFrame saved to 'data.csv'\")\n",
        "  #   from google.colab import files\n",
        "  #   files.download('labels.csv')\n",
        "  #   files.download('data.csv')\n",
        "\n",
        "  x_train, x_test, y_train, y_test = split_train_test(df_x, df_y)\n",
        "\n",
        "  # Apply CV\n",
        "  x_for_kfold = np.array(x_train)\n",
        "  y_for_kfold = np.array(y_train)\n",
        "  kfold = model_selection.KFold(n_splits=5)\n",
        "\n",
        "  for i, j in kfold.split(x_for_kfold):\n",
        "   x_train2, x_test2 = x_for_kfold[i], x_for_kfold[j]\n",
        "   y_train2, y_test2 = y_for_kfold[i], y_for_kfold[j]\n",
        "\n",
        "  # Feature scaling\n",
        "  x_train2, x_test2 = feature_scaling(x_train2, x_test2)\n",
        "\n",
        "  # Feature scaling\n",
        "  # scaler = StandardScaler()\n",
        "  # x_train2 = scaler.fit_transform(x_train2)\n",
        "  # x_test2 = scaler.transform(x_test2)\n",
        "\n",
        "\n",
        "  if (clf == \"svm\"):\n",
        "    clf_svm.fit(x_train2, y_train2)\n",
        "    y_predict = clf_svm.predict(x_test2)\n",
        "  elif (clf == \"knn\"):\n",
        "    clf_knn.fit(x_train2, y_train2)\n",
        "    y_predict = clf_knn.predict(x_test2)\n",
        "  elif (clf == \"dtree\"):\n",
        "    clf_dtree.fit(x_train2, y_train2)\n",
        "    y_predict = clf_dtree.predict(x_test2)\n",
        "  elif (clf == \"rf\"):\n",
        "    clf_rf.fit(x_train2, y_train2)\n",
        "    y_predict = clf_rf.predict(x_test2)\n",
        "  elif (clf == \"nb\"):\n",
        "    clf_nb.fit(x_train2, y_train2)\n",
        "    y_predict = clf_nb.predict(x_test2)\n",
        "  elif (clf == \"mlp\"):\n",
        "    clf_mlp.fit(x_train2, y_train2)\n",
        "    y_predict = clf_mlp.predict(x_test2)\n",
        "  elif (clf == \"ab\"):\n",
        "    clf_adaboost.fit(x_train2, y_train2)\n",
        "    y_predict = clf_adaboost.predict(x_test2)\n",
        "  elif (clf == \"xgb\"):\n",
        "    clf_xgb.fit(x_train2, y_train2)\n",
        "    y_predict = clf_xgb.predict(x_test2)\n",
        "  elif (clf == \"lgbm\"):\n",
        "    clf_lgbm.fit(x_train2, y_train2)\n",
        "    y_predict = clf_lgbm.predict(x_test2)\n",
        "  elif (clf == \"gpc\"):\n",
        "    clf_gpc.fit(x_train2, y_train2)\n",
        "    y_predict = clf_gpc.predict(x_test2)\n",
        "  elif (clf == \"per\"):\n",
        "    clf_perceptron.fit(x_train2, y_train2)\n",
        "    y_predict = clf_perceptron.predict(x_test2)\n",
        "  elif (clf == \"cb\"):\n",
        "    clf_catboost.fit(x_train2, y_train2)\n",
        "    y_predict = clf_catboost.predict(x_test2)\n",
        "  elif (clf == \"cnn\"):\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = train_and_evaluate_cnn(df_x, df_y)\n",
        "    # print(f\"Test Loss: {test_loss}\")\n",
        "    # print(f\"Test Accuracy: {test_accuracy}\")\n",
        "    return \"DL\",test_loss, test_accuracy\n",
        "\n",
        "  elif(clf ==\"ann\"):\n",
        "    test_loss, test_accuracy = train_and_evaluate_ann(df_x, df_y)\n",
        "    # print(f\"Test Loss: {test_loss}\")\n",
        "    # print(f\"Test Accuracy: {test_accuracy}\")\n",
        "    return \"DL\",test_loss, test_accuracy\n",
        "  elif(clf ==\"lstm\"):\n",
        "    test_loss, test_accuracy = train_and_evaluate_lstm(df_x, df_y)\n",
        "    return \"DL\",test_loss,test_accuracy\n",
        "  return \"ML\",y_test2, y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "gWN0kvbJjyhB"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(band, channel, label, clf):\n",
        "  classifier,y_test2, y_predict = run_clf_cv(band, channel, label, clf)\n",
        "  if (classifier == \"DL\"):\n",
        "    return y_predict\n",
        "  return np.round(accuracy_score(y_test2, y_predict)*100,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "cB-1MOCIuv_M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "def print_conf(band, channel, label, clf):\n",
        "  y_test2, y_predict = run_clf_cv(band, channel, label, clf)\n",
        "  conf_matrix = confusion_matrix(y_test2, y_predict)\n",
        "  # print(conf_matrix)\n",
        "  plt.figure(figsize=(4, 2))  # Decrease the figure size\n",
        "  plt.title('Confusion Matrix')\n",
        "  sns.heatmap(conf_matrix,\n",
        "              annot=True,\n",
        "              fmt='g',\n",
        "              xticklabels=['Not Spam','Spam'],\n",
        "              yticklabels=['Not Spam','Spam'])\n",
        "\n",
        "  # display matrix\n",
        "  plt.ylabel('Actual',fontsize=12)\n",
        "  plt.xlabel('Prediction',fontsize=12)\n",
        "  plt.show()\n",
        "\n",
        "  # printing the classification report aswell\n",
        "\n",
        "  class_report = classification_report(y_test2, y_predict, target_names=['Not Spam', 'Spam'])\n",
        "  print(\"\\nClassification Report:\")\n",
        "  print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_kBo9bznkFa9"
      },
      "outputs": [],
      "source": [
        "def print_accuracy(label, clf):\n",
        "  arr = []\n",
        "  for i in range (len(band_names)):\n",
        "    for j in range (len(channel_names)):\n",
        "      arr.append(get_accuracy(band_names[i], channel_names[j], label, clf))\n",
        "  arr = np.reshape(arr, (4,4))\n",
        "  df = pd.DataFrame(data = arr, index=band_names, columns=channel_names)\n",
        "\n",
        "  #print(\"Top 3 EEG regions with highest scores\")\n",
        "  #print(df.apply(lambda s: s.abs()).max().nlargest(3))\n",
        "  #print()\n",
        "  #print(\"Top 2 bands with highest scores\")\n",
        "  #print(df.apply(lambda s: s.abs()).max(axis=1).nlargest(2))\n",
        "  #print()\n",
        "  #print(\"EEG region with highest scores per each band\")\n",
        "  #print(df.idxmax(axis=1))\n",
        "  #print()\n",
        "  #print(\"Accuracy Scores\")\n",
        "  #print(df.idxmax())\n",
        "  #print()\n",
        "  print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDIaK777kOdU",
        "outputId": "48234377-d1c5-4bbe-d3f4-cad467c7bfb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    68.63    69.61     69.12      68.63\n",
            "alpha    68.63    70.10     69.12      68.63\n",
            "beta     70.10    69.61     70.10      70.10\n",
            "gamma    69.61    69.61     70.10      69.61\n"
          ]
        }
      ],
      "source": [
        "print_accuracy('HAHV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfE3GdBoXXlK"
      },
      "outputs": [],
      "source": [
        "print_conf(\"beta\",\"frontal\",\"HAHV\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTqPyKdifUch"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LAHV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv-yHWWNXq4F"
      },
      "outputs": [],
      "source": [
        "print_conf(\"theta\",\"occipital\",\"LAHV\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaV8Ul3zfbVG"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HALV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsXUXB_mX4Yq"
      },
      "outputs": [],
      "source": [
        "print_conf(\"gamma\",\"frontal\",\"HALV\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sPz6Kjdfkia"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LALV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IytKfnprYIKG"
      },
      "outputs": [],
      "source": [
        "print_conf(\"gamma\",\"occipital\",\"LALV\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"ann\")"
      ],
      "metadata": {
        "id": "3ZJ1eRTBagJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"lstm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47cLDLLtc3dL",
        "outputId": "571393d7-9b6a-4fb9-cb5a-12f15bc17912"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 9s 67ms/step - loss: 0.6641 - accuracy: 0.6357 - val_loss: 0.5201 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.7529 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5653 - accuracy: 0.7559 - val_loss: 0.5125 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.7656 - val_loss: 0.5179 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5664 - accuracy: 0.7686 - val_loss: 0.5146 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5568 - accuracy: 0.7705 - val_loss: 0.5167 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.7725 - val_loss: 0.5144 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7734 - val_loss: 0.5190 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7754 - val_loss: 0.5166 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7764 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7764 - val_loss: 0.5187 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5431 - accuracy: 0.7764 - val_loss: 0.5156 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5513 - accuracy: 0.7773 - val_loss: 0.5152 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7764 - val_loss: 0.5199 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7764 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7764 - val_loss: 0.5185 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5401 - accuracy: 0.7764 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7764 - val_loss: 0.5166 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5447 - accuracy: 0.7754 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5191 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7754 - val_loss: 0.5189 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5217 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7764 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5170 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7764 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.7764 - val_loss: 0.5281 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7764 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7764 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7764 - val_loss: 0.5195 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7764 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7764 - val_loss: 0.5170 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7764 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7764 - val_loss: 0.5180 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5158 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7764 - val_loss: 0.5120 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.7764 - val_loss: 0.5220 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5176 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5137 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7764 - val_loss: 0.5148 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5131 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5106 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5244 - accuracy: 0.7764 - val_loss: 0.5116 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5136 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7764 - val_loss: 0.5150 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 31ms/step - loss: 0.6318 - accuracy: 0.7109 - val_loss: 0.5240 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5989 - accuracy: 0.7500 - val_loss: 0.5253 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5668 - accuracy: 0.7559 - val_loss: 0.5302 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5749 - accuracy: 0.7617 - val_loss: 0.5303 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5515 - accuracy: 0.7695 - val_loss: 0.5331 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7734 - val_loss: 0.5343 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5504 - accuracy: 0.7695 - val_loss: 0.5332 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5627 - accuracy: 0.7686 - val_loss: 0.5312 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5529 - accuracy: 0.7695 - val_loss: 0.5313 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5426 - accuracy: 0.7754 - val_loss: 0.5356 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5384 - accuracy: 0.7744 - val_loss: 0.5279 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5320 - accuracy: 0.7754 - val_loss: 0.5319 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5489 - accuracy: 0.7754 - val_loss: 0.5367 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5400 - accuracy: 0.7764 - val_loss: 0.5272 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5494 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5326 - accuracy: 0.7764 - val_loss: 0.5262 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5267 - accuracy: 0.7764 - val_loss: 0.5277 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5353 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5379 - accuracy: 0.7764 - val_loss: 0.5321 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5292 - accuracy: 0.7764 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7764 - val_loss: 0.5282 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5429 - accuracy: 0.7764 - val_loss: 0.5297 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5282 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5328 - accuracy: 0.7764 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7764 - val_loss: 0.5326 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5286 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5361 - accuracy: 0.7764 - val_loss: 0.5314 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5348 - accuracy: 0.7764 - val_loss: 0.5293 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5277 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5259 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7764 - val_loss: 0.5286 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.7764 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5279 - accuracy: 0.7764 - val_loss: 0.5210 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.7764 - val_loss: 0.5228 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5311 - accuracy: 0.7764 - val_loss: 0.5254 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5310 - accuracy: 0.7764 - val_loss: 0.5229 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7764 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5241 - accuracy: 0.7764 - val_loss: 0.5184 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7764 - val_loss: 0.5184 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.7764 - val_loss: 0.5192 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5224 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5264 - accuracy: 0.7764 - val_loss: 0.5174 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7764 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7764 - val_loss: 0.5205 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5268 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5261 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.6244 - accuracy: 0.6787 - val_loss: 0.5122 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7705 - val_loss: 0.5039 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5734 - accuracy: 0.7783 - val_loss: 0.5065 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.7715 - val_loss: 0.5066 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7754 - val_loss: 0.5067 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5572 - accuracy: 0.7764 - val_loss: 0.5086 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5476 - accuracy: 0.7744 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7764 - val_loss: 0.5089 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.7754 - val_loss: 0.5126 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7754 - val_loss: 0.5089 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5443 - accuracy: 0.7764 - val_loss: 0.5103 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7764 - val_loss: 0.5131 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5450 - accuracy: 0.7764 - val_loss: 0.5075 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7764 - val_loss: 0.5156 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5082 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5113 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5420 - accuracy: 0.7764 - val_loss: 0.5137 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5347 - accuracy: 0.7764 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5255 - accuracy: 0.7764 - val_loss: 0.5108 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5321 - accuracy: 0.7764 - val_loss: 0.5108 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5297 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5351 - accuracy: 0.7764 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5294 - accuracy: 0.7764 - val_loss: 0.5099 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5316 - accuracy: 0.7764 - val_loss: 0.5121 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5370 - accuracy: 0.7764 - val_loss: 0.5120 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5110 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5121 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5112 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5348 - accuracy: 0.7764 - val_loss: 0.5096 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5319 - accuracy: 0.7764 - val_loss: 0.5106 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.7764 - val_loss: 0.5104 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7764 - val_loss: 0.5074 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7764 - val_loss: 0.5081 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7764 - val_loss: 0.5094 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7764 - val_loss: 0.5100 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7764 - val_loss: 0.5080 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5199 - accuracy: 0.7764 - val_loss: 0.5080 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5103 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5244 - accuracy: 0.7764 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5083 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5270 - accuracy: 0.7764 - val_loss: 0.5092 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5074 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.5760 - accuracy: 0.7529 - val_loss: 0.5138 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5761 - accuracy: 0.7715 - val_loss: 0.5190 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5706 - accuracy: 0.7744 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.7764 - val_loss: 0.5176 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7764 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7764 - val_loss: 0.5193 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7764 - val_loss: 0.5229 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.7764 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5474 - accuracy: 0.7764 - val_loss: 0.5294 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5429 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7764 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7764 - val_loss: 0.5233 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5278 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5413 - accuracy: 0.7764 - val_loss: 0.5248 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7764 - val_loss: 0.5204 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.7764 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7764 - val_loss: 0.5257 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7764 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7764 - val_loss: 0.5251 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5359 - accuracy: 0.7764 - val_loss: 0.5201 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5382 - accuracy: 0.7764 - val_loss: 0.5191 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5294 - accuracy: 0.7764 - val_loss: 0.5194 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5321 - accuracy: 0.7764 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5373 - accuracy: 0.7764 - val_loss: 0.5244 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.7764 - val_loss: 0.5262 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5335 - accuracy: 0.7764 - val_loss: 0.5237 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5372 - accuracy: 0.7764 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5320 - accuracy: 0.7764 - val_loss: 0.5204 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5350 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5339 - accuracy: 0.7764 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5389 - accuracy: 0.7764 - val_loss: 0.5206 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5293 - accuracy: 0.7764 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7764 - val_loss: 0.5195 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7764 - val_loss: 0.5214 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5209 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5332 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5352 - accuracy: 0.7764 - val_loss: 0.5178 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5187 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5288 - accuracy: 0.7764 - val_loss: 0.5156 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5366 - accuracy: 0.7764 - val_loss: 0.5194 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5158 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 22ms/step - loss: 0.7580 - accuracy: 0.5088 - val_loss: 0.5274 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5878 - accuracy: 0.7568 - val_loss: 0.5122 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5836 - accuracy: 0.7568 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5706 - accuracy: 0.7783 - val_loss: 0.5131 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5629 - accuracy: 0.7725 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5536 - accuracy: 0.7725 - val_loss: 0.5095 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5522 - accuracy: 0.7666 - val_loss: 0.5092 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5533 - accuracy: 0.7686 - val_loss: 0.5087 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5475 - accuracy: 0.7734 - val_loss: 0.5070 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7773 - val_loss: 0.5056 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5430 - accuracy: 0.7754 - val_loss: 0.5080 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5427 - accuracy: 0.7754 - val_loss: 0.5082 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5082 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5433 - accuracy: 0.7754 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7764 - val_loss: 0.5057 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5034 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5411 - accuracy: 0.7744 - val_loss: 0.5023 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.7754 - val_loss: 0.5042 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5365 - accuracy: 0.7754 - val_loss: 0.5029 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5374 - accuracy: 0.7754 - val_loss: 0.5021 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5012 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5332 - accuracy: 0.7764 - val_loss: 0.5025 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7764 - val_loss: 0.5094 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5239 - accuracy: 0.7764 - val_loss: 0.4991 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7764 - val_loss: 0.4993 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5252 - accuracy: 0.7764 - val_loss: 0.4987 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5271 - accuracy: 0.7764 - val_loss: 0.4993 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5019 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5290 - accuracy: 0.7754 - val_loss: 0.5022 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5004 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5252 - accuracy: 0.7764 - val_loss: 0.4989 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5288 - accuracy: 0.7764 - val_loss: 0.4994 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5014 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5251 - accuracy: 0.7764 - val_loss: 0.5003 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5196 - accuracy: 0.7764 - val_loss: 0.4947 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5211 - accuracy: 0.7764 - val_loss: 0.4991 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5270 - accuracy: 0.7764 - val_loss: 0.4900 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5152 - accuracy: 0.7764 - val_loss: 0.4934 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5184 - accuracy: 0.7764 - val_loss: 0.4933 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5250 - accuracy: 0.7764 - val_loss: 0.4981 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5257 - accuracy: 0.7764 - val_loss: 0.4981 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5203 - accuracy: 0.7764 - val_loss: 0.4913 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5218 - accuracy: 0.7764 - val_loss: 0.5012 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5221 - accuracy: 0.7764 - val_loss: 0.4994 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5248 - accuracy: 0.7764 - val_loss: 0.4981 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5235 - accuracy: 0.7764 - val_loss: 0.4991 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7764 - val_loss: 0.4970 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5237 - accuracy: 0.7764 - val_loss: 0.4976 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5179 - accuracy: 0.7764 - val_loss: 0.4949 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5236 - accuracy: 0.7764 - val_loss: 0.4975 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 24ms/step - loss: 0.6401 - accuracy: 0.6680 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5599 - accuracy: 0.7695 - val_loss: 0.5096 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5754 - accuracy: 0.7705 - val_loss: 0.5179 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5591 - accuracy: 0.7734 - val_loss: 0.5148 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5536 - accuracy: 0.7725 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5491 - accuracy: 0.7744 - val_loss: 0.5093 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5463 - accuracy: 0.7764 - val_loss: 0.5144 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5435 - accuracy: 0.7764 - val_loss: 0.5120 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7764 - val_loss: 0.5134 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5426 - accuracy: 0.7764 - val_loss: 0.5131 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5418 - accuracy: 0.7764 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5439 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7773 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5386 - accuracy: 0.7764 - val_loss: 0.5172 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5133 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5275 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5478 - accuracy: 0.7764 - val_loss: 0.5156 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5373 - accuracy: 0.7764 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7764 - val_loss: 0.5121 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5337 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5381 - accuracy: 0.7764 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5361 - accuracy: 0.7764 - val_loss: 0.5202 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5322 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5312 - accuracy: 0.7764 - val_loss: 0.5171 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5338 - accuracy: 0.7764 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5243 - accuracy: 0.7764 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5330 - accuracy: 0.7764 - val_loss: 0.5125 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5293 - accuracy: 0.7764 - val_loss: 0.5135 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5322 - accuracy: 0.7764 - val_loss: 0.5169 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5204 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5366 - accuracy: 0.7764 - val_loss: 0.5170 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5148 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5319 - accuracy: 0.7764 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5295 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5255 - accuracy: 0.7764 - val_loss: 0.5135 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5292 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5145 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5122 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5261 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5243 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5269 - accuracy: 0.7764 - val_loss: 0.5105 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5246 - accuracy: 0.7764 - val_loss: 0.5122 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5254 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5295 - accuracy: 0.7764 - val_loss: 0.5096 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5239 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 4s 36ms/step - loss: 0.6111 - accuracy: 0.6895 - val_loss: 0.5180 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5595 - accuracy: 0.7725 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5474 - accuracy: 0.7715 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5634 - accuracy: 0.7666 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5581 - accuracy: 0.7734 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5504 - accuracy: 0.7754 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5530 - accuracy: 0.7764 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5487 - accuracy: 0.7764 - val_loss: 0.5162 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.7764 - val_loss: 0.5235 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5446 - accuracy: 0.7764 - val_loss: 0.5153 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5576 - accuracy: 0.7764 - val_loss: 0.5235 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5457 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5426 - accuracy: 0.7764 - val_loss: 0.5128 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5403 - accuracy: 0.7764 - val_loss: 0.5178 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5430 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.7764 - val_loss: 0.5215 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7764 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5412 - accuracy: 0.7764 - val_loss: 0.5167 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7764 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7764 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5325 - accuracy: 0.7764 - val_loss: 0.5150 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5287 - accuracy: 0.7764 - val_loss: 0.5146 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5372 - accuracy: 0.7764 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5364 - accuracy: 0.7764 - val_loss: 0.5137 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5226 - accuracy: 0.7764 - val_loss: 0.5128 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5274 - accuracy: 0.7764 - val_loss: 0.5129 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5310 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7764 - val_loss: 0.5129 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5133 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7764 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.7764 - val_loss: 0.5143 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5138 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5288 - accuracy: 0.7764 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5374 - accuracy: 0.7764 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5143 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5124 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5246 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7764 - val_loss: 0.5112 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7764 - val_loss: 0.5113 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5258 - accuracy: 0.7764 - val_loss: 0.5105 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7764 - val_loss: 0.5136 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5262 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7764 - val_loss: 0.5129 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.5928 - accuracy: 0.7236 - val_loss: 0.5265 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7734 - val_loss: 0.5136 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5670 - accuracy: 0.7773 - val_loss: 0.5183 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5550 - accuracy: 0.7734 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7764 - val_loss: 0.5248 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5516 - accuracy: 0.7764 - val_loss: 0.5263 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5466 - accuracy: 0.7754 - val_loss: 0.5335 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5513 - accuracy: 0.7754 - val_loss: 0.5316 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5397 - accuracy: 0.7764 - val_loss: 0.5276 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5406 - accuracy: 0.7764 - val_loss: 0.5286 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5481 - accuracy: 0.7764 - val_loss: 0.5299 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5389 - accuracy: 0.7764 - val_loss: 0.5321 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5296 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5367 - accuracy: 0.7764 - val_loss: 0.5330 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5405 - accuracy: 0.7764 - val_loss: 0.5324 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5407 - accuracy: 0.7764 - val_loss: 0.5273 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5422 - accuracy: 0.7764 - val_loss: 0.5300 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7764 - val_loss: 0.5253 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5340 - accuracy: 0.7764 - val_loss: 0.5232 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5347 - accuracy: 0.7764 - val_loss: 0.5223 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5394 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7764 - val_loss: 0.5233 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5399 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5330 - accuracy: 0.7764 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7764 - val_loss: 0.5263 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5248 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5335 - accuracy: 0.7764 - val_loss: 0.5242 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5274 - accuracy: 0.7764 - val_loss: 0.5191 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5267 - accuracy: 0.7764 - val_loss: 0.5211 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5325 - accuracy: 0.7764 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5335 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5263 - accuracy: 0.7764 - val_loss: 0.5194 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.7764 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5393 - accuracy: 0.7764 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5319 - accuracy: 0.7764 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5291 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7764 - val_loss: 0.5240 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5276 - accuracy: 0.7764 - val_loss: 0.5178 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5338 - accuracy: 0.7764 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.7764 - val_loss: 0.5193 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5206 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5381 - accuracy: 0.7764 - val_loss: 0.5202 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5342 - accuracy: 0.7764 - val_loss: 0.5208 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.7764 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7764 - val_loss: 0.5213 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5305 - accuracy: 0.7764 - val_loss: 0.5193 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 22ms/step - loss: 0.5889 - accuracy: 0.7490 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5908 - accuracy: 0.7676 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5629 - accuracy: 0.7676 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5504 - accuracy: 0.7725 - val_loss: 0.5197 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.7783 - val_loss: 0.5197 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5514 - accuracy: 0.7744 - val_loss: 0.5223 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.7754 - val_loss: 0.5193 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5405 - accuracy: 0.7734 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5538 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7773 - val_loss: 0.5208 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5426 - accuracy: 0.7773 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5420 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5434 - accuracy: 0.7754 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5347 - accuracy: 0.7764 - val_loss: 0.5109 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5365 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5071 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5315 - accuracy: 0.7764 - val_loss: 0.5135 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5324 - accuracy: 0.7764 - val_loss: 0.5118 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5070 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7764 - val_loss: 0.5101 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5238 - accuracy: 0.7764 - val_loss: 0.5057 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7764 - val_loss: 0.5063 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5024 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7764 - val_loss: 0.5071 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5219 - accuracy: 0.7764 - val_loss: 0.5017 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5231 - accuracy: 0.7764 - val_loss: 0.5003 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5012 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5012 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5044 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5262 - accuracy: 0.7764 - val_loss: 0.5032 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5186 - accuracy: 0.7764 - val_loss: 0.5021 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5044 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7764 - val_loss: 0.5030 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5222 - accuracy: 0.7764 - val_loss: 0.5043 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5046 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5192 - accuracy: 0.7764 - val_loss: 0.4973 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5205 - accuracy: 0.7764 - val_loss: 0.5001 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5166 - accuracy: 0.7764 - val_loss: 0.4949 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.7764 - val_loss: 0.4922 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5255 - accuracy: 0.7764 - val_loss: 0.5013 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5190 - accuracy: 0.7764 - val_loss: 0.4968 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5184 - accuracy: 0.7764 - val_loss: 0.4996 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5183 - accuracy: 0.7764 - val_loss: 0.4951 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5229 - accuracy: 0.7764 - val_loss: 0.4970 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5173 - accuracy: 0.7764 - val_loss: 0.4943 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5089 - accuracy: 0.7754 - val_loss: 0.4916 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5227 - accuracy: 0.7764 - val_loss: 0.5000 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.6364 - accuracy: 0.6904 - val_loss: 0.5179 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5651 - accuracy: 0.7656 - val_loss: 0.5203 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5655 - accuracy: 0.7725 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5628 - accuracy: 0.7734 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5509 - accuracy: 0.7754 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5358 - accuracy: 0.7744 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.7754 - val_loss: 0.5291 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5431 - accuracy: 0.7773 - val_loss: 0.5233 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5264 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5473 - accuracy: 0.7764 - val_loss: 0.5244 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.7764 - val_loss: 0.5232 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5380 - accuracy: 0.7764 - val_loss: 0.5252 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5404 - accuracy: 0.7764 - val_loss: 0.5242 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7764 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7764 - val_loss: 0.5246 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7764 - val_loss: 0.5231 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7764 - val_loss: 0.5235 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7764 - val_loss: 0.5234 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5380 - accuracy: 0.7764 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5194 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5380 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5311 - accuracy: 0.7764 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.7764 - val_loss: 0.5188 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.7764 - val_loss: 0.5179 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5297 - accuracy: 0.7764 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5294 - accuracy: 0.7764 - val_loss: 0.5144 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5176 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5317 - accuracy: 0.7764 - val_loss: 0.5169 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5310 - accuracy: 0.7764 - val_loss: 0.5210 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5277 - accuracy: 0.7764 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.7764 - val_loss: 0.5147 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5183 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5267 - accuracy: 0.7764 - val_loss: 0.5074 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5238 - accuracy: 0.7764 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.7764 - val_loss: 0.5056 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5227 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.7764 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5209 - accuracy: 0.7764 - val_loss: 0.5057 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.7764 - val_loss: 0.5041 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5216 - accuracy: 0.7764 - val_loss: 0.5055 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5222 - accuracy: 0.7764 - val_loss: 0.5035 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5288 - accuracy: 0.7764 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7764 - val_loss: 0.5056 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5140 - accuracy: 0.7764 - val_loss: 0.5054 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5218 - accuracy: 0.7764 - val_loss: 0.5074 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5176 - accuracy: 0.7764 - val_loss: 0.5035 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5173 - accuracy: 0.7764 - val_loss: 0.5064 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5170 - accuracy: 0.7764 - val_loss: 0.5008 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5183 - accuracy: 0.7764 - val_loss: 0.5045 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7764 - val_loss: 0.5053 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 20ms/step - loss: 0.6053 - accuracy: 0.6855 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5675 - accuracy: 0.7695 - val_loss: 0.5097 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7754 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5471 - accuracy: 0.7734 - val_loss: 0.5122 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7725 - val_loss: 0.5118 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5611 - accuracy: 0.7764 - val_loss: 0.5146 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7754 - val_loss: 0.5095 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5464 - accuracy: 0.7764 - val_loss: 0.5116 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7744 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5137 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5406 - accuracy: 0.7764 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7764 - val_loss: 0.5101 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5442 - accuracy: 0.7764 - val_loss: 0.5106 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5126 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5094 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5400 - accuracy: 0.7764 - val_loss: 0.5134 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5282 - accuracy: 0.7764 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5375 - accuracy: 0.7764 - val_loss: 0.5106 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5401 - accuracy: 0.7764 - val_loss: 0.5113 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5352 - accuracy: 0.7764 - val_loss: 0.5131 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5300 - accuracy: 0.7764 - val_loss: 0.5115 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.7764 - val_loss: 0.5110 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.7764 - val_loss: 0.5099 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5243 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7764 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7764 - val_loss: 0.5108 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5295 - accuracy: 0.7764 - val_loss: 0.5120 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7764 - val_loss: 0.5109 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7764 - val_loss: 0.5144 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5324 - accuracy: 0.7764 - val_loss: 0.5115 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5265 - accuracy: 0.7764 - val_loss: 0.5104 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7764 - val_loss: 0.5126 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5353 - accuracy: 0.7764 - val_loss: 0.5110 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7764 - val_loss: 0.5115 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7764 - val_loss: 0.5115 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5256 - accuracy: 0.7764 - val_loss: 0.5086 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5325 - accuracy: 0.7764 - val_loss: 0.5112 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5247 - accuracy: 0.7764 - val_loss: 0.5091 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5128 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5262 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 4s 32ms/step - loss: 0.5941 - accuracy: 0.7383 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5677 - accuracy: 0.7744 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5644 - accuracy: 0.7764 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5504 - accuracy: 0.7725 - val_loss: 0.5268 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5445 - accuracy: 0.7764 - val_loss: 0.5256 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5402 - accuracy: 0.7773 - val_loss: 0.5213 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5527 - accuracy: 0.7744 - val_loss: 0.5262 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5517 - accuracy: 0.7773 - val_loss: 0.5273 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5440 - accuracy: 0.7764 - val_loss: 0.5231 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5361 - accuracy: 0.7783 - val_loss: 0.5237 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5451 - accuracy: 0.7764 - val_loss: 0.5274 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7764 - val_loss: 0.5291 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5375 - accuracy: 0.7764 - val_loss: 0.5265 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.7764 - val_loss: 0.5273 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5310 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7764 - val_loss: 0.5271 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7764 - val_loss: 0.5256 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.7764 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5338 - accuracy: 0.7764 - val_loss: 0.5257 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5260 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5385 - accuracy: 0.7764 - val_loss: 0.5226 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5447 - accuracy: 0.7764 - val_loss: 0.5247 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7764 - val_loss: 0.5270 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5281 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5269 - accuracy: 0.7764 - val_loss: 0.5242 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5299 - accuracy: 0.7764 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7764 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7764 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7764 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5319 - accuracy: 0.7764 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5246 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5350 - accuracy: 0.7764 - val_loss: 0.5251 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5363 - accuracy: 0.7764 - val_loss: 0.5238 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5328 - accuracy: 0.7764 - val_loss: 0.5238 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5333 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5245 - accuracy: 0.7764 - val_loss: 0.5216 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5352 - accuracy: 0.7764 - val_loss: 0.5232 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7764 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7764 - val_loss: 0.5228 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5315 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7764 - val_loss: 0.5241 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5363 - accuracy: 0.7764 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5345 - accuracy: 0.7764 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5203 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5203 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5361 - accuracy: 0.7764 - val_loss: 0.5199 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 30ms/step - loss: 0.5939 - accuracy: 0.7197 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5697 - accuracy: 0.7744 - val_loss: 0.5178 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5613 - accuracy: 0.7705 - val_loss: 0.5172 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5434 - accuracy: 0.7695 - val_loss: 0.5190 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5595 - accuracy: 0.7754 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5490 - accuracy: 0.7725 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5412 - accuracy: 0.7754 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5339 - accuracy: 0.7764 - val_loss: 0.5152 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5338 - accuracy: 0.7754 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5367 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5420 - accuracy: 0.7764 - val_loss: 0.5130 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5353 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7754 - val_loss: 0.5109 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5319 - accuracy: 0.7764 - val_loss: 0.5098 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5351 - accuracy: 0.7764 - val_loss: 0.5130 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5101 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5233 - accuracy: 0.7764 - val_loss: 0.5071 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.7764 - val_loss: 0.5061 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.7764 - val_loss: 0.5079 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5313 - accuracy: 0.7764 - val_loss: 0.5098 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5202 - accuracy: 0.7764 - val_loss: 0.5059 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5243 - accuracy: 0.7764 - val_loss: 0.5056 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5063 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5187 - accuracy: 0.7764 - val_loss: 0.5087 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5151 - accuracy: 0.7764 - val_loss: 0.5090 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5245 - accuracy: 0.7754 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5252 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7764 - val_loss: 0.5088 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7764 - val_loss: 0.5076 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5163 - accuracy: 0.7764 - val_loss: 0.5069 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5120 - accuracy: 0.7764 - val_loss: 0.5082 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5223 - accuracy: 0.7764 - val_loss: 0.5081 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5176 - accuracy: 0.7764 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7764 - val_loss: 0.5109 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5142 - accuracy: 0.7764 - val_loss: 0.5060 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.7764 - val_loss: 0.5085 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5167 - accuracy: 0.7764 - val_loss: 0.5070 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5141 - accuracy: 0.7764 - val_loss: 0.5075 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5140 - accuracy: 0.7764 - val_loss: 0.5097 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5132 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5104 - accuracy: 0.7764 - val_loss: 0.5077 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5099 - accuracy: 0.7764 - val_loss: 0.5094 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5066 - accuracy: 0.7764 - val_loss: 0.5096 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.7764 - val_loss: 0.5087 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5136 - accuracy: 0.7764 - val_loss: 0.5101 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.7764 - val_loss: 0.5092 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.6036 - accuracy: 0.7119 - val_loss: 0.5202 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5671 - accuracy: 0.7754 - val_loss: 0.5202 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5536 - accuracy: 0.7744 - val_loss: 0.5229 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5580 - accuracy: 0.7715 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5544 - accuracy: 0.7744 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5541 - accuracy: 0.7764 - val_loss: 0.5296 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5460 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5449 - accuracy: 0.7754 - val_loss: 0.5231 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5427 - accuracy: 0.7764 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5366 - accuracy: 0.7764 - val_loss: 0.5223 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5464 - accuracy: 0.7764 - val_loss: 0.5244 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5269 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5350 - accuracy: 0.7764 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5370 - accuracy: 0.7764 - val_loss: 0.5209 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7764 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.5294 - accuracy: 0.7764 - val_loss: 0.5232 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.5347 - accuracy: 0.7764 - val_loss: 0.5269 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5180 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5249 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5201 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5274 - accuracy: 0.7764 - val_loss: 0.5222 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5241 - accuracy: 0.7764 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5268 - accuracy: 0.7764 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5235 - accuracy: 0.7764 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5192 - accuracy: 0.7764 - val_loss: 0.5169 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5128 - accuracy: 0.7764 - val_loss: 0.5146 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5181 - accuracy: 0.7764 - val_loss: 0.5188 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5287 - accuracy: 0.7764 - val_loss: 0.5222 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5186 - accuracy: 0.7764 - val_loss: 0.5158 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5288 - accuracy: 0.7764 - val_loss: 0.5314 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5264 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5210 - accuracy: 0.7764 - val_loss: 0.5185 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5140 - accuracy: 0.7764 - val_loss: 0.5196 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5180 - accuracy: 0.7764 - val_loss: 0.5152 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5161 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5202 - accuracy: 0.7754 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5231 - accuracy: 0.7764 - val_loss: 0.5184 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5178 - accuracy: 0.7764 - val_loss: 0.5129 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5198 - accuracy: 0.7764 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5185 - accuracy: 0.7764 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.7764 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5158 - accuracy: 0.7764 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5129 - accuracy: 0.7764 - val_loss: 0.5143 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5074 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5149 - accuracy: 0.7764 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5096 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5095 - accuracy: 0.7764 - val_loss: 0.5174 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5200 - accuracy: 0.7764 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5152 - accuracy: 0.7764 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 22ms/step - loss: 0.6044 - accuracy: 0.7061 - val_loss: 0.5258 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5660 - accuracy: 0.7695 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5500 - accuracy: 0.7744 - val_loss: 0.5244 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5600 - accuracy: 0.7725 - val_loss: 0.5269 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5522 - accuracy: 0.7754 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5363 - accuracy: 0.7754 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5472 - accuracy: 0.7764 - val_loss: 0.5279 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5433 - accuracy: 0.7764 - val_loss: 0.5281 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5447 - accuracy: 0.7754 - val_loss: 0.5286 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7773 - val_loss: 0.5270 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5450 - accuracy: 0.7764 - val_loss: 0.5272 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5256 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.7764 - val_loss: 0.5260 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5400 - accuracy: 0.7764 - val_loss: 0.5274 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5364 - accuracy: 0.7764 - val_loss: 0.5246 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5382 - accuracy: 0.7764 - val_loss: 0.5275 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5324 - accuracy: 0.7764 - val_loss: 0.5234 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7764 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5230 - accuracy: 0.7764 - val_loss: 0.5238 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7764 - val_loss: 0.5247 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7764 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5356 - accuracy: 0.7764 - val_loss: 0.5233 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5277 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5350 - accuracy: 0.7764 - val_loss: 0.5258 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5369 - accuracy: 0.7764 - val_loss: 0.5251 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5335 - accuracy: 0.7764 - val_loss: 0.5237 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5305 - accuracy: 0.7764 - val_loss: 0.5234 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5365 - accuracy: 0.7764 - val_loss: 0.5265 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5235 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5376 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5286 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5356 - accuracy: 0.7764 - val_loss: 0.5247 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5351 - accuracy: 0.7764 - val_loss: 0.5208 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7764 - val_loss: 0.5208 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5213 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5336 - accuracy: 0.7764 - val_loss: 0.5215 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5382 - accuracy: 0.7764 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5226 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5389 - accuracy: 0.7764 - val_loss: 0.5214 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5294 - accuracy: 0.7764 - val_loss: 0.5195 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5371 - accuracy: 0.7764 - val_loss: 0.5214 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5200 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.7764 - val_loss: 0.5220 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5300 - accuracy: 0.7764 - val_loss: 0.5202 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5330 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5325 - accuracy: 0.7764 - val_loss: 0.5211 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5218 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 5s 27ms/step - loss: 0.5965 - accuracy: 0.7314 - val_loss: 0.5283 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5751 - accuracy: 0.7764 - val_loss: 0.5263 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5480 - accuracy: 0.7773 - val_loss: 0.5260 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7764 - val_loss: 0.5283 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5540 - accuracy: 0.7764 - val_loss: 0.5263 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7764 - val_loss: 0.5287 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5450 - accuracy: 0.7764 - val_loss: 0.5278 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5393 - accuracy: 0.7764 - val_loss: 0.5312 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5366 - accuracy: 0.7764 - val_loss: 0.5300 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5371 - accuracy: 0.7764 - val_loss: 0.5310 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5442 - accuracy: 0.7764 - val_loss: 0.5310 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5385 - accuracy: 0.7764 - val_loss: 0.5300 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5378 - accuracy: 0.7764 - val_loss: 0.5297 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7764 - val_loss: 0.5274 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7764 - val_loss: 0.5277 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5293 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5352 - accuracy: 0.7764 - val_loss: 0.5262 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5335 - accuracy: 0.7764 - val_loss: 0.5291 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7764 - val_loss: 0.5289 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5360 - accuracy: 0.7764 - val_loss: 0.5266 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7764 - val_loss: 0.5257 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.7764 - val_loss: 0.5300 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7764 - val_loss: 0.5251 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7764 - val_loss: 0.5292 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5353 - accuracy: 0.7764 - val_loss: 0.5275 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5358 - accuracy: 0.7764 - val_loss: 0.5282 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5323 - accuracy: 0.7764 - val_loss: 0.5271 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5372 - accuracy: 0.7764 - val_loss: 0.5257 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5253 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5268 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5344 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5354 - accuracy: 0.7764 - val_loss: 0.5294 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5354 - accuracy: 0.7764 - val_loss: 0.5244 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5269 - accuracy: 0.7764 - val_loss: 0.5240 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5220 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5261 - accuracy: 0.7764 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5300 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5268 - accuracy: 0.7764 - val_loss: 0.5246 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5300 - accuracy: 0.7764 - val_loss: 0.5253 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5311 - accuracy: 0.7764 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5205 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5229 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5307 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5231 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5262 - accuracy: 0.7764 - val_loss: 0.5213 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5275 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7930\n",
            "        frontal   central  parietal  occipital\n",
            "theta  0.792969  0.792969  0.792969   0.792969\n",
            "alpha  0.792969  0.792969  0.792969   0.792969\n",
            "beta   0.792969  0.792969  0.792969   0.792969\n",
            "gamma  0.792969  0.792969  0.792969   0.792969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY9uqQzbv46q"
      },
      "outputs": [],
      "source": [
        "# print the confusion matrix which gives the highest accuracy\n",
        "print_conf(\"theta\",\"parietal\",\"arousal\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHUBype4mFY6"
      },
      "outputs": [],
      "source": [
        "print_accuracy('valence', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv3oLNIVGCSf"
      },
      "outputs": [],
      "source": [
        "print_conf(\"gamma\",\"central\",\"valence\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoKgtLNEpU-v"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'ab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcqO8QBLHR7q"
      },
      "outputs": [],
      "source": [
        "print_conf(\"gamma\",\"occipital\",\"arousal\",\"ab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1za3TrVphgH"
      },
      "outputs": [],
      "source": [
        "print_accuracy('valence', 'ab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DPjYGhArgcr"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'xgb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYrfmtLwrmES"
      },
      "outputs": [],
      "source": [
        "print_accuracy('valence', 'xgb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_wzHU40YhWY"
      },
      "outputs": [],
      "source": [
        "print_conf(\"beta\",\"central\",\"valence\",\"xgb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3qH1vs2J5rC"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'knn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x84JhQCIKciv"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LALV', 'knn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XXLSSWWl9kI"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HALV', 'knn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4WnM3ismDzw"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LAHV', 'knn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXS8oiqJKknT"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'dtree')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPn1ljyNKtr4"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LALV', 'dtree')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zS_EF8dRKyLm"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'rf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luDd1AY6mjqs"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LAHV', 'rf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNTGFHQOK14l"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HALV', 'rf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhGLn0G4_l8E"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LALV', 'rf')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy('HAHV', 'cnn')"
      ],
      "metadata": {
        "id": "lkL0I6x7PY-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkmagqFfK54a"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HALV', 'cnn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV3gnYCKK-cA"
      },
      "outputs": [],
      "source": [
        "print_accuracy('valence', 'nb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02_ynnQ1LEoz"
      },
      "outputs": [],
      "source": [
        "print_accuracy('arousal', 'mlp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuwCpDS1LHAx"
      },
      "outputs": [],
      "source": [
        "print_accuracy('valence', 'mlp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAvwS8OmOkX6"
      },
      "outputs": [],
      "source": [
        "print_accuracy('arousal', 'lgbm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIwlFJ7nOyFX"
      },
      "outputs": [],
      "source": [
        "print_accuracy('valence', 'lgbm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBw1c8r9O6s5"
      },
      "outputs": [],
      "source": [
        "print_accuracy('arousal', 'gpc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mBzYOJwO-Tc"
      },
      "outputs": [],
      "source": [
        "print_accuracy('valence', 'gpc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_tYtr1vPEwA"
      },
      "outputs": [],
      "source": [
        "print_accuracy('arousal', 'per')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz0L94FJPKCx"
      },
      "outputs": [],
      "source": [
        "print_accuracy('valence', 'per')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPkBIcPtPTXf"
      },
      "outputs": [],
      "source": [
        "print_accuracy('arousal', 'cb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al5LA0spYBqU"
      },
      "outputs": [],
      "source": [
        "print_conf(\"gamma\",\"frontal\",\"arousal\",\"cb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LB1NnMQQcTD"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'cb')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}