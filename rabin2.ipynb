{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RabinSharma25/emotion-classification-using-eeg-signals/blob/main/rabin2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pwwbhMy0pssx"
      },
      "outputs": [],
      "source": [
        "#import the required libraries\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "#for feature extraction\n",
        "from scipy.signal import welch\n",
        "from scipy.integrate import simps\n",
        "\n",
        "#classifier libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7ZUAXilSp_n9"
      },
      "outputs": [],
      "source": [
        "def read_data(filename):\n",
        "    x = pickle._Unpickler(open(filename, 'rb'))\n",
        "    x.encoding = 'latin1'\n",
        "    p = x.load()\n",
        "    return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYK5hgFMqFNy",
        "outputId": "b8f829f3-ef8d-4419-f5ef-8919d24a8579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['s01.dat', 's02.dat', 's03.dat', 's04.dat', 's05.dat', 's06.dat', 's07.dat', 's08.dat', 's09.dat', 's10.dat', 's11.dat', 's12.dat', 's13.dat', 's14.dat', 's15.dat', 's16.dat', 's17.dat', 's18.dat', 's19.dat', 's20.dat', 's21.dat', 's22.dat', 's23.dat', 's24.dat', 's25.dat', 's26.dat', 's27.dat', 's28.dat', 's29.dat', 's30.dat', 's31.dat', 's32.dat']\n"
          ]
        }
      ],
      "source": [
        "#creating the file names of the dataset to load it\n",
        "files = []\n",
        "for n in range (1, 33):\n",
        "    s = 's'\n",
        "    if n < 10:\n",
        "        s += '0'\n",
        "    s += str(n)\n",
        "    s+=str(\".dat\")\n",
        "    files.append(s)\n",
        "print(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ru2cxT3qrtI",
        "outputId": "15e3beaa-38ef-4d0a-8ecb-b6357369af2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 32x40 = 1280 trials for 32 participants\n",
        "labels = []\n",
        "data = []\n",
        "drive.mount('/content/drive')\n",
        "for i in files:\n",
        "  filename = \"/content/drive/My Drive/major-project/major-project-dataset/\" + i\n",
        "  trial = read_data(filename)\n",
        "  labels.append(trial['labels'])\n",
        "  data.append(trial['data'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwIUirXzuY_3",
        "outputId": "33ff46bf-5f71-47fe-b145-d649a9ce9fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels:  (32, 40, 4)\n",
            "Data:  (32, 40, 40, 8064)\n"
          ]
        }
      ],
      "source": [
        "# Lets see the shapes of the raw data\n",
        "labels = np.array(labels)\n",
        "data = np.array(data)\n",
        "print(\"Labels: \", labels.shape) # participants x videos x labels\n",
        "print(\"Data: \", data.shape) # participants x videos x channels x data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6JhtYReeudzh"
      },
      "outputs": [],
      "source": [
        "# Re-shape arrays into desired shapes\n",
        "labels = labels.flatten()\n",
        "labels = labels.reshape(1280, 4)\n",
        "\n",
        "data = data.flatten()\n",
        "data = data.reshape(1280, 40, 8064)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw4kk4WasX14",
        "outputId": "72b7ef05-e634-47fd-d568-91c29d786157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels:  (1280, 4)\n",
            "Data:  (1280, 40, 8064)\n"
          ]
        }
      ],
      "source": [
        "# Double-check the new arrays\n",
        "#Here trial = participants x vidoes = 32 x 40 = 1280\n",
        "\n",
        "print(\"Labels: \", labels.shape) # trial x label\n",
        "print(\"Data: \", data.shape) # trial x channel x data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "puNQxQcOx0Gq",
        "outputId": "7fb081e9-739c-4b0b-b7b7-565a2df2cdd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "printing the labels dataframe\n",
            "\n",
            "         0     1     2     3\n",
            "0     7.71  7.60  6.90  7.83\n",
            "1     8.10  7.31  7.28  8.47\n",
            "2     8.58  7.54  9.00  7.08\n",
            "3     4.94  6.01  6.12  8.06\n",
            "4     6.96  3.92  7.19  6.05\n",
            "...    ...   ...   ...   ...\n",
            "1275  3.91  6.96  5.82  3.12\n",
            "1276  2.81  6.13  6.06  1.04\n",
            "1277  3.05  7.01  5.10  1.10\n",
            "1278  3.99  7.17  4.85  1.00\n",
            "1279  7.15  4.03  9.00  1.88\n",
            "\n",
            "[1280 rows x 4 columns]\n",
            "\n",
            "\n",
            "Describing the labels dataframe\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0            1            2            3\n",
              "count  1280.000000  1280.000000  1280.000000  1280.000000\n",
              "mean      5.254313     5.156711     5.382750     5.518133\n",
              "std       2.130816     2.020499     2.096321     2.282780\n",
              "min       1.000000     1.000000     1.000000     1.000000\n",
              "25%       3.867500     3.762500     3.932500     3.960000\n",
              "50%       5.040000     5.230000     5.240000     6.050000\n",
              "75%       7.050000     6.950000     7.040000     7.090000\n",
              "max       9.000000     9.000000     9.000000     9.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3791643-046a-4c5c-ac9f-4f6061e1489f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1280.000000</td>\n",
              "      <td>1280.000000</td>\n",
              "      <td>1280.000000</td>\n",
              "      <td>1280.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.254313</td>\n",
              "      <td>5.156711</td>\n",
              "      <td>5.382750</td>\n",
              "      <td>5.518133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.130816</td>\n",
              "      <td>2.020499</td>\n",
              "      <td>2.096321</td>\n",
              "      <td>2.282780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.867500</td>\n",
              "      <td>3.762500</td>\n",
              "      <td>3.932500</td>\n",
              "      <td>3.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.040000</td>\n",
              "      <td>5.230000</td>\n",
              "      <td>5.240000</td>\n",
              "      <td>6.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.050000</td>\n",
              "      <td>6.950000</td>\n",
              "      <td>7.040000</td>\n",
              "      <td>7.090000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3791643-046a-4c5c-ac9f-4f6061e1489f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a3791643-046a-4c5c-ac9f-4f6061e1489f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a3791643-046a-4c5c-ac9f-4f6061e1489f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c5ddb4f9-64b7-4bd7-8a89-60b797b681cf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c5ddb4f9-64b7-4bd7-8a89-60b797b681cf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c5ddb4f9-64b7-4bd7-8a89-60b797b681cf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"labelsDf\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.87147400594165,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.2543125,\n          5.04,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.88279505775586,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.1567109375,\n          5.23,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.85389766830843,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.38275,\n          5.24,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.79289858765816,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.5181328125,\n          6.05,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#creating the dataframes for the labels\n",
        "labelsDf = pd.DataFrame(labels)\n",
        "print(\"printing the labels dataframe\\n\")\n",
        "print(labelsDf)\n",
        "print(\"\\n\\nDescribing the labels dataframe\")\n",
        "labelsDf.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SGS2ghM3uYC",
        "outputId": "ef434b1b-86c2-42aa-f446-e1d44c05f883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 0            1            2            3\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000\n",
            "mean      5.254313     5.156711     5.382750     5.518133\n",
            "std       2.130816     2.020499     2.096321     2.282780\n",
            "min       1.000000     1.000000     1.000000     1.000000\n",
            "25%       3.867500     3.762500     3.932500     3.960000\n",
            "50%       5.040000     5.230000     5.240000     6.050000\n",
            "75%       7.050000     6.950000     7.040000     7.090000\n",
            "max       9.000000     9.000000     9.000000     9.000000\n"
          ]
        }
      ],
      "source": [
        "#giving names to the label columns\n",
        "df_labels= pd.DataFrame({'valence': labels[:,0], 'arousal': labels[:,1], 'dominance': labels[:,2], 'liking': labels[:,3]})\n",
        "print(labelsDf.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3boVQ1FE4var",
        "outputId": "6b492975-5e48-4100-fb60-4a5bdc15f109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      valence  arousal\n",
            "0        7.71     7.60\n",
            "1        8.10     7.31\n",
            "2        8.58     7.54\n",
            "3        4.94     6.01\n",
            "4        6.96     3.92\n",
            "...       ...      ...\n",
            "1275     3.91     6.96\n",
            "1276     2.81     6.13\n",
            "1277     3.05     7.01\n",
            "1278     3.99     7.17\n",
            "1279     7.15     4.03\n",
            "\n",
            "[1280 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "#Dropping the Dominance and Liking columns\n",
        "df_labels=df_labels.drop('dominance',axis=1)\n",
        "df_labels=df_labels.drop('liking',axis=1)\n",
        "# print(df_labels.describe())\n",
        "print(df_labels)\n",
        "# df = df.drop('B', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pet3Pska6SDA"
      },
      "source": [
        "# Separte Valence and Arousal to HAHV, LAHV, HALV, LALV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhIWzOBq6QSq",
        "outputId": "ee875919-d6b2-406a-9b49-7982211561c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.23\n",
            "5.04\n",
            "      HAHV  LAHV  HALV  LALV\n",
            "0        1     0     0     0\n",
            "1        1     0     0     0\n",
            "2        1     0     0     0\n",
            "3        0     0     1     0\n",
            "4        0     1     0     0\n",
            "...    ...   ...   ...   ...\n",
            "1275     0     0     1     0\n",
            "1276     0     0     1     0\n",
            "1277     0     0     1     0\n",
            "1278     0     0     1     0\n",
            "1279     0     1     0     0\n",
            "\n",
            "[1280 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# # Create a sample DataFrame with 'valence' and 'arousal' columns\n",
        "# np.random.seed(0)\n",
        "# valence = np.random.uniform(1, 9, 1280)\n",
        "# arousal = np.random.uniform(1, 9, 1280)\n",
        "# data = {'valence': valence, 'arousal': arousal}\n",
        "# df_valence_arousal = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the median value of arousal and valence column\n",
        "arousal_median = df_labels['arousal'].median()\n",
        "print(arousal_median)\n",
        "valence_median = df_labels['valence'].median()\n",
        "print(valence_median)\n",
        "\n",
        "# Create a new DataFrame with the desired columns\n",
        "df_result = pd.DataFrame(index=range(1280), columns=['HAHV', 'LAHV', 'HALV', 'LALV'])\n",
        "df_result[['HAHV', 'LAHV', 'HALV', 'LALV']] = 0\n",
        "\n",
        "# Apply the conditions\n",
        "df_result.loc[(df_labels['valence'] >= valence_median) & (df_labels['arousal'] >= arousal_median), 'HAHV'] = 1\n",
        "df_result.loc[(df_labels['arousal'] < arousal_median) & (df_labels['valence'] >= valence_median), 'LAHV'] = 1\n",
        "df_result.loc[(df_labels['arousal'] >= arousal_median) & (df_labels['valence'] < valence_median), 'HALV'] = 1\n",
        "df_result.loc[(df_labels['valence'] < valence_median) & (df_labels['arousal'] < arousal_median), 'LALV'] = 1\n",
        "\n",
        "# Show the first few rows of the result DataFrame\n",
        "# df_result.tail()\n",
        "print(df_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcYaudZZDylG"
      },
      "source": [
        "Verify the data in 4 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tc9aAzbD7U3",
        "outputId": "0d1aac5f-ce93-4648-c8ca-e96e7a988b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of 1s in HAHV: 358\n",
            "Number of 1s in LAHV: 322\n",
            "Number of 1s in HALV: 282\n",
            "Number of 1s in LALV: 318\n",
            "Total = 1280\n"
          ]
        }
      ],
      "source": [
        "# Check the number of 1s in each individual column\n",
        "count_HAHV = df_result['HAHV'].sum()\n",
        "count_LAHV = df_result['LAHV'].sum()\n",
        "count_HALV = df_result['HALV'].sum()\n",
        "count_LALV = df_result['LALV'].sum()\n",
        "\n",
        "print(f\"Number of 1s in HAHV: {count_HAHV}\")\n",
        "print(f\"Number of 1s in LAHV: {count_LAHV}\")\n",
        "print(f\"Number of 1s in HALV: {count_HALV}\")\n",
        "print(f\"Number of 1s in LALV: {count_LALV}\")\n",
        "\n",
        "print(f\"Total = {count_HAHV+count_LAHV+count_HALV+count_LALV}\") # the total must be 1280\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Pjhzu_pQlWDv"
      },
      "outputs": [],
      "source": [
        "# Dataset with only Valence column\n",
        "df_val = df_labels['valence']\n",
        "# Dataset with only Arousal column\n",
        "df_aro = df_labels['arousal']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "u8H4KOWLll-C"
      },
      "outputs": [],
      "source": [
        "# Function to check if each trial has positive or negative valence\n",
        "def positive_valence(trial):\n",
        "    return 1 if labels[trial,0] >= np.median(labels[:,0]) else 0\n",
        "# Function to check if each trial has high or low arousal\n",
        "def high_arousal(trial):\n",
        "    return 1 if labels[trial,1] >= np.median(labels[:,1]) else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37Gsz-Z_lp_2",
        "outputId": "09f9877b-bd1d-49ca-f4b9-5ee7a9e4dc7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       High Valence  High Arousal\n",
            "count   1280.000000   1280.000000\n",
            "mean       0.531250      0.500000\n",
            "std        0.499218      0.500195\n",
            "min        0.000000      0.000000\n",
            "25%        0.000000      0.000000\n",
            "50%        1.000000      0.500000\n",
            "75%        1.000000      1.000000\n",
            "max        1.000000      1.000000\n",
            "      High Valence  High Arousal\n",
            "0                1             1\n",
            "1                1             1\n",
            "2                1             1\n",
            "3                0             1\n",
            "4                1             0\n",
            "...            ...           ...\n",
            "1275             0             1\n",
            "1276             0             1\n",
            "1277             0             1\n",
            "1278             0             1\n",
            "1279             1             0\n",
            "\n",
            "[1280 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Convert all ratings to boolean values\n",
        "labels_encoded = []\n",
        "for i in range (len(labels)):\n",
        "    labels_encoded.append([positive_valence(i), high_arousal(i)])\n",
        "labels_encoded = np.reshape(labels_encoded, (1280, 2))\n",
        "df_labels = pd.DataFrame(data=labels_encoded, columns=[\"High Valence\", \"High Arousal\"])\n",
        "print(df_labels.describe())\n",
        "print(df_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BrMAjqult5R",
        "outputId": "e1a4dfb9-2859-4072-c231-d18a9ddd89ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       0\n",
            "4       1\n",
            "       ..\n",
            "1275    0\n",
            "1276    0\n",
            "1277    0\n",
            "1278    0\n",
            "1279    1\n",
            "Name: High Valence, Length: 1280, dtype: int64\n",
            "(1280,)\n"
          ]
        }
      ],
      "source": [
        "# Dataset with only Valence column\n",
        "df_valence = df_labels['High Valence']\n",
        "# Dataset with only Arousal column\n",
        "df_arousal = df_labels['High Arousal']\n",
        "print(df_valence)\n",
        "print(df_valence.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh0IevZcnKtX"
      },
      "source": [
        "# FEATURE EXTRACTION USING WELCH'S METHOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QGtC7nRipvA8"
      },
      "outputs": [],
      "source": [
        "eeg_channels = np.array([\"Fp1\", \"AF3\", \"F3\", \"F7\", \"FC5\", \"FC1\", \"C3\", \"T7\", \"CP5\", \"CP1\", \"P3\", \"P7\", \"PO3\", \"O1\", \"Oz\", \"Pz\", \"Fp2\", \"AF4\", \"Fz\", \"F4\", \"F8\", \"FC6\", \"FC2\", \"Cz\", \"C4\", \"T8\", \"CP6\", \"CP2\", \"P4\", \"P8\", \"PO4\", \"O2\"])\n",
        "peripheral_channels = np.array([\"hEOG\", \"vEOG\", \"zEMG\", \"tEMG\", \"GSR\", \"Respiration belt\", \"Plethysmograph\", \"Temperature\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyC_7IWLp93t",
        "outputId": "18d4954c-d0c7-42a0-880f-7351d5a8a2ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1280, 32, 8064)\n"
          ]
        }
      ],
      "source": [
        "eeg_data = []\n",
        "for i in range (len(data)):\n",
        "  for j in range (len(eeg_channels)):\n",
        "    eeg_data.append(data[i,j])\n",
        "eeg_data = np.reshape(eeg_data, (len(data), len(eeg_channels), len(data[0,0])))\n",
        "print(eeg_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5P3G0PWqEsM",
        "outputId": "17e79bf5-9446-4dd7-b2fd-622e504176de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1280, 8, 8064)\n"
          ]
        }
      ],
      "source": [
        "peripheral_data = []\n",
        "for i in range (len(data)):\n",
        "  for j in range (32,len(data[0])):\n",
        "    peripheral_data.append(data[i,j])\n",
        "peripheral_data = np.reshape(peripheral_data, (len(data), len(peripheral_channels), len(data[0,0])))\n",
        "print(peripheral_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Xc9rTRGHnYKt"
      },
      "outputs": [],
      "source": [
        "def bandpower(data, sf, band, window_sec=None, relative=False):\n",
        "    band = np.asarray(band)\n",
        "    low, high = band\n",
        "\n",
        "    # Define window length\n",
        "    if window_sec is not None:\n",
        "        nperseg = window_sec * sf\n",
        "    else:\n",
        "        nperseg = (2 / low) * sf\n",
        "\n",
        "    # Compute the modified periodogram (Welch)\n",
        "    freqs, psd = welch(data, sf, nperseg=nperseg)\n",
        "\n",
        "    # Frequency resolution\n",
        "    freq_res = freqs[1] - freqs[0]\n",
        "\n",
        "    # Find closest indices of band in frequency vector\n",
        "    idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
        "\n",
        "    # Integral approximation of the spectrum using Simpson's rule.\n",
        "    bp = simps(psd[idx_band], dx=freq_res)\n",
        "\n",
        "    if relative:\n",
        "        bp /= simps(psd, dx=freq_res)\n",
        "    return bp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mIxttAuQnrel"
      },
      "outputs": [],
      "source": [
        "def get_band_power(trial, channel, band):\n",
        "  bd = (0,0)\n",
        "\n",
        "  if (band == \"theta\"): # drownsiness, emotional connection, intuition, creativity\n",
        "    bd = (4,8)\n",
        "  elif (band == \"alpha\"): # reflection, relaxation\n",
        "    bd = (8,12)\n",
        "  elif (band == \"beta\"): # concentration, problem solving, memory\n",
        "    bd = (12,30)\n",
        "  elif (band == \"gamma\"): # cognition, perception, learning, multi-tasking\n",
        "    bd = (30,64)\n",
        "\n",
        "  return bandpower(eeg_data[trial,channel], 128, bd)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpNyS4s8n9Q3",
        "outputId": "aa8ac9b3-b567-4354-9c8b-38d00e38774a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.434119660168186\n",
            "5.369595513295193\n",
            "6.286556266834863\n",
            "0.9879159580139809\n"
          ]
        }
      ],
      "source": [
        "print(get_band_power(0,31,\"theta\"))\n",
        "print(get_band_power(0,31,\"alpha\"))\n",
        "print(get_band_power(0,31,\"beta\"))\n",
        "print(get_band_power(0,31,\"gamma\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8psQHMB9xqpj"
      },
      "source": [
        "# Process new datasets with 6 EEG regions and 4 band power values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "r0y_hNHIxoxi"
      },
      "outputs": [],
      "source": [
        "# Transform 1280x 32 x 8064 => 1280 x 128\n",
        "eeg_band_arr = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"theta\"))\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"alpha\"))\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"beta\"))\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"gamma\"))\n",
        "eeg_band_arr = np.reshape(eeg_band_arr, (1280, 128))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "HVksA4V2ypUD"
      },
      "outputs": [],
      "source": [
        "frontal = np.array([\"F3\", \"FC1\", \"Fz\", \"F4\", \"FC2\"])\n",
        "parietal = np.array([\"P3\", \"P7\", \"Pz\", \"P4\", \"P8\"])\n",
        "occipital = np.array([\"O1\", \"Oz\", \"O2\", \"PO3\", \"PO4\"])\n",
        "central = np.array([\"CP5\", \"CP1\", \"Cz\", \"C4\", \"C3\", \"CP6\", \"CP2\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YQbtKTRzmdG",
        "outputId": "39090eda-57b9-4244-98d3-e4710c662f9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Fp1           AF3            F3            F7           FC5  \\\n",
            "count   1280.000000   1280.000000   1280.000000   1280.000000   1280.000000   \n",
            "mean     517.431002    974.493856    795.093910   1515.004071    746.435950   \n",
            "std     1165.295163   3147.555132   3020.711666   4990.544508   2188.101734   \n",
            "min        2.698928      1.995398      1.820656      3.283107      1.311200   \n",
            "25%       23.306027     17.117475     18.392335     30.827191     14.023436   \n",
            "50%       65.468048     82.102529     60.241953     91.266539     48.704968   \n",
            "75%      331.636624    304.949248    175.394835    248.308696    218.358248   \n",
            "max    15524.135098  38122.870846  39431.320394  49272.793208  20182.668545   \n",
            "\n",
            "               FC1            C3           T7           CP5          CP1  ...  \\\n",
            "count  1280.000000   1280.000000  1280.000000   1280.000000  1280.000000  ...   \n",
            "mean    345.936665    486.095113   354.004358    664.656754   276.667812  ...   \n",
            "std     717.328768   1497.636647   641.432373   2146.857585   498.823733  ...   \n",
            "min       2.025214      1.200156     3.418167      1.857737     1.340340  ...   \n",
            "25%      17.383454     18.273844    43.838157     19.178089    28.281757  ...   \n",
            "50%      55.561232     46.451432   128.629588     61.998792    60.330974  ...   \n",
            "75%     281.828747    234.342275   348.249862    312.653366   237.040645  ...   \n",
            "max    8542.244175  26021.167025  7023.985761  23255.512271  5972.589469  ...   \n",
            "\n",
            "                FC2            Cz            C4            T8           CP6  \\\n",
            "count   1280.000000   1280.000000   1280.000000   1280.000000   1280.000000   \n",
            "mean     669.953166    518.975872    471.905917    763.990397    544.785103   \n",
            "std     1714.340609   1407.210210   1896.584105   2236.655420   1563.878765   \n",
            "min        2.809501      1.637028      1.713283      2.133474      1.496299   \n",
            "25%       14.927239     23.440039      9.724978     25.143155     18.202863   \n",
            "50%       66.078472     67.044674     24.318235     90.110040     77.517763   \n",
            "75%      214.293557    305.766182    109.715681    386.232875    297.742897   \n",
            "max    18617.218099  16408.471958  24826.365142  28038.714329  19908.437378   \n",
            "\n",
            "               CP2            P4           P8           PO4            O2  \n",
            "count  1280.000000   1280.000000  1280.000000   1280.000000   1280.000000  \n",
            "mean    303.158814    527.491149   222.759444    780.700914    327.242856  \n",
            "std     650.093432   1429.084909   451.119818   1802.083002   1080.707954  \n",
            "min       1.439077      1.791296     1.641482      1.995230      3.681268  \n",
            "25%      26.754006     18.110041    18.064264     23.491991     19.333926  \n",
            "50%      88.083088     62.269206    90.914662     69.772647     49.630345  \n",
            "75%     257.959593    246.195582   225.463786    495.202699    113.117403  \n",
            "max    7210.746793  17568.065100  5487.311705  17167.017710  12314.030522  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "eeg_theta = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_theta.append(get_band_power(i,j,\"theta\"))\n",
        "eeg_theta = np.reshape(eeg_theta, (1280, 32))\n",
        "\n",
        "df_theta = pd.DataFrame(data = eeg_theta, columns=eeg_channels)\n",
        "print(df_theta.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1uT6ZlnzqL-",
        "outputId": "53d16d95-94f8-4d3c-bb98-388863e3e8c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Fp1           AF3            F3            F7          FC5  \\\n",
            "count  1280.000000   1280.000000   1280.000000   1280.000000  1280.000000   \n",
            "mean    173.544174    333.184883    285.545436    573.725974   249.793720   \n",
            "std     378.371554   1058.758333   1036.330438   1943.692827   702.436934   \n",
            "min       2.770151      1.793012      1.724442      2.793554     0.975527   \n",
            "25%      14.082681     10.737435     10.012318     15.888935    10.074042   \n",
            "50%      33.713172     34.992442     30.026795     38.178299    20.079100   \n",
            "75%     125.508396    114.334883     73.488279     93.987498    74.040939   \n",
            "max    5627.906982  12380.702125  12764.724842  20843.070851  6575.781434   \n",
            "\n",
            "               FC1           C3           T7          CP5          CP1  ...  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  ...   \n",
            "mean    138.011594   170.423962   124.101183   232.750895    97.610644  ...   \n",
            "std     275.218934   497.507620   200.171342   735.717912   166.430024  ...   \n",
            "min       1.682977     1.963403     2.545447     2.251935     1.682386  ...   \n",
            "25%       9.228670    10.197058    21.452775    11.461012    13.367379  ...   \n",
            "50%      24.929907    22.318468    51.473641    25.364340    26.229818  ...   \n",
            "75%     117.988147    83.518174   129.890552   110.822931    91.941255  ...   \n",
            "max    3030.077791  9215.549575  2142.437275  7894.273428  2148.109415  ...   \n",
            "\n",
            "               FC2           Cz            C4           T8          CP6  \\\n",
            "count  1280.000000  1280.000000   1280.000000  1280.000000  1280.000000   \n",
            "mean    228.331178   199.941306    193.380344   276.638039   213.620700   \n",
            "std     569.202821   578.947819    812.031964   782.782127   661.135030   \n",
            "min       2.390011     1.315395      1.227024     1.636114     2.181082   \n",
            "25%       8.715210    12.127290      6.665166    15.980086    11.300805   \n",
            "50%      26.880000    29.827367     14.169702    34.252038    31.722499   \n",
            "75%      95.964685   102.480314     40.800135   142.704220   106.673844   \n",
            "max    6038.451512  6881.486185  10501.570698  9022.269308  8394.200372   \n",
            "\n",
            "               CP2           P4           P8          PO4           O2  \n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  \n",
            "mean    112.138023   181.507936    89.003586   269.572920   126.053116  \n",
            "std     236.260122   482.163785   186.841170   597.330120   400.465505  \n",
            "min       1.520363     2.158950     1.212432     2.002769     3.617116  \n",
            "25%      15.797490    11.564300    10.971965    13.489443    10.548845  \n",
            "50%      37.807211    28.494994    38.758864    29.247807    23.906708  \n",
            "75%      86.070815    92.261617    88.107272   162.117585    45.294454  \n",
            "max    2368.537880  5666.733316  2323.499853  5542.263376  3966.714864  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "# Transform 880 x 32 x 8064 => 880 x 32\n",
        "eeg_alpha = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_alpha.append(get_band_power(i,j,\"alpha\"))\n",
        "eeg_alpha = np.reshape(eeg_alpha, (1280, 32))\n",
        "\n",
        "df_alpha = pd.DataFrame(data = eeg_alpha, columns=eeg_channels)\n",
        "print(df_alpha.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUNGxdRLzvAW",
        "outputId": "fa4b8184-2c2e-45f0-beed-2311b1b9da24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Fp1          AF3           F3            F7          FC5  \\\n",
            "count  1280.000000  1280.000000  1280.000000   1280.000000  1280.000000   \n",
            "mean     92.200266   200.684361   193.372441    341.951096   140.642394   \n",
            "std     176.162562   668.027842   668.771074   1274.679748   386.740178   \n",
            "min       4.486703     2.650970     2.784376      3.363422     2.788531   \n",
            "25%      17.999409    13.190613    10.170223     17.951892    11.341571   \n",
            "50%      34.413828    29.155242    28.120517     33.617573    22.402198   \n",
            "75%      80.774739   107.619088    59.807546     62.087123    53.162211   \n",
            "max    3528.485435  5784.160193  5841.475721  14848.700463  3094.687504   \n",
            "\n",
            "               FC1           C3           T7          CP5          CP1  ...  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  ...   \n",
            "mean     99.397187    96.901859    77.540922   137.387625    55.047411  ...   \n",
            "std     197.556641   247.621839    90.107877   409.366974    85.846400  ...   \n",
            "min       3.145262     2.991550     2.477519     2.886994     2.237445  ...   \n",
            "25%       8.919796     9.331138    23.668656    11.097811     9.370318  ...   \n",
            "50%      17.625226    19.698019    44.350493    22.622621    18.748879  ...   \n",
            "75%      79.066898    46.494215    93.087474    58.273844    51.308093  ...   \n",
            "max    1702.542675  5187.441594   634.645675  4094.116788  1238.024108  ...   \n",
            "\n",
            "               FC2           Cz           C4           T8          CP6  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000   \n",
            "mean    130.756212   131.961699   136.536661   178.534190   144.021213   \n",
            "std     338.843374   409.481195   603.902680   506.405387   484.806320   \n",
            "min       3.037555     1.816169     2.079646     2.429178     2.524762   \n",
            "25%       9.115906    10.803851     7.350435    17.466794    11.400277   \n",
            "50%      17.479204    25.300435    12.926731    30.157902    23.679679   \n",
            "75%      75.259937    54.745901    25.609433    93.320360    64.338413   \n",
            "max    2786.622358  4842.537927  7489.480637  4064.418656  5955.637009   \n",
            "\n",
            "               CP2           P4           P8          PO4           O2  \n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  \n",
            "mean     74.751315   103.971557    62.850280   148.868580    90.837375  \n",
            "std     165.803855   288.941591   134.177873   329.650542   275.150372  \n",
            "min       2.272088     2.914214     3.059450     2.461123     5.084168  \n",
            "25%      13.014515    11.560334    12.312069    13.732279    11.291516  \n",
            "50%      24.705624    20.439224    27.763129    23.940855    19.688820  \n",
            "75%      53.062550    67.593128    64.187473    99.947093    36.076683  \n",
            "max    1265.234960  2533.794744  1653.743590  2516.334382  2454.759737  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "# Transform 880 x 32 x 8064 => 880 x 32\n",
        "eeg_beta = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_beta.append(get_band_power(i,j,\"beta\"))\n",
        "eeg_beta = np.reshape(eeg_beta, (1280, 32))\n",
        "\n",
        "df_beta = pd.DataFrame(data = eeg_beta, columns=eeg_channels)\n",
        "print(df_beta.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJP58i-60AEV",
        "outputId": "e62d8940-6db5-477d-dee3-7f1bd1a10bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Fp1          AF3           F3           F7          FC5  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000   \n",
            "mean     50.663247   150.492372   149.210824   122.775294    91.633571   \n",
            "std     135.591365   645.635199   632.049548   496.744509   340.562025   \n",
            "min       1.069233     1.119910     0.791859     1.177512     0.712624   \n",
            "25%       8.292302     5.605668     4.352724     7.591098     5.172920   \n",
            "50%      18.329100    14.069330    11.828027    15.919877    12.648067   \n",
            "75%      39.995543    43.454610    28.586812    36.456420    38.094737   \n",
            "max    3213.255538  6060.539788  5758.756812  6348.177208  3472.515858   \n",
            "\n",
            "               FC1           C3           T7          CP5          CP1  ...  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  ...   \n",
            "mean     60.487715    56.236468    43.792285    77.048369    29.250057  ...   \n",
            "std     139.230040   180.285647    62.089299   267.809883    68.503827  ...   \n",
            "min       0.694928     0.684210     0.562676     0.788359     0.509259  ...   \n",
            "25%       2.666459     3.534375    10.492723     3.837095     3.156311  ...   \n",
            "50%       5.313502     9.056340    23.540152     9.532963     7.735783  ...   \n",
            "75%      41.027482    29.838450    54.382720    22.302862    18.604669  ...   \n",
            "max    1413.985901  4376.356658   809.935644  2294.561961  1011.985310  ...   \n",
            "\n",
            "               FC2           Cz           C4           T8          CP6  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000   \n",
            "mean     79.191679    56.547283    55.989289   117.745424    64.340498   \n",
            "std     306.464243   167.968314   239.143748   428.381018   199.387966   \n",
            "min       0.692350     0.395680     0.697486     1.027260     0.609425   \n",
            "25%       2.893590     3.800780     2.286229     7.221083     3.850387   \n",
            "50%       7.535055     8.493068     4.640151    17.921722    10.563661   \n",
            "75%      26.896601    20.882885    13.538524    39.981006    30.943717   \n",
            "max    2829.052404  1892.813293  3054.309237  3954.519861  2405.614840   \n",
            "\n",
            "               CP2           P4           P8          PO4           O2  \n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  \n",
            "mean     46.943309    68.100629    29.805883    82.197819    55.821892  \n",
            "std     142.501802   265.168885    57.843154   272.880509   203.288109  \n",
            "min       0.478152     0.761387     0.804002     0.838747     0.877576  \n",
            "25%       3.849956     3.690054     4.513405     4.620006     4.380690  \n",
            "50%       8.646393     7.300040    10.911662    10.430337     6.994829  \n",
            "75%      22.614200    28.908609    26.489674    42.960182    14.567389  \n",
            "max    1426.462453  2446.765512   647.533599  2505.826127  1794.801694  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "# Transform 880 x 32 x 8064 => 880 x 32\n",
        "eeg_gamma = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_gamma.append(get_band_power(i,j,\"gamma\"))\n",
        "eeg_gamma = np.reshape(eeg_gamma, (1280, 32))\n",
        "\n",
        "df_gamma = pd.DataFrame(data = eeg_gamma, columns=eeg_channels)\n",
        "print(df_gamma.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "kmTpi6Qc02Bu"
      },
      "outputs": [],
      "source": [
        "# Split the data into training/testing sets\n",
        "def split_train_test(x, y):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
        "  return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "cOCvaWDba3pa"
      },
      "outputs": [],
      "source": [
        "# Feature scaling\n",
        "def feature_scaling(train, test):\n",
        "  sc = StandardScaler()\n",
        "  train = sc.fit_transform(train)\n",
        "  test = sc.transform(test)\n",
        "  return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "EHrmKN1nf8ys"
      },
      "outputs": [],
      "source": [
        "band_names = np.array([\"theta\", \"alpha\", \"beta\", \"gamma\"])\n",
        "channel_names = np.array([\"frontal\",  \"central\", \"parietal\", \"occipital\"])\n",
        "label_names = np.array([\"valence\", \"arousal\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "tYVZwPvFgATk"
      },
      "outputs": [],
      "source": [
        "# Testing different kernels (linear, sigmoid, rbf, poly) to select the most optimal one\n",
        "clf_svm = SVC(kernel = 'rbf',random_state = 42, probability=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "t4pznSOZgHmK"
      },
      "outputs": [],
      "source": [
        "# Testing different k (odd) numbers, algorithm (auto, ball_tree, kd_tree) and weight (uniform, distance) to select the most optimal one\n",
        "clf_knn = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "7gi_aMFOgL08"
      },
      "outputs": [],
      "source": [
        "clf_dtree=DecisionTreeClassifier(max_depth=20,min_samples_split=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "T9hH4fktgPOX"
      },
      "outputs": [],
      "source": [
        "clf_rf=RandomForestClassifier(n_estimators=50,max_depth=20,min_samples_split=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "7lJ9wwn0gUmH"
      },
      "outputs": [],
      "source": [
        "clf_nb= GaussianNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "h-f5ay_0gYey"
      },
      "outputs": [],
      "source": [
        "# Testing different learning rate (alpha), solver (adam, sgd, lbfgs) and activation (relu, tanh, logistic) to select the most optimal one\n",
        "clf_mlp = MLPClassifier(solver='adam', activation='tanh', alpha=0.3, max_iter=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "vOCq_XttoT4e"
      },
      "outputs": [],
      "source": [
        "clf_adaboost = AdaBoostClassifier(n_estimators=50, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "xJMuk2lWq8v6"
      },
      "outputs": [],
      "source": [
        "clf_xgb = xgb.XGBClassifier(learning_rate=0.1, max_depth=3, n_estimators=100, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KFc0oT1XMHGv"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "clf_lgbm = lgb.LGBMClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "G_SB4HCTNIWQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "clf_gpc = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0), random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "xQ_4Dt-2N5t8"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "clf_perceptron = Perceptron(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pheOwL8PlYt",
        "outputId": "72ff5207-1fe5-4a7d-8ff9-deff919fb4ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.3.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "import catboost as cb\n",
        "clf_catboost = cb.CatBoostClassifier(iterations=1000, depth=6, learning_rate=0.1, loss_function='Logloss', verbose=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define cnn model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "def create_cnn_model(data_np):\n",
        "    model = Sequential([\n",
        "        Input(shape=(data_np.shape[1], 1)),  # Adjusted to match data_np shape\n",
        "        Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.2),\n",
        "        Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.2),\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(2, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate_cnn(df_x, df_y):\n",
        "    # Convert dataframes to numpy arrays\n",
        "    data_np = df_x.values\n",
        "    labels_np = df_y.values\n",
        "\n",
        "    # Reshape data for CNN: (number of samples, height, width, channels)\n",
        "    # Here, height=1, width=number of features, channels=1\n",
        "    data_reshaped = data_np.reshape((data_np.shape[0], data_np.shape[1], 1))\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    labels_encoded = to_categorical(labels_np)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_reshaped, labels_encoded, test_size=0.20, random_state=42)\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = create_cnn_model(data_np)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "    return test_loss, test_accuracy*100\n"
      ],
      "metadata": {
        "id": "tIwd_l6MD6dw"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define ann model\n",
        "def create_ann_model(data_scaled):\n",
        "    model = Sequential([\n",
        "        Dense(64, input_dim=data_scaled.shape[1], activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(2, activation='softmax')  # Assuming two classes: 0 and 1\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_and_evaluate_ann(df_x, df_y):\n",
        "    # Convert dataframes to numpy arrays\n",
        "    data_np = df_x.values\n",
        "    labels_np = df_y.values\n",
        "\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    data_scaled = scaler.fit_transform(data_np)\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    labels_encoded = to_categorical(labels_np)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_scaled, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = create_ann_model(data_np)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "    return test_loss, test_accuracy*100"
      ],
      "metadata": {
        "id": "C81EuQgrZIim"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define lstm model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "def create_lstm_model(data_np):\n",
        "    model = Sequential([\n",
        "    LSTM(20, input_shape=(data_np.shape[1], 1)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')  # Assuming two classes: 0 and 1\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate_lstm(df_x, df_y):\n",
        "    # Convert dataframes to numpy arrays\n",
        "    data_np = df_x.values\n",
        "    labels_np = df_y.values\n",
        "\n",
        "    # Reshape data for LSTM: (samples, time_steps, features)\n",
        "    # Here, each row is treated as a sequence with a single time step\n",
        "    data_reshaped = data_np.reshape((data_np.shape[0], data_np.shape[1], 1))\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    labels_encoded = to_categorical(labels_np)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_reshaped, labels_encoded, test_size=0.2, random_state=42)\n",
        "    # Define the CNN model\n",
        "    model = create_lstm_model(data_np)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "    return test_loss, test_accuracy*100\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7hC14PKCbZUM"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "i28DLITPgfgJ"
      },
      "outputs": [],
      "source": [
        "models = []\n",
        "models.append(('SVM', clf_svm))\n",
        "models.append(('k-NN', clf_knn))\n",
        "models.append(('DT', clf_dtree))\n",
        "models.append(('RF', clf_rf))\n",
        "models.append(('NB', clf_nb))\n",
        "models.append(('MLP', clf_mlp))\n",
        "models.append(('AB', clf_adaboost))\n",
        "models.append(('XGB', clf_xgb))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjABDw0eqHmm",
        "outputId": "507cecdd-ce86-45eb-c239-aba04324f61b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "L_WzJMzsjrL4"
      },
      "outputs": [],
      "source": [
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "def run_clf_cv(band, channel, label, clf):\n",
        "  if (band == \"theta\"):\n",
        "    df_x = df_theta\n",
        "  elif (band == \"alpha\"):\n",
        "    df_x = df_alpha\n",
        "  elif (band == \"beta\"):\n",
        "    df_x = df_beta\n",
        "  elif (band == \"gamma\"):\n",
        "    df_x = df_gamma\n",
        "\n",
        "  if (channel == \"frontal\"):\n",
        "    df_x = df_x[frontal]\n",
        "  elif (channel == \"central\"):\n",
        "    df_x = df_x[central]\n",
        "  elif (channel == \"parietal\"):\n",
        "    df_x = df_x[parietal]\n",
        "  elif (channel == \"occipital\"):\n",
        "    df_x = df_x[occipital]\n",
        "\n",
        "  # df_y = df_arousal if (label == \"arousal\") else df_valence\n",
        "  # print(df_y.shape)\n",
        "  # df_y = df_result[\"HAHV\"]\n",
        "  # df_y = df_result\n",
        "  # df_y = df_y.flatten\n",
        "  # print(f\"the shape of df_y is {df_y.shape}\")\n",
        "  # print(f\"the shape of df_x is {df_x.shape}\")\n",
        "  if (label == \"HAHV\"):\n",
        "    df_y = df_result[\"HAHV\"]\n",
        "  elif (label == \"LAHV\"):\n",
        "    df_y = df_result[\"LAHV\"]\n",
        "  elif (label == \"HALV\"):\n",
        "    df_y = df_result[\"HALV\"]\n",
        "  elif (label == \"LALV\"):\n",
        "    df_y = df_result[\"LALV\"]\n",
        "\n",
        "  # print(f\"the shape of df_y is {df_y.shape}\")\n",
        "  # print(f\"the shape of df_x is {df_x.shape}\")\n",
        "  # Train-test split\n",
        "\n",
        "  # save he dataframes in csv format for analysis\n",
        "  # if (band == \"gamma\" and channel == \"frontal\" and label == \"HALV\"):\n",
        "  #   df_y.to_csv('labels.csv', index=False)\n",
        "  #   print(\"DataFrame saved to 'labels.csv'\")\n",
        "  #   df_x.to_csv('data.csv', index=False)\n",
        "  #   print(\"DataFrame saved to 'data.csv'\")\n",
        "  #   from google.colab import files\n",
        "  #   files.download('labels.csv')\n",
        "  #   files.download('data.csv')\n",
        "\n",
        "  x_train, x_test, y_train, y_test = split_train_test(df_x, df_y)\n",
        "\n",
        "  # Apply SMOTE to upsample the minority class in the training set\n",
        "  # smote = SMOTE(random_state=42)\n",
        "  # X_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)\n",
        "\n",
        "  # Apply CV\n",
        "  x_for_kfold = np.array(x_train)\n",
        "  y_for_kfold = np.array(y_train)\n",
        "  kfold = model_selection.KFold(n_splits=10)\n",
        "\n",
        "  for i, j in kfold.split(x_for_kfold):\n",
        "   x_train2, x_test2 = x_for_kfold[i], x_for_kfold[j]\n",
        "   y_train2, y_test2 = y_for_kfold[i], y_for_kfold[j]\n",
        "\n",
        "  # Feature scaling\n",
        "  x_train2, x_test2 = feature_scaling(x_train2, x_test2)\n",
        "\n",
        "  # Feature scaling\n",
        "  scaler = StandardScaler()\n",
        "  x_train2 = scaler.fit_transform(x_train2)\n",
        "  x_test2 = scaler.transform(x_test2)\n",
        "\n",
        "  # x_train2 = X_train_resampled\n",
        "  # x_test2 = x_test\n",
        "  # y_train2 = y_train_resampled\n",
        "  # y_test2 = y_test\n",
        "\n",
        "  # Standardize the features\n",
        "  # scaler = StandardScaler()\n",
        "  # X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
        "  # x_test = scaler.transform(x_test)\n",
        "\n",
        "\n",
        "  # x_train2 = x_train\n",
        "  # x_test2 = x_test\n",
        "  # y_train2 = y_train\n",
        "  # y_test2 = y_test\n",
        "  if (clf == \"svm\"):\n",
        "    clf_svm.fit(x_train2, y_train2)\n",
        "    y_predict = clf_svm.predict(x_test2)\n",
        "  elif (clf == \"knn\"):\n",
        "    clf_knn.fit(x_train2, y_train2)\n",
        "    y_predict = clf_knn.predict(x_test2)\n",
        "  elif (clf == \"dtree\"):\n",
        "    clf_dtree.fit(x_train2, y_train2)\n",
        "    y_predict = clf_dtree.predict(x_test2)\n",
        "  elif (clf == \"rf\"):\n",
        "    clf_rf.fit(x_train2, y_train2)\n",
        "    y_predict = clf_rf.predict(x_test2)\n",
        "  elif (clf == \"nb\"):\n",
        "    clf_nb.fit(x_train2, y_train2)\n",
        "    y_predict = clf_nb.predict(x_test2)\n",
        "  elif (clf == \"mlp\"):\n",
        "    clf_mlp.fit(x_train2, y_train2)\n",
        "    y_predict = clf_mlp.predict(x_test2)\n",
        "  elif (clf == \"ab\"):\n",
        "    clf_adaboost.fit(x_train2, y_train2)\n",
        "    y_predict = clf_adaboost.predict(x_test2)\n",
        "  elif (clf == \"xgb\"):\n",
        "    clf_xgb.fit(x_train2, y_train2)\n",
        "    y_predict = clf_xgb.predict(x_test2)\n",
        "  elif (clf == \"lgbm\"):\n",
        "    clf_lgbm.fit(x_train2, y_train2)\n",
        "    y_predict = clf_lgbm.predict(x_test2)\n",
        "  elif (clf == \"gpc\"):\n",
        "    clf_gpc.fit(x_train2, y_train2)\n",
        "    y_predict = clf_gpc.predict(x_test2)\n",
        "  elif (clf == \"per\"):\n",
        "    clf_perceptron.fit(x_train2, y_train2)\n",
        "    y_predict = clf_perceptron.predict(x_test2)\n",
        "  elif (clf == \"cb\"):\n",
        "    clf_catboost.fit(x_train2, y_train2)\n",
        "    y_predict = clf_catboost.predict(x_test2)\n",
        "  elif (clf == \"cnn\"):\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = train_and_evaluate_cnn(df_x, df_y)\n",
        "    # print(f\"Test Loss: {test_loss}\")\n",
        "    # print(f\"Test Accuracy: {test_accuracy}\")\n",
        "    return \"DL\",test_loss, test_accuracy\n",
        "\n",
        "  elif(clf ==\"ann\"):\n",
        "    test_loss, test_accuracy = train_and_evaluate_ann(df_x, df_y)\n",
        "    # print(f\"Test Loss: {test_loss}\")\n",
        "    # print(f\"Test Accuracy: {test_accuracy}\")\n",
        "    return \"DL\",test_loss, test_accuracy\n",
        "  elif(clf ==\"lstm\"):\n",
        "    test_loss, test_accuracy = train_and_evaluate_lstm(df_x, df_y)\n",
        "    return \"DL\",test_loss,test_accuracy\n",
        "  return \"ML\",y_test2, y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "gWN0kvbJjyhB"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(band, channel, label, clf):\n",
        "  classifier,y_test2, y_predict = run_clf_cv(band, channel, label, clf)\n",
        "  if (classifier == \"DL\"):\n",
        "    return y_predict\n",
        "  return np.round(accuracy_score(y_test2, y_predict)*100,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "cB-1MOCIuv_M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "def print_conf(band, channel, label, clf):\n",
        "  classifier,y_test2, y_predict = run_clf_cv(band, channel, label, clf)\n",
        "  conf_matrix = confusion_matrix(y_test2, y_predict)\n",
        "  # print(conf_matrix)\n",
        "  plt.figure(figsize=(4, 2))  # Decrease the figure size\n",
        "  plt.title('Confusion Matrix')\n",
        "  sns.heatmap(conf_matrix,\n",
        "              annot=True,\n",
        "              fmt='g',\n",
        "              xticklabels=['0','1'],\n",
        "              yticklabels=['0','1'])\n",
        "\n",
        "  # display matrix\n",
        "  plt.ylabel('True Label',fontsize=12)\n",
        "  plt.xlabel('Predicted Label',fontsize=12)\n",
        "  plt.show()\n",
        "\n",
        "  # printing the classification report aswell\n",
        "\n",
        "  class_report = classification_report(y_test2, y_predict, target_names=['0', '1'])\n",
        "  print(\"\\nClassification Report:\")\n",
        "  print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_kBo9bznkFa9"
      },
      "outputs": [],
      "source": [
        "def print_accuracy(label, clf):\n",
        "  arr = []\n",
        "  for i in range (len(band_names)):\n",
        "    for j in range (len(channel_names)):\n",
        "      arr.append(get_accuracy(band_names[i], channel_names[j], label, clf))\n",
        "  arr = np.reshape(arr, (4,4))\n",
        "  df = pd.DataFrame(data = arr, index=band_names, columns=channel_names)\n",
        "\n",
        "  #print(\"Top 3 EEG regions with highest scores\")\n",
        "  #print(df.apply(lambda s: s.abs()).max().nlargest(3))\n",
        "  #print()\n",
        "  #print(\"Top 2 bands with highest scores\")\n",
        "  #print(df.apply(lambda s: s.abs()).max(axis=1).nlargest(2))\n",
        "  #print()\n",
        "  #print(\"EEG region with highest scores per each band\")\n",
        "  #print(df.idxmax(axis=1))\n",
        "  #print()\n",
        "  #print(\"Accuracy Scores\")\n",
        "  #print(df.idxmax())\n",
        "  #print()\n",
        "  print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDIaK777kOdU",
        "outputId": "f33630b3-f691-4dc7-f384-45f11394b809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    65.69    67.65     65.69      65.69\n",
            "alpha    65.69    67.65     67.65      65.69\n",
            "beta     67.65    66.67     67.65      67.65\n",
            "gamma    65.69    66.67     67.65      66.67\n"
          ]
        }
      ],
      "source": [
        "print_accuracy('HAHV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTqPyKdifUch",
        "outputId": "c8800668-269e-423a-fbd0-590df5b3aedc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    71.57    72.55     72.55      72.55\n",
            "alpha    71.57    72.55     72.55      72.55\n",
            "beta     71.57    72.55     72.55      72.55\n",
            "gamma    71.57    71.57     71.57      71.57\n"
          ]
        }
      ],
      "source": [
        "print_accuracy('LAHV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "BaV8Ul3zfbVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ef4585d-ff2f-41c9-ade7-f7fc8d42de29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    81.37    81.37     81.37      81.37\n",
            "alpha    81.37    81.37     81.37      81.37\n",
            "beta     81.37    81.37     81.37      81.37\n",
            "gamma    81.37    80.39     80.39      81.37\n"
          ]
        }
      ],
      "source": [
        "print_accuracy('HALV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "8sPz6Kjdfkia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a48927-0b69-4cca-fc8f-7daf88417127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    78.43    80.39     79.41      79.41\n",
            "alpha    78.43    80.39     79.41      78.43\n",
            "beta     79.41    79.41     79.41      79.41\n",
            "gamma    79.41    79.41     79.41      79.41\n"
          ]
        }
      ],
      "source": [
        "print_accuracy('LALV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_conf(\"theta\",\"central\",\"HAHV\",\"svm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "hsbBLsXCg3wg",
        "outputId": "93780791-3a8c-4818-a536-9db25a96e6d1"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      1.00      0.81        69\n",
            "           1       0.00      0.00      0.00        33\n",
            "\n",
            "    accuracy                           0.68       102\n",
            "   macro avg       0.34      0.50      0.40       102\n",
            "weighted avg       0.46      0.68      0.55       102\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"knn\")"
      ],
      "metadata": {
        "id": "3ZJ1eRTBagJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d58aa2d1-6430-4510-afd2-a1c5a23b7add"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    54.90    58.82     55.88      55.88\n",
            "alpha    62.75    64.71     65.69      59.80\n",
            "beta     58.82    61.76     69.61      60.78\n",
            "gamma    67.65    63.73     63.73      62.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"knn\")"
      ],
      "metadata": {
        "id": "47cLDLLtc3dL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900d9147-3581-47b0-d3bc-ad7f2a8f42d7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    71.57    68.63     70.59      63.73\n",
            "alpha    70.59    67.65     69.61      73.53\n",
            "beta     66.67    64.71     69.61      66.67\n",
            "gamma    72.55    70.59     66.67      70.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"knn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3_ANNm2g7jl",
        "outputId": "c0f7eeec-9260-4229-8727-1b756285fefb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    79.41    76.47     77.45      82.35\n",
            "alpha    84.31    73.53     75.49      74.51\n",
            "beta     80.39    80.39     77.45      80.39\n",
            "gamma    79.41    78.43     79.41      76.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"knn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBuNsO0whCji",
        "outputId": "e7d3f66d-2fe8-435a-a7ca-1beef32ba032"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    70.59    75.49     67.65      69.61\n",
            "alpha    74.51    75.49     76.47      74.51\n",
            "beta     76.47    76.47     79.41      70.59\n",
            "gamma    72.55    72.55     77.45      70.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_conf(\"beta\",\"parietal\",\"HAHV\",\"knn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "nBwFkxiHg_Zr",
        "outputId": "aaa9365d-5e22-4bcb-c783-c5ec140ca142"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.90      0.80        69\n",
            "           1       0.56      0.27      0.37        33\n",
            "\n",
            "    accuracy                           0.70       102\n",
            "   macro avg       0.64      0.59      0.58       102\n",
            "weighted avg       0.67      0.70      0.66       102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"dtree\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7McLqGAXhFmh",
        "outputId": "dcabf742-570a-48a2-868e-3a8e83d4d824"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    62.75    57.84     55.88      54.90\n",
            "alpha    54.90    56.86     57.84      62.75\n",
            "beta     63.73    57.84     60.78      60.78\n",
            "gamma    64.71    62.75     61.76      66.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"dtree\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qyAj7CdhLoh",
        "outputId": "86806914-4bb4-4581-e62e-cae80e3d61f0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    67.65    64.71     64.71      63.73\n",
            "alpha    66.67    70.59     62.75      55.88\n",
            "beta     57.84    65.69     60.78      59.80\n",
            "gamma    57.84    67.65     62.75      62.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"dtree\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5iFr3h1hODL",
        "outputId": "8ba1e4c7-c594-4cf0-c998-74d292bc430d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    70.59    68.63     81.37      70.59\n",
            "alpha    73.53    60.78     67.65      65.69\n",
            "beta     78.43    74.51     78.43      67.65\n",
            "gamma    79.41    78.43     72.55      73.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"dtree\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQY984Z4hTAg",
        "outputId": "c67bf7d5-7d67-4d24-eed4-cfd29fc7b7eb"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    67.65    68.63     74.51      67.65\n",
            "alpha    66.67    63.73     59.80      69.61\n",
            "beta     66.67    65.69     68.63      71.57\n",
            "gamma    70.59    70.59     67.65      63.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_conf(\"gamma\",\"frontal\",\"HAHV\",\"dtree\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "tc8ZudXghKF2",
        "outputId": "793a4133-dd19-4c1e-9c08-4b2c27968974"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79        69\n",
            "           1       0.56      0.45      0.50        33\n",
            "\n",
            "    accuracy                           0.71       102\n",
            "   macro avg       0.66      0.64      0.65       102\n",
            "weighted avg       0.69      0.71      0.70       102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"rf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XazVDwjhVW0",
        "outputId": "bb45b455-183c-4d3c-af7e-911e2152195a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    61.76    56.86     56.86      56.86\n",
            "alpha    68.63    62.75     65.69      62.75\n",
            "beta     64.71    65.69     69.61      63.73\n",
            "gamma    69.61    67.65     68.63      72.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"rf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6V2n3jahc5l",
        "outputId": "ad1b1c0b-d7df-4e02-e0db-1aabf06d2885"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    69.61    67.65     67.65      70.59\n",
            "alpha    72.55    69.61     72.55      70.59\n",
            "beta     66.67    75.49     68.63      70.59\n",
            "gamma    75.49    78.43     71.57      71.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"rf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_947cDehfTh",
        "outputId": "eadaac56-269a-4ba5-b9dd-05fb8f011f65"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    81.37    76.47     82.35      82.35\n",
            "alpha    84.31    81.37     77.45      77.45\n",
            "beta     80.39    77.45     80.39      81.37\n",
            "gamma    83.33    78.43     82.35      80.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"rf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpaIBT6chh-J",
        "outputId": "4db21274-cce3-4e4e-a240-348cc00587d7"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    74.51    74.51     76.47      76.47\n",
            "alpha    76.47    77.45     81.37      75.49\n",
            "beta     79.41    76.47     78.43      75.49\n",
            "gamma    74.51    74.51     75.49      72.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_conf(\"gamma\",\"occipital\",\"HAHV\",\"rf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "Hj_Q2HSMhaPH",
        "outputId": "b447c0d8-5aba-403f-c684-c7895502436c"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.90      0.82        69\n",
            "           1       0.63      0.36      0.46        33\n",
            "\n",
            "    accuracy                           0.73       102\n",
            "   macro avg       0.69      0.63      0.64       102\n",
            "weighted avg       0.71      0.73      0.70       102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"nb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48cd7Ye-hlP9",
        "outputId": "33641e8a-43fb-4920-f4cb-85dcbd164f00"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    62.75    38.24     61.76      62.75\n",
            "alpha    62.75    40.20     62.75      67.65\n",
            "beta     62.75    39.22     67.65      67.65\n",
            "gamma    67.65    40.20     67.65      67.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"nb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw1gw4y-hvol",
        "outputId": "7d272991-2ceb-4334-afb4-48d0e9d375e3"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    39.22    72.55     74.51      35.29\n",
            "alpha    40.20    72.55     74.51      36.27\n",
            "beta     36.27    73.53     73.53      33.33\n",
            "gamma    32.35    73.53     72.55      28.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"nb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jpmOw5XhzK7",
        "outputId": "e78c9c51-6cdf-417b-82c2-7d5a5211301e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    80.39    28.43     80.39      80.39\n",
            "alpha    80.39    27.45     78.43      80.39\n",
            "beta     80.39    81.37     79.41      78.43\n",
            "gamma    78.43    77.45     78.43      80.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"nb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpIC6lTMh3XK",
        "outputId": "38f99d7d-2a7d-4b6e-c47a-3ed345cf2e2b"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    71.57    73.53     76.47      73.53\n",
            "alpha    70.59    72.55     76.47      73.53\n",
            "beta     71.57    70.59     53.92      75.49\n",
            "gamma    77.45    76.47     79.41      77.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_conf(\"gamma\",\"frontal\",\"HAHV\",\"nb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "KDg3mBQQh4Mq",
        "outputId": "3b829f57-475b-4dc0-fb27-d73d32547b26"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.99      0.80        69\n",
            "           1       0.50      0.03      0.06        33\n",
            "\n",
            "    accuracy                           0.68       102\n",
            "   macro avg       0.59      0.51      0.43       102\n",
            "weighted avg       0.62      0.68      0.56       102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"mlp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnJufSQEk3gr",
        "outputId": "912c82f6-a013-4626-a114-bfb82b36b0e8"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    67.65    66.67     67.65      67.65\n",
            "alpha    67.65    67.65     67.65      67.65\n",
            "beta     67.65    66.67     67.65      67.65\n",
            "gamma    68.63    66.67     67.65      67.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"mlp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE7LJGYYlNmD",
        "outputId": "02aab90c-ec70-4fb0-80d3-7aa46054d87a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    71.57    72.55     72.55      72.55\n",
            "alpha    71.57    72.55     72.55      72.55\n",
            "beta     71.57    72.55     72.55      72.55\n",
            "gamma    71.57    70.59     71.57      71.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"mlp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRT6VcEclUkW",
        "outputId": "69866250-90bc-47b2-d241-8122b7e9733c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    81.37    81.37     81.37      81.37\n",
            "alpha    81.37    81.37     81.37      81.37\n",
            "beta     81.37    82.35     81.37      81.37\n",
            "gamma    81.37    81.37     80.39      80.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"mlp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpNkotrVlZWu",
        "outputId": "b0679be0-4cf4-47fb-a130-e6fa806d6920"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    76.47    77.45     78.43      76.47\n",
            "alpha    77.45    78.43     79.41      76.47\n",
            "beta     79.41    77.45     79.41      77.45\n",
            "gamma    79.41    79.41     79.41      79.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_conf(\"gamma\",\"frontal\",\"HAHV\",\"mlp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "C9siaoG0iGwU",
        "outputId": "1ac8cd52-e852-485f-b208-61f683aa487d"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      1.00      0.81        69\n",
            "           1       1.00      0.03      0.06        33\n",
            "\n",
            "    accuracy                           0.69       102\n",
            "   macro avg       0.84      0.52      0.44       102\n",
            "weighted avg       0.79      0.69      0.57       102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"ab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erYq7nicnROs",
        "outputId": "5a124208-d72d-44fe-de8d-dc3fc503949e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    64.71    62.75     65.69      63.73\n",
            "alpha    63.73    67.65     63.73      67.65\n",
            "beta     65.69    68.63     68.63      67.65\n",
            "gamma    66.67    63.73     65.69      66.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"ab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fPMwhsXnX2f",
        "outputId": "4a35f787-9155-4f2e-829c-6f4459351b59"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    70.59    72.55     71.57      68.63\n",
            "alpha    71.57    74.51     71.57      71.57\n",
            "beta     70.59    73.53     73.53      73.53\n",
            "gamma    72.55    73.53     72.55      70.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"ab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1BAgu7lncbF",
        "outputId": "357805a0-7b22-4938-dafb-cff2197def33"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    82.35    79.41     81.37      76.47\n",
            "alpha    79.41    81.37     77.45      79.41\n",
            "beta     78.43    79.41     81.37      79.41\n",
            "gamma    78.43    78.43     79.41      77.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"ab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EtZqaWJngRs",
        "outputId": "fe127098-4eb5-44e0-911d-cc1654501906"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    75.49    77.45     77.45      77.45\n",
            "alpha    75.49    76.47     77.45      77.45\n",
            "beta     73.53    77.45     81.37      77.45\n",
            "gamma    77.45    75.49     77.45      74.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_conf(\"beta\",\"central\",\"HAHV\",\"ab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "ZTEOAiuriUEN",
        "outputId": "6bc633a7-1a81-4577-d9d5-71d5a36ecea6"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.96      0.80        69\n",
            "           1       0.57      0.12      0.20        33\n",
            "\n",
            "    accuracy                           0.69       102\n",
            "   macro avg       0.63      0.54      0.50       102\n",
            "weighted avg       0.65      0.69      0.61       102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"xgb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fdCu6AonjgZ",
        "outputId": "bb609987-9e39-4aa4-edb2-b9c941a9cb5a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    58.82    66.67     65.69      62.75\n",
            "alpha    67.65    66.67     69.61      65.69\n",
            "beta     71.57    63.73     69.61      64.71\n",
            "gamma    70.59    62.75     71.57      70.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"xgb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo9lY7kynp5r",
        "outputId": "9b57688e-b8fa-4d83-da7b-21f9fc2852a6"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    72.55    71.57     69.61      70.59\n",
            "alpha    71.57    72.55     74.51      72.55\n",
            "beta     75.49    74.51     73.53      74.51\n",
            "gamma    73.53    71.57     72.55      73.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"xgb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkJk2VfvnuWW",
        "outputId": "3d7a906a-02fd-46cd-c669-814909a17ff6"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    80.39    81.37     80.39      80.39\n",
            "alpha    82.35    81.37     78.43      79.41\n",
            "beta     82.35    80.39     80.39      81.37\n",
            "gamma    80.39    79.41     82.35      77.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"xgb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDRn39Jknwj8",
        "outputId": "54f7d94b-834b-42f6-d25d-5766e557231f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    75.49    77.45     76.47      78.43\n",
            "alpha    76.47    77.45     77.45      77.45\n",
            "beta     78.43    78.43     80.39      78.43\n",
            "gamma    76.47    78.43     76.47      76.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_conf(\"beta\",\"frontal\",\"HAHV\",\"xgb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "hT86J8kFirHP",
        "outputId": "4aa00749-ec59-428f-de4d-9945f7e35f58"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x200 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAADzCAYAAABNGkelAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAurUlEQVR4nO3deVgTV9s/8G/CEpBN9sUFcQc3FK0iCloRqli1WPcq0KroD1fcWxdAK60r7qD1EeryVn2s2sWKiCBqsSqKCnXB3UoBQQFFCJCc3x+85jVCIIRAMuT+9JrrMmfOnLkn2pvDmTNneIwxBkIIIZzAV3UAhBBC5EdJmxBCOISSNiGEcAglbUII4RBK2oQQwiGUtAkhhEMoaRNCCIdQ0iaEEA6hpE0IIRxCSZvUWUZGBry8vGBiYgIej4fjx48rtf3Hjx+Dx+MhOjpaqe1y2YABAzBgwABVh0FUgJJ2I/HgwQMEBgaidevW0NPTg7GxMdzc3LB582YUFxfX67n9/Pxw69YtfPvtt9i3bx969uxZr+drSP7+/uDxeDA2Nq7ye8zIyACPxwOPx8P69etr3X5mZiZCQkKQmpqqhGiJJtBWdQCk7n7//XeMHj0aAoEAkydPRufOnVFaWooLFy5g4cKFSE9Px65du+rl3MXFxUhOTsY333yDmTNn1ss57O3tUVxcDB0dnXppvyba2tp4+/Ytfv31V4wZM0Zq34EDB6Cnp4eSkhKF2s7MzERoaChatWoFZ2dnuY87ffq0Qucj3EdJm+MePXqEcePGwd7eHmfPnoWtra1kX1BQEO7fv4/ff/+93s7/4sULAEDTpk3r7Rw8Hg96enr11n5NBAIB3Nzc8D//8z+VkvbBgwfh4+ODo0ePNkgsb9++RZMmTaCrq9sg5yNqiBFOmz59OgPALl68KFf9srIyFhYWxlq3bs10dXWZvb09W7p0KSspKZGqZ29vz3x8fNj58+dZr169mEAgYA4ODiwmJkZSZ+XKlQyA1GZvb88YY8zPz0/y5/e9O+Z9p0+fZm5ubszExIQZGBiw9u3bs6VLl0r2P3r0iAFge/fulTouPj6e9evXjzVp0oSZmJiw4cOHs7///rvK82VkZDA/Pz9mYmLCjI2Nmb+/PysqKqrx+/Lz82MGBgYsOjqaCQQC9urVK8m+y5cvMwDs6NGjDABbt26dZF9eXh6bP38+69y5MzMwMGBGRkbsk08+YampqZI6CQkJlb6/96/Tw8ODderUiV29epX179+f6evrszlz5kj2eXh4SNqaPHkyEwgEla7fy8uLNW3alD1//rzGayXcQGPaHPfrr7+idevW6Nu3r1z1p0yZghUrVqBHjx7YtGkTPDw8EB4ejnHjxlWqe//+fXz++ecYPHgwNmzYAFNTU/j7+yM9PR0A4Ovri02bNgEAxo8fj3379iEiIqJW8aenp2PYsGEQCoUICwvDhg0bMHz4cFy8eLHa486cOQNvb2/k5OQgJCQEwcHB+PPPP+Hm5obHjx9Xqj9mzBi8fv0a4eHhGDNmDKKjoxEaGip3nL6+vuDxePj5558lZQcPHkTHjh3Ro0ePSvUfPnyI48ePY9iwYdi4cSMWLlyIW7duwcPDA5mZmQAAR0dHhIWFAQCmTZuGffv2Yd++fXB3d5e0k5eXhyFDhsDZ2RkREREYOHBglfFt3rwZlpaW8PPzg0gkAgBERUXh9OnT2Lp1K+zs7OS+VqLmVP1TgyiuoKCAAWAjRoyQq35qaioDwKZMmSJVvmDBAgaAnT17VlJmb2/PALCkpCRJWU5ODhMIBGz+/PmSsne94Pd7mYzJ39PetGkTA8BevHghM+6qetrOzs7MysqK5eXlScpu3LjB+Hw+mzx5cqXzffnll1JtfvbZZ8zc3FzmOd+/DgMDA8YYY59//jkbNGgQY4wxkUjEbGxsWGhoaJXfQUlJCROJRJWuQyAQsLCwMEnZlStXqvwtgrGK3jQAFhkZWeW+93vajDEWGxvLALDVq1ezhw8fMkNDQzZy5Mgar5FwC/W0OaywsBAAYGRkJFf9kydPAgCCg4OlyufPnw8Alca+nZyc0L9/f8lnS0tLdOjQAQ8fPlQ45g+9Gws/ceIExGKxXMf8+++/SE1Nhb+/P8zMzCTlXbt2xeDBgyXX+b7p06dLfe7fvz/y8vIk36E8JkyYgMTERGRlZeHs2bPIysrChAkTqqwrEAjA51f87yUSiZCXlwdDQ0N06NAB165dk/ucAoEAAQEBctX18vJCYGAgwsLC4OvrCz09PURFRcl9LsINlLQ5zNjYGADw+vVrueo/efIEfD4fbdu2lSq3sbFB06ZN8eTJE6nyli1bVmrD1NQUr169UjDiysaOHQs3NzdMmTIF1tbWGDduHA4fPlxtAn8XZ4cOHSrtc3R0RG5uLoqKiqTKP7wWU1NTAKjVtQwdOhRGRkY4dOgQDhw4gF69elX6Lt8Ri8XYtGkT2rVrB4FAAAsLC1haWuLmzZsoKCiQ+5zNmjWr1U3H9evXw8zMDKmpqdiyZQusrKzkPpZwAyVtDjM2NoadnR3S0tJqdRyPx5OrnpaWVpXlTI431Mk6x7vx1nf09fWRlJSEM2fOYNKkSbh58ybGjh2LwYMHV6pbF3W5lncEAgF8fX0RExODY8eOyexlA8CaNWsQHBwMd3d37N+/H7GxsYiLi0OnTp3k/o0CqPh+auP69evIyckBANy6datWxxJuoKTNccOGDcODBw+QnJxcY117e3uIxWJkZGRIlWdnZyM/Px/29vZKi8vU1BT5+fmVyj/szQMAn8/HoEGDsHHjRvz999/49ttvcfbsWSQkJFTZ9rs47969W2nfnTt3YGFhAQMDg7pdgAwTJkzA9evX8fr16ypv3r7z3//+FwMHDsSePXswbtw4eHl5wdPTs9J3Iu8PUHkUFRUhICAATk5OmDZtGtauXYsrV64orX2iHihpc9yiRYtgYGCAKVOmIDs7u9L+Bw8eYPPmzQAqfr0HUGmGx8aNGwEAPj4+SourTZs2KCgowM2bNyVl//77L44dOyZV7+XLl5WOffeQiVAorLJtW1tbODs7IyYmRioJpqWl4fTp05LrrA8DBw7EqlWrsG3bNtjY2Misp6WlVakXf+TIETx//lyq7N0Pl6p+wNXW4sWL8fTpU8TExGDjxo1o1aoV/Pz8ZH6PhJvo4RqOa9OmDQ4ePIixY8fC0dFR6onIP//8E0eOHIG/vz8AoFu3bvDz88OuXbuQn58PDw8PXL58GTExMRg5cqTM6WSKGDduHBYvXozPPvsMs2fPxtu3b7Fz5060b99e6kZcWFgYkpKS4OPjA3t7e+Tk5GDHjh1o3rw5+vXrJ7P9devWYciQIXB1dcVXX32F4uJibN26FSYmJggJCVHadXyIz+dj2bJlNdYbNmwYwsLCEBAQgL59++LWrVs4cOAAWrduLVWvTZs2aNq0KSIjI2FkZAQDAwP07t0bDg4OtYrr7Nmz2LFjB1auXCmZgrh3714MGDAAy5cvx9q1a2vVHlFjKp69QpTk3r17bOrUqaxVq1ZMV1eXGRkZMTc3N7Z161apB2fKyspYaGgoc3BwYDo6OqxFixbVPlzzoQ+nmsma8sdYxUMznTt3Zrq6uqxDhw5s//79lab8xcfHsxEjRjA7Ozumq6vL7Ozs2Pjx49m9e/cqnePDaXFnzpxhbm5uTF9fnxkbG7NPP/1U5sM1H04p3Lt3LwPAHj16JPM7ZUx6yp8ssqb8zZ8/n9na2jJ9fX3m5ubGkpOTq5yqd+LECebk5MS0tbWrfLimKu+3U1hYyOzt7VmPHj1YWVmZVL158+YxPp/PkpOTq70Gwh08xmpxJ4YQQohK0Zg2IYRwCCVtQgjhEErahBDCIZS0CSGEQyhpE0IIh1DSJoQQDqGkTQghHKIRT0SW5SpvKVGi/vTt+tdciTQa5aXPa65UjbKcDJn7dKza1ant+qARSZsQQmRi8q+6qA4oaRNCNBoTlas6hFqhpE0I0WyUtAkhhEPEynvZRkOgpE0I0WzU0yaEEO6gMW1CCOESmj1CCCEcIipTdQS1QkmbEKLZaHiEEEI4REzDI4QQwhlMTMMjhBDCHTQ8QgghHEIP1xBCCIdQT5sQQjiEY0mbXoJACNFsYrHsrZaeP3+OL774Aubm5tDX10eXLl1w9epVyX7GGFasWAFbW1vo6+vD09MTGRmy1/OuCiVtQohGY6IymVttvHr1Cm5ubtDR0cEff/yBv//+Gxs2bICpqamkztq1a7FlyxZERkbir7/+goGBAby9vVFSUiL3eWh4hBCi2ZQ0PPL999+jRYsW2Lt3r6TMwcFB8mfGGCIiIrBs2TKMGDECAPDjjz/C2toax48fx7hx4+Q6D/W0CSGajYllbkKhEIWFhVKbUCissplffvkFPXv2xOjRo2FlZYXu3btj9+7dkv2PHj1CVlYWPD09JWUmJibo3bs3kpOT5Q6XkjYhRLOJymVu4eHhMDExkdrCw8OrbObhw4fYuXMn2rVrh9jYWMyYMQOzZ89GTEwMACArKwsAYG1tLXWctbW1ZJ88aHiEEKLZymUPjyxduhTBwcFSZQKBoMq6YrEYPXv2xJo1awAA3bt3R1paGiIjI+Hn56e0cKmnTQjRbNUMjwgEAhgbG0ttspK2ra0tnJycpMocHR3x9OlTAICNjQ0AIDs7W6pOdna2ZJ88KGkTQjRbNcMjteHm5oa7d+9Kld27dw/29vYAKm5K2tjYID4+XrK/sLAQf/31F1xdXeU+Dw2PEEI0m5Jmj8ybNw99+/bFmjVrMGbMGFy+fBm7du3Crl27AAA8Hg9z587F6tWr0a5dOzg4OGD58uWws7PDyJEj5T4PJW1CiGZT0tKsvXr1wrFjx7B06VKEhYXBwcEBERERmDhxoqTOokWLUFRUhGnTpiE/Px/9+vXDqVOnoKenJ/d5eIwxppSI1VhZ7kNVh0AakL5df1WHQBpQeenzOh1ffChU5j79sSvr1HZ9oJ42IUSzVTN7RB1R0iaEaDZ6sS8hhHCIiNbTJoQQ7qDhEUII4RAaHiGEEO5g5dwaHqEnIjku+0UuFoeuhduQMXAZOAKfTZqBtNv3JPtzX77CN6s3YODwiej58UgEBi/Dk2d1myJF1M+M6X64f+8S3hQ+wJ8XfkWvns6qDok7RCLZmxqipM1hBYWvMWn6fOhoayNywyqcOBCFBTOnwNjIEEDF+r1zloThn8wsbPl+BY7s3QY7GytMmfM13hbLv+g6UW+jRw/H+nUrsWr1RvTq/Qlu3PwbJ38/AEtLc1WHxg1KfHNNQ6CkzWH/OXAENlaWWP1NMLo4dUBzOxu49XZBy+Z2AIAnz57jRvodLF8wE10cO8DBvjmWL5gJoVCIk3GJqg2eKM28OVPxw56DiPnxMG7fzsD/C1qCt2+LEeAv36L6Go9jPW21GtPOzc3Ff/7zHyQnJ0vWl7WxsUHfvn3h7+8PS0tLFUeoXhIuXILbRy4IXvYtrl6/BStLc4zzHYbPhw8BAJSWVbwuSVdXR3IMn8+Hjq4Ort9Mx+fDP1FJ3ER5dHR00KNHV3y3dpukjDGG+LMX0KePiwoj4xCOjWnLlbQdHBzA4/Fq1TCPx8ODBw/krn/lyhV4e3ujSZMm8PT0RPv27QFULFu4ZcsWfPfdd4iNjUXPnj2rbUcoFFZ6swRfKJS5nCKX/ZOZhUPHf8fksb6YOnks0m7fQ/imSOhoa2PE0MFwsG8BW2srbI6KxoqFs9BEXw8/HjqG7JxcvMh7qerwiRJYWJhBW1sbOdm5UuU5OS/QsUMbFUXFMY1x9oiHh0etk3ZtzZo1C6NHj0ZkZGSlczHGMH36dMyaNavG1/KEh4cjNFR6LYFlC2djxaI5So9Z1cRihk4d22HudH8AgGP7tsh4+ASHj5/EiKGDoaOtjYg1y7AiPAJuQ8ZAS4uPPj27o3+fnmj0C84QIieuzR6RK2lHR0fXcxjAjRs3EB0dXeUPBx6Ph3nz5qF79+41tlPVmyb4rxvnbAlLczO0adVSqqx1qxY4k3hR8rlTx3Y4GrMdr98UoaysDGamTTF+6lx06tiuocMl9SA39yXKy8thZW0hVW5lZYms7Bcqiopj1HTsWha1uRFpY2ODy5cvy9x/+fLlSu9Wq0pt3jTBdd27OuHx03+kyp48fQ5bG6tKdY0MDWBm2hRPnj1H+p0MDOzXp6HCJPWorKwM167dxMcD+0nKeDwePh7YD5cupagwMg4RM9mbGlL4RmRhYSF27NiBhIQE5OTkICoqCh999BFevnyJ6OhoDB8+HG3btpW7vQULFmDatGlISUnBoEGDJAk6Ozsb8fHx2L17N9avX69ouI3SpLEjMSlwPnbF/IRPBrnj1t938d9f/sDKRbMldWLPnodpUxPYWlsi4+FjfBcRiY/7u8KtN92kaiw2bd6NvXs2IeXaTVy5ch2zZ02FgYE+omMOqTo0bmiMwyMf+ueff+Dh4YFnz56hXbt2uHPnDt68eQMAMDMzQ1RUFJ48eYLNmzfL3WZQUBAsLCywadMm7NixA6L//ZVFS0sLLi4uiI6OxpgxYxQJt9Hq4tgBEeHLsTkyGpHRB9HM1gaL5wRimPfHkjov8l5i7dZdyHuZD0tzMwz/ZBCmB4xXYdRE2Y4c+QWWFmYIWbEANjaWuHEjHT7DvkBOTm7NBxPODY8o9BKE8ePHIz4+HomJibCysoKVlRXOnDmDjz+uSBaLFy/Gb7/9hvT0dIWCKisrQ25uxT84CwsL6Ojo1HBEDe3RSxA0Cr0EQbPU9SUIb5aOkrnPMPxondquDwr1tE+fPo158+bByckJeXl5lfa3bt0az549UzgoHR0d2NraKnw8IYTIrbwRTvn7UHFxcbUPurx+/VrhgAghpEFxbHhEodkjTk5OSEpKkrn/+PHjck3PI4QQVWNiJnNTRwr1tOfOnQs/Pz907doVo0ePBgCIxWLcv38foaGhSE5OxtGj6jcWRAghlWjC7JEvvvgCT548wbJly/DNN98AAD755BMwxsDn87FmzRqMHDlSmXESQkj90IQxbQD45ptvMGnSJBw9ehT379+HWCxGmzZt4Ovri9atWyszRkIIqTcKTKBTqTqt8teyZUvMmzdPWbEQQkjD05SeNgCkpaXh5MmTePz4MYCK1QA/+eQTdOnSRRmxEUJIvWOakLSFQiECAwOxb98+yTg2UHEzcsmSJZg4cSJ++OEH6OrqKjVYQghROm7lbMWm/C1evBg//vgjZsyYgdu3b6OkpARCoRC3b9/G9OnTsX//fixatEjZsRJCiNKxcrHMTR0p9Bi7hYUFfHx8EBMTU+X+SZMm4Y8//pA8iq5q9Bi7ZqHH2DVLXR9jfzV6gMx9pkcS69R2fVCop11WVoY+fWQv7dm3b1+Ul5crHBQhhDQYcTWbGlIoaXt7eyM2Nlbm/lOnTsHLy0vhoAghpKGwciZzU0dy3Yh8+VL6fYKrVq3CmDFj4Ovri6CgIMm62RkZGdi+fTuePHmCQ4doLV9CiPpjHBsUkGtMm8/nV/neRgAyy/l8vtoMkdCYtmahMW3NUtcx7dwhHjL3Wfxxrk5t1we5etorVqyo9xf7EkKIKnCtpy1X0g4JCannMAghRDXEHEvaavNiX0IIUQnGk73VwXfffQcej4e5c+dKykpKShAUFARzc3MYGhpi1KhRyM7OrlW7dXqM/eLFi7h27RoKCgogFkvPj+HxeFi+fHldmieEkHonLlf+0O+VK1cQFRWFrl27SpXPmzcPv//+O44cOQITExPMnDkTvr6+uHjxotxtK5S0X758CR8fH1y+fBmMMfB4PKkbk+/KKGkTQtSdWCQ7aQuFQgiFQqkygUAAgUAg85g3b95g4sSJ2L17N1avXi0pLygowJ49e3Dw4EHJ+3T37t0LR0dHXLp0qdpnX96n0PDIwoULcfPmTRw8eBAPHz4EYwyxsbG4d+8epk+fDmdnZ2RmZirSNCGENCgmlr2Fh4fDxMREagsPD6+2vaCgIPj4+MDT01OqPCUlBWVlZVLlHTt2RMuWLZGcnCx3vAol7ZMnTyIwMBBjx46FkZFRRUN8Ptq2bYvt27ejVatWUuM4hBCirsQinsxt6dKlKCgokNqWLl0qs62ffvoJ165dqzKxZ2VlQVdXF02bNpUqt7a2RlZWltzxKjQ8kp+fj06dOgEADA0NAVT8SvCOl5cXvv76a0WaJoSQBiUul913rWko5H3Pnj3DnDlzEBcXBz09PWWFV4lCPW07OzvJTwaBQAArKyvcuHFDsv/58+c0r5sQwgmMyd5qIyUlBTk5OejRowe0tbWhra2Nc+fOYcuWLdDW1oa1tTVKS0uRn58vdVx2djZsbGzkPo9CPW13d3fExcVJ3g85duxYrF27FlpaWhCLxYiIiIC3t7ciTRNCSIMSi5Qz83nQoEG4deuWVFlAQAA6duyIxYsXo0WLFtDR0UF8fDxGjRoFALh79y6ePn0KV1dXuc+jUNIODg5GXFwchEIhBAIBQkJCkJ6eLpkt4u7uji1btijSNCGENCimpNX8jIyM0LlzZ6kyAwMDmJubS8q/+uorBAcHw8zMDMbGxpg1axZcXV3lnjkCKJi0u3TpIvVKMVNTU5w5cwb5+fnQ0tKS3JwkhBB1JxI33DOGmzZtAp/Px6hRoyAUCuHt7Y0dO3bUqg2FXoJQk4MHDyI6OhqnT59WdtMKoQWjNAstGKVZ6rpg1O12Q2Xuc8w4Wae260OdnoiU5dGjR4iPj6+PpgkhRKmYmFuTJuolaRNCCFc05PCIMlDSJoRoNBH1tAkhhDtYHVfza2iUtAkhGq3R9rQ/XGKwOjk5OQoFU1+Od6HVBjWJuT5NOSXya7Rj2mZmZnI/mm5ubg5HR0eFgyKEkIainu9cl03upJ2YmFiPYRBCiGo02p42IYQ0RiI00jFtQghpjMQcGx+hpE0I0Wgijr3fnJI2IUSj0fAIIYRwiJJWZm0wlLQJIRpNo3raz58/R1JSEnJycjBq1Cg0b94cIpEIBQUFMDExgZaWlrLiJISQelHOsVcjKjQCzxhDcHAwHBwcMHHiRAQHB+PevXsAKl7w26pVK2zdulWpgRJCSH1g1WzqSKGkvW7dOmzevBkLFixAXFwc3n+PgomJCXx9fXH06FGlBUkIIfWlnMeTuakjhZL27t27MXnyZKxZswbOzs6V9nft2lXS8yaEEHUmqmZTRwqNaT979gx9+/aVud/AwACFhYUKB0UIIQ2FY4v8KZa0rays8OzZM5n7U1JS0LJlS4WDIoSQhsK12SMKDY/4+voiMjISDx/+3wtz360AePr0aURHR2P06NHKiZAQQupROU/2po4UStqhoaGwtbWFs7MzJk+eDB6Ph++//x79+vXDkCFD0LVrV3z99dfKjpUQQpROI2aPmJiY4NKlS1i0aBGeP38OPT09nDt3Dvn5+Vi5ciXOnz+PJk2aKDtWQghROq71tBV+uEZfXx/Lli3DsmXLlBkPIYQ0KJGaJmdZ6DF2QohG04i1R7788ssa6/B4POzZs0eR5gkhpMGo63xsWRRK2mfPnq30vkiRSIR///0XIpEIlpaWMDAwUEqAhBBSn9R17FoWhZL248ePqywvKytDVFQUIiIiEBcXV5e4CCGkQXBteESpr2zQ0dHBzJkz4eXlhZkzZyqzaUIIqRcinuxNHdXLe3a6deuGpKSk+miaEEKUSiPWHqlJXFwczdMmhHCCWG0fo6maQkk7LCysyvL8/HwkJSXh2rVrWLJkSZ0CI4SQhqCuPWpZFEraISEhVZabmpqiTZs2iIyMxNSpU+sSFyGENAiuzR5RaExbLBZXueXl5eHy5cuYNm1apSmBhBCijsRgMrfaCA8PR69evWBkZAQrKyuMHDkSd+/elapTUlKCoKAgmJubw9DQEKNGjUJ2dnatzlPrpF1cXIzg4GD8+uuvtT2UEELUjrJuRJ47dw5BQUG4dOkS4uLiUFZWBi8vLxQVFUnqzJs3D7/++iuOHDmCc+fOITMzE76+vrU6T62HR/T19REVFQUnJ6faHkoIIWpHpKQbkadOnZL6HB0dDSsrK6SkpMDd3R0FBQXYs2cPDh48iI8//hgAsHfvXjg6OuLSpUvo06ePXOdRaHjExcUFaWlpihxKCCFqRVzNJhQKUVhYKLUJhUK52i0oKAAAmJmZAah4OUxZWRk8PT0ldTp27IiWLVsiOTlZ7ngVStoRERH46aef8MMPP6C8vFyRJgghRC2IwGRu4eHhMDExkdrCw8NrbFMsFmPu3Llwc3ND586dAQBZWVnQ1dVF06ZNpepaW1sjKytL7njlHh5JSkqCo6MjLC0t4efnBz6fj8DAQMyePRvNmjWDvr6+VH0ej4cbN27IHQipvY6zhqPZ0J4wamsHUUkp8q5m4Obqn/Dmwb+SOgb2Vui2cgIsPuoAvq4OshJu4Po3MRDm0js8G6NZ86ZiWch87NoRg+VLa04upPrhkaVLlyI4OFiqTCAQ1NhmUFAQ0tLScOHChTrH9yG5k/bAgQOxf/9+jB8/Hubm5rCwsECHDh2UHhCRn6VrR9zfewavUh+Ap62FLkvHwP2nJYh1XwRRsRBa+gK4/7QE+X8/ReLnawAAnRd/jn4/LkC8z0qAceuhAlI95x6dMTlgLNJv3VF1KJxS3dojAoFAriT9vpkzZ+K3335DUlISmjdvLim3sbFBaWkp8vPzpXrb2dnZsLGxkbt9uZM2Ywzsf/8nT0xMlPsEpP6cn7BW6vPluVEYkRYJ024OyL10BxYftYdBC0vEDf4G5W+KK+rMjsTIO7tg1c8JOefTVRE2qQdNDJpgx+71mD97OeYumKHqcDhFWTciGWOYNWsWjh07hsTERDg4OEjtd3FxgY6ODuLj4zFq1CgAwN27d/H06VO4urrKfZ56WXuEqIaOUcXSAaWv3gAA+LraYIxBXFomqSMWloGJGSw+ot+SGpPv1q/AmdhEJCXKf0OLVCgHk7nVRlBQEPbv34+DBw/CyMgIWVlZyMrKQnFxRYfJxMQEX331FYKDg5GQkICUlBQEBATA1dVV7pkjQC2TtqofmHn27FmNL2Co6m5vGePag6oK4PHgHDYJuZfvovDuPwCAvGv3IXorRJdl46ClrwstfQG6rpgAvrYW9KybqjZeojQjRw1F125O+DZ0o6pD4SRWzX+1sXPnThQUFGDAgAGwtbWVbIcOHZLU2bRpE4YNG4ZRo0bB3d0dNjY2+Pnnn2t1nlol7S+++AJaWlpybdrayl+L6uXLl4iJiam2TlV3e4+9afzDAD3C/WHSsTkuTd8mKSvNe43kaVtgN7gHPru/ByPv7YauiQFe3XwEiGk8uzGwa2aD1d99jf83dQGEwlJVh8NJ1c0eqY13Q8gfbv7+/pI6enp62L59O16+fImioiL8/PPPtRrPBmr5cI2npyfat29fqxPUxi+//FLt/ocPH9bYRlV3e39rP61Ocam77t/6wdazOxI+W4Xif19K7cs+dwt/uAZD18wQrFyMssK3+PTGdrx5kqOiaIkydXPuBEsrC8Ql/V9vTVtbG65uPfHltIloYdkVYjHXlvlvWOUcuyFfq6Tt5+eHCRMm1FcsGDlyJHg8nuSGZ1VqGqKp6m6vDk9LKfGpo+7f+qHZkJ5IHLUab5+9kFmv9GXFOLelmxMEFsbIPH2toUIk9Sjp3CV49PlUqixixxrcv/cQ2yJ+oIQtB26lbDV7G7utrS127NiBESNGVLk/NTUVLi4uDRyV+uoe7o+Wn/XFxYCNKHtTAoGlCQCg7PVbiEsqbj62GuuOwoxMCPMKYd6zHZzDJuHerlNSc7kJdxW9KcKd2xlSZW+LivHqZX6lclI1EcdeOKZWSdvFxQUpKSkyk3ZNvXBN09Z/MABg4M/Lpcovz4nCk8MVbw4yamOLLl+PhW5TQxQ9e4HbW04gI+qPBo+VEHVV21kiqqZWSXvhwoVSK2J9qG3btkhISGjAiNTbEduJNda5teYQbq05VGM90nj4Dpus6hA4pbazRFRN7qTdEGNj/fv3r3a/gYEBPDw86j0OQojmEHHst3e16mkTQkhDo+ERQgjhkEY7PEIIIY2RiNHsEUII4QxlLRjVUChpE0I0Wm1f4KtqlLQJIRqNhkcIIYRDKGkTQgiHcGtwhJI2IUTDldPaI4QQwh00PEIIIRxCD9cQQgiHUE+bEEI4hJI2IYRwCA2PEEIIh1BPmxBCOISSNiGEcIiYXoJACCHcQT1tQgjhEDETqTqEWqGkTQjRaLQ0KyGEcAgNjxBCCIeIxJS0CSGEM+jhGkII4RAaHiGEEA5hNE+bEEK4g8a0CSGEQ2h4hBBCOIRrj7HzVR0AIYSokoiJZW6K2L59O1q1agU9PT307t0bly9fVmq8lLQJIRpNzMQyt9o6dOgQgoODsXLlSly7dg3dunWDt7c3cnJylBYvJW1CiEZjjMncamvjxo2YOnUqAgIC4OTkhMjISDRp0gT/+c9/lBYvJW1CiEYTMyZzEwqFKCwslNqEQmGV7ZSWliIlJQWenp6SMj6fD09PTyQnJystXo24ETn63wOqDqHBCYVChIeHY+nSpRAIBKoOp0GNVnUAKqDJf991VV76XOa+kJAQhIaGSpWtXLkSISEhlerm5uZCJBLB2tpaqtza2hp37txRSqwAwGNcm1lO5FJYWAgTExMUFBTA2NhY1eGQekZ/3/VDKBRW6lkLBIIqfzBmZmaiWbNm+PPPP+Hq6iopX7RoEc6dO4e//vpLKTFpRE+bEEIUIStBV8XCwgJaWlrIzs6WKs/OzoaNjY3SYqIxbUIIUQJdXV24uLggPj5eUiYWixEfHy/V864r6mkTQoiSBAcHw8/PDz179sRHH32EiIgIFBUVISAgQGnnoKTdSAkEAqxcuZJuSmkI+vtWD2PHjsWLFy+wYsUKZGVlwdnZGadOnap0c7Iu6EYkIYRwCI1pE0IIh1DSJoQQDqGkTQghHEJJmxBCOISSdiNV38tDEvWQlJSETz/9FHZ2duDxeDh+/LiqQyL1jJJ2I9QQy0MS9VBUVIRu3bph+/btqg6FNBCa8tcI9e7dG7169cK2bdsAVDyV1aJFC8yaNQtLlixRcXSkvvB4PBw7dgwjR45UdSikHlFPu5FpqOUhCSGqQUm7kaluecisrCwVRUUIURZK2oQQwiGUtBuZhloekhCiGpS0G5mGWh6SEKIatMpfI9QQy0MS9fDmzRvcv39f8vnRo0dITU2FmZkZWrZsqcLISH2hKX+N1LZt27Bu3TrJ8pBbtmxB7969VR0WUbLExEQMHDiwUrmfnx+io6MbPiBS7yhpE0IIh9CYNiGEcAglbUII4RBK2oQQwiGUtAkhhEMoaRNCCIdQ0iaEEA6hpE0IIRxCSZsQQjiEkjapN61atYK/v7/kc2JiIng8HhITE1UW04c+jLEhDBgwAJ07d1Zqm6q4DqIalLQbqejoaPB4PMmmp6eH9u3bY+bMmZVWAFR3J0+eREhIiEpj4PF4mDlzpkpjIASgBaMavbCwMDg4OKCkpAQXLlzAzp07cfLkSaSlpaFJkyYNGou7uzuKi4uhq6tbq+NOnjyJ7du3qzxxE6IOKGk3ckOGDEHPnj0BAFOmTIG5uTk2btyIEydOYPz48VUeU1RUBAMDA6XHwufzoaenp/R2CdEkNDyiYT7++GMAFUt4AoC/vz8MDQ3x4MEDDB06FEZGRpg4cSKAinW4IyIi0KlTJ+jp6cHa2hqBgYF49eqVVJuMMaxevRrNmzdHkyZNMHDgQKSnp1c6t6wx7b/++gtDhw6FqakpDAwM0LVrV2zevFkS37s3jb8/3POOsmOsixMnTsDHxwd2dnYQCARo06YNVq1aBZFIVGX9lJQU9O3bF/r6+nBwcEBkZGSlOkKhECtXrkTbtm0hEAjQokULLFq0CEKhUKmxE+6gnraGefDgAQDA3NxcUlZeXg5vb2/069cP69evlwybBAYGIjo6GgEBAZg9ezYePXqEbdu24fr167h48SJ0dHQAACtWrMDq1asxdOhQDB06FNeuXYOXlxdKS0trjCcuLg7Dhg2Dra0t5syZAxsbG9y+fRu//fYb5syZg8DAQGRmZiIuLg779u2rdHxDxCiv6OhoGBoaIjg4GIaGhjh79ixWrFiBwsJCrFu3Tqruq1evMHToUIwZMwbjx4/H4cOHMWPGDOjq6uLLL78EUPEDafjw4bhw4QKmTZsGR0dH3Lp1C5s2bcK9e/dw/PhxpcVOOISRRmnv3r0MADtz5gx78eIFe/bsGfvpp5+Yubk509fXZ//88w9jjDE/Pz8GgC1ZskTq+PPnzzMA7MCBA1Llp06dkirPyclhurq6zMfHh4nFYkm9r7/+mgFgfn5+krKEhAQGgCUkJDDGGCsvL2cODg7M3t6evXr1Suo877cVFBTEqvqnWh8xygKABQUFVVvn7du3lcoCAwNZkyZNWElJiaTMw8ODAWAbNmyQlAmFQubs7MysrKxYaWkpY4yxffv2MT6fz86fPy/VZmRkJAPALl68KCmzt7eX6zoI99HwSCPn6ekJS0tLtGjRAuPGjYOhoSGOHTuGZs2aSdWbMWOG1OcjR47AxMQEgwcPRm5urmRzcXGBoaEhEhISAABnzpxBaWkpZs2aJTVsMXfu3Bpju379Oh49eoS5c+eiadOmUvveb0uWhoixNvT19SV/fv36NXJzc9G/f3+8ffsWd+7ckaqrra2NwMBAyWddXV0EBgYiJycHKSkpkutzdHREx44dpa7v3RDXu+sjmoWGRxq57du3o3379tDW1oa1tTU6dOgAPl/6Z7W2tjaaN28uVZaRkYGCggJYWVlV2W5OTg4A4MmTJwCAdu3aSe23tLSEqalptbG9G6pRdM5yQ8RYG+np6Vi2bBnOnj2LwsJCqX0FBQVSn+3s7Crd7G3fvj0A4PHjx+jTpw8yMjJw+/ZtWFpaVnm+d9dHNAsl7Ubuo48+kswekUUgEFRK5GKxGFZWVjhw4ECVx8hKJA1JnWLMz8+Hh4cHjI2NERYWhjZt2kBPTw/Xrl3D4sWLIRaLa92mWCxGly5dsHHjxir3t2jRoq5hEw6ipE2q1KZNG5w5cwZubm5Sv/Z/yN7eHkBFr7d169aS8hcvXlSawVHVOQAgLS0Nnp6eMuvJGippiBjllZiYiLy8PPz8889wd3eXlL+bpfOhzMzMSlMr7927B6Di6Uag4vpu3LiBQYMGyTVcRDQDjWmTKo0ZMwYikQirVq2qtK+8vBz5+fkAKsbMdXR0sHXrVrD3XjcaERFR4zl69OgBBwcHRERESNp75/223iW2D+s0RIzy0tLSqhR3aWkpduzYUWX98vJyREVFSdWNioqCpaUlXFxcAFRc3/Pnz7F79+5KxxcXF6OoqEhp8RPuoJ42qZKHhwcCAwMRHh6O1NRUeHl5QUdHBxkZGThy5Ag2b96Mzz//HJaWlliwYAHCw8MxbNgwDB06FNevX8cff/wBCwuLas/B5/Oxc+dOfPrpp3B2dkZAQABsbW1x584dpKenIzY2FgAkSWz27Nnw9vaGlpYWxo0b1yAxvu/q1atYvXp1pfIBAwagb9++MDU1hZ+fH2bPng0ej4d9+/ZJJfH32dnZ4fvvv8fjx4/Rvn17HDp0CKmpqdi1a5dkmuKkSZNw+PBhTJ8+HQkJCXBzc4NIJMKdO3dw+PBhxMbG1jj0RRohlc5dIfXm3ZS/K1euVFvPz8+PGRgYyNy/a9cu5uLiwvT19ZmRkRHr0qULW7RoEcvMzJTUEYlELDQ0lNna2jJ9fX02YMAAlpaWVmka2odT/t65cOECGzx4MDMyMmIGBgasa9eubOvWrZL95eXlbNasWczS0pLxeLxK0/+UGaMsAGRuq1atYowxdvHiRdanTx+mr6/P7Ozs2KJFi1hsbGyla/bw8GCdOnViV69eZa6urkxPT4/Z29uzbdu2VTpvaWkp+/7771mnTp2YQCBgpqamzMXFhYWGhrKCggJJPZrypzl4jMnoChBCCFE7NKZNCCEcQkmbEEI4hJI2IYRwCCVtQgjhEErahBDCIZS0CSGEQyhpE0IIh1DSJoQQDqGkTQghHEJJmxBCOISSNiGEcAglbUII4ZD/D69e6xrsMIdkAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      1.00      0.83        69\n",
            "           1       1.00      0.12      0.22        33\n",
            "\n",
            "    accuracy                           0.72       102\n",
            "   macro avg       0.85      0.56      0.52       102\n",
            "weighted avg       0.80      0.72      0.63       102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"lgbm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHLHgabcnysD",
        "outputId": "52cd82f3-219a-423d-b2a2-f4f97cc20b6b"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000063 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000066 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000069 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000065 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000065 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000065 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000065 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000066 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000063 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n",
            "       frontal  central  parietal  occipital\n",
            "theta    63.73    64.71     58.82      58.82\n",
            "alpha    68.63    66.67     60.78      63.73\n",
            "beta     63.73    62.75     62.75      63.73\n",
            "gamma    71.57    65.69     68.63      67.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"lgbm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7RfoknLn90T",
        "outputId": "b443f040-2e49-4b3a-c3ac-e6f371b86990"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000066 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000067 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000066 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000065 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000069 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000069 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000072 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000070 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000073 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "[LightGBM] [Info] Number of positive: 230, number of negative: 692\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000066 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249458 -> initscore=-1.101507\n",
            "[LightGBM] [Info] Start training from score -1.101507\n",
            "       frontal  central  parietal  occipital\n",
            "theta    65.69    68.63     64.71      69.61\n",
            "alpha    68.63    72.55     69.61      71.57\n",
            "beta     68.63    66.67     70.59      69.61\n",
            "gamma    68.63    74.51     71.57      70.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"lgbm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXpblqNyoDsM",
        "outputId": "876182de-399d-4214-e907-2c5538cd8f9f"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000070 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000070 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000070 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000075 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000073 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000077 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "[LightGBM] [Info] Number of positive: 210, number of negative: 712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227766 -> initscore=-1.220970\n",
            "[LightGBM] [Info] Start training from score -1.220970\n",
            "       frontal  central  parietal  occipital\n",
            "theta    80.39    78.43     80.39      76.47\n",
            "alpha    81.37    86.27     79.41      73.53\n",
            "beta     77.45    76.47     79.41      80.39\n",
            "gamma    84.31    79.41     83.33      73.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"lgbm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u-SszMVoFo6",
        "outputId": "d9061152-9cbd-4a70-acba-a8497838c954"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000066 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000079 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000067 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000065 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000065 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000067 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000066 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "[LightGBM] [Info] Number of positive: 234, number of negative: 688\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253796 -> initscore=-1.078468\n",
            "[LightGBM] [Info] Start training from score -1.078468\n",
            "       frontal  central  parietal  occipital\n",
            "theta    74.51    74.51     72.55      67.65\n",
            "alpha    76.47    75.49     79.41      75.49\n",
            "beta     73.53    77.45     73.53      74.51\n",
            "gamma    75.49    77.45     73.53      71.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_conf(\"gamma\",\"frontal\",\"HAHV\",\"lgbm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "et0Q7VqujgZh",
        "outputId": "4b4b4309-6f95-4558-9a2e-f789aea868b5"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 248, number of negative: 674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 922, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268980 -> initscore=-0.999801\n",
            "[LightGBM] [Info] Start training from score -0.999801\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79        69\n",
            "           1       0.57      0.52      0.54        33\n",
            "\n",
            "    accuracy                           0.72       102\n",
            "   macro avg       0.67      0.66      0.67       102\n",
            "weighted avg       0.71      0.72      0.71       102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"gpc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJGDn8dVoIS0",
        "outputId": "c515e961-e39f-47f5-e07f-afbc3ffe38cb"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    67.65    67.65     67.65      67.65\n",
            "alpha    67.65    67.65     67.65      67.65\n",
            "beta     67.65    67.65     67.65      67.65\n",
            "gamma    67.65    67.65     67.65      65.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"gpc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peDp-nMaoPit",
        "outputId": "22609ebb-3d96-4d9c-936e-bfa1173b6f9f"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    71.57    71.57     71.57      72.55\n",
            "alpha    71.57    71.57     71.57      72.55\n",
            "beta     71.57    71.57     71.57      72.55\n",
            "gamma    71.57    71.57     71.57      71.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"gpc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35McLer6oSSg",
        "outputId": "606ed5d0-b071-44da-a755-89393675bff0"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    81.37    81.37     81.37      81.37\n",
            "alpha    81.37    81.37     81.37      81.37\n",
            "beta     81.37    81.37     81.37      82.35\n",
            "gamma    81.37    80.39     81.37      81.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"gpc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWMhm_XAoVDl",
        "outputId": "604a58a8-7322-48cb-a036-013cc286af24"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    78.43    79.41     79.41      78.43\n",
            "alpha    78.43    79.41     79.41      78.43\n",
            "beta     79.41    79.41     79.41      78.43\n",
            "gamma    79.41    79.41     78.43      77.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_conf(\"gamma\",\"frontal\",\"HAHV\",\"gpc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "H7O13D9tj6xg",
        "outputId": "79c376cd-63df-4185-91f8-406c617510bb"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      1.00      0.81        69\n",
            "           1       0.00      0.00      0.00        33\n",
            "\n",
            "    accuracy                           0.68       102\n",
            "   macro avg       0.34      0.50      0.40       102\n",
            "weighted avg       0.46      0.68      0.55       102\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"per\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo4ffCb7oZ2x",
        "outputId": "de5235ab-d8da-4487-fe11-44aec400f7ba"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    55.88    57.84     59.80      59.80\n",
            "alpha    40.20    57.84     56.86      48.04\n",
            "beta     62.75    53.92     50.00      62.75\n",
            "gamma    58.82    57.84     39.22      61.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"per\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfEA3KWLoc9e",
        "outputId": "1d1d410d-bd6b-4555-e802-1b4f46c589b2"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    65.69    38.24     56.86      31.37\n",
            "alpha    36.27    38.24     57.84      49.02\n",
            "beta     64.71    43.14     58.82      32.35\n",
            "gamma    63.73    37.25     44.12      71.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"per\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5BnwXVfogUL",
        "outputId": "fb494462-256e-43e5-8d93-8460d40683da"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    79.41    73.53     70.59      76.47\n",
            "alpha    74.51    78.43     74.51      53.92\n",
            "beta     81.37    51.96     68.63      74.51\n",
            "gamma    81.37    81.37     70.59      78.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"per\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXjBfPXJoorP",
        "outputId": "555f4e6f-bf72-4fbe-8fee-f70c0a5f27b8"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    61.76    53.92     70.59      42.16\n",
            "alpha    67.65    70.59     72.55      36.27\n",
            "beta     47.06    68.63     56.86      69.61\n",
            "gamma    66.67    53.92     31.37      62.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_conf(\"beta\",\"frontal\",\"HAHV\",\"per\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "DaktHoYJkJcR",
        "outputId": "c22b1456-e1b6-4c24-baf9-19322da5c36c"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.90      0.77        69\n",
            "           1       0.22      0.06      0.10        33\n",
            "\n",
            "    accuracy                           0.63       102\n",
            "   macro avg       0.44      0.48      0.43       102\n",
            "weighted avg       0.52      0.63      0.55       102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"cb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLC_cx8Jorcu",
        "outputId": "f916a5d4-baeb-4fc2-b7f9-132669ccc4ce"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    62.75    66.67     58.82      56.86\n",
            "alpha    65.69    67.65     63.73      62.75\n",
            "beta     66.67    65.69     61.76      59.80\n",
            "gamma    64.71    60.78     71.57      71.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"cb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLm53vGeowND",
        "outputId": "6f7944b4-01d6-4e57-a94a-25e739b75e8f"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    72.55    70.59     65.69      68.63\n",
            "alpha    66.67    72.55     68.63      69.61\n",
            "beta     64.71    69.61     64.71      68.63\n",
            "gamma    65.69    77.45     68.63      64.71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"cb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poVbrGLKozIC",
        "outputId": "30397d63-09c8-4e63-8972-0be073951c99"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    79.41    78.43     77.45      77.45\n",
            "alpha    78.43    79.41     76.47      74.51\n",
            "beta     82.35    74.51     80.39      78.43\n",
            "gamma    78.43    80.39     83.33      77.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"cb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDs9Xl3_o173",
        "outputId": "27568e9a-ec9d-44ae-f023-6aafc89b53ec"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    70.59    71.57     72.55      68.63\n",
            "alpha    73.53    76.47     80.39      80.39\n",
            "beta     72.55    75.49     75.49      73.53\n",
            "gamma    71.57    73.53     74.51      70.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_conf(\"gamma\",\"parietal\",\"HAHV\",\"cb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "aZMdDpHtkaH3",
        "outputId": "81c9ea48-a68c-419d-bea7-41c2b3098cb1"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.86      0.80        69\n",
            "           1       0.58      0.42      0.49        33\n",
            "\n",
            "    accuracy                           0.72       102\n",
            "   macro avg       0.67      0.64      0.65       102\n",
            "weighted avg       0.70      0.72      0.70       102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"cnn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BJq0tCp5h3c",
        "outputId": "ed213184-e044-4821-d081-1b91c886518f"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 9ms/step - loss: 0.7798 - accuracy: 0.6143 - val_loss: 0.6435 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.6777 - val_loss: 0.6229 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.6885 - val_loss: 0.6120 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.6914 - val_loss: 0.6104 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.7051 - val_loss: 0.6101 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.7080 - val_loss: 0.6140 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.7168 - val_loss: 0.6077 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.6963 - val_loss: 0.6076 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.7109 - val_loss: 0.6009 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.7197 - val_loss: 0.6011 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.7158 - val_loss: 0.6026 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.7158 - val_loss: 0.6059 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.7168 - val_loss: 0.6055 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.7188 - val_loss: 0.6035 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6025 - accuracy: 0.7256 - val_loss: 0.6080 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.7168 - val_loss: 0.6014 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.7188 - val_loss: 0.6066 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.7246 - val_loss: 0.6042 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.7178 - val_loss: 0.6064 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.7207 - val_loss: 0.6102 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7253 - accuracy: 0.6836 - val_loss: 0.6570 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.6758 - val_loss: 0.6541 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.7070 - val_loss: 0.6409 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.7109 - val_loss: 0.6355 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.7100 - val_loss: 0.6263 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6776 - accuracy: 0.7129 - val_loss: 0.6270 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.7090 - val_loss: 0.6167 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.7080 - val_loss: 0.6196 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7109 - val_loss: 0.6249 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.7090 - val_loss: 0.6442 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.7148 - val_loss: 0.6179 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.7061 - val_loss: 0.6273 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6444 - accuracy: 0.7148 - val_loss: 0.6288 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.7090 - val_loss: 0.6319 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.7197 - val_loss: 0.6207 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.7129 - val_loss: 0.6230 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.7197 - val_loss: 0.6217 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.7197 - val_loss: 0.6200 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.7256 - val_loss: 0.6188 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.7207 - val_loss: 0.6168 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7800 - accuracy: 0.6074 - val_loss: 0.7472 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.6855 - val_loss: 0.6206 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7010 - accuracy: 0.6650 - val_loss: 0.6275 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.6953 - val_loss: 0.6080 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.6924 - val_loss: 0.6109 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.6992 - val_loss: 0.6096 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.6992 - val_loss: 0.6093 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.7197 - val_loss: 0.6118 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.7031 - val_loss: 0.6138 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.7100 - val_loss: 0.6057 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6267 - accuracy: 0.7109 - val_loss: 0.6068 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.7207 - val_loss: 0.6114 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.7207 - val_loss: 0.6086 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.7158 - val_loss: 0.6086 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.7188 - val_loss: 0.6136 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.7178 - val_loss: 0.6100 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.7227 - val_loss: 0.6142 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6045 - accuracy: 0.7188 - val_loss: 0.6097 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6016 - accuracy: 0.7178 - val_loss: 0.6128 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.7217 - val_loss: 0.6139 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 9ms/step - loss: 0.8381 - accuracy: 0.5879 - val_loss: 0.6630 - val_accuracy: 0.6680\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.7031 - val_loss: 0.6263 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.7061 - val_loss: 0.6142 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.7002 - val_loss: 0.6128 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.6963 - val_loss: 0.6140 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.7100 - val_loss: 0.6284 - val_accuracy: 0.6875\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.7139 - val_loss: 0.6296 - val_accuracy: 0.6836\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.7100 - val_loss: 0.6403 - val_accuracy: 0.6797\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.7158 - val_loss: 0.6135 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.7168 - val_loss: 0.6229 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.7168 - val_loss: 0.6060 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.7168 - val_loss: 0.6353 - val_accuracy: 0.6719\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.7148 - val_loss: 0.6049 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.7158 - val_loss: 0.6077 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.7217 - val_loss: 0.6177 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.7148 - val_loss: 0.6028 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6195 - accuracy: 0.7158 - val_loss: 0.6176 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.7227 - val_loss: 0.6152 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.7178 - val_loss: 0.6064 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.7207 - val_loss: 0.6076 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7412 - accuracy: 0.6758 - val_loss: 0.6561 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7260 - accuracy: 0.6904 - val_loss: 0.6487 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.7148 - val_loss: 0.6246 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.6875 - val_loss: 0.6239 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.7021 - val_loss: 0.6200 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.7002 - val_loss: 0.6148 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.6982 - val_loss: 0.6052 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.7109 - val_loss: 0.6100 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.7139 - val_loss: 0.6088 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.7002 - val_loss: 0.6082 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.7236 - val_loss: 0.6049 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.7188 - val_loss: 0.6084 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.7051 - val_loss: 0.6061 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7129 - val_loss: 0.6116 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.7100 - val_loss: 0.6090 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6221 - accuracy: 0.7109 - val_loss: 0.6101 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.7178 - val_loss: 0.6052 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.7129 - val_loss: 0.6039 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.7236 - val_loss: 0.6049 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.7139 - val_loss: 0.6052 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7795 - accuracy: 0.6602 - val_loss: 0.6719 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.6807 - val_loss: 0.6290 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6498 - accuracy: 0.7051 - val_loss: 0.6357 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6859 - accuracy: 0.6943 - val_loss: 0.6667 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.7061 - val_loss: 0.6361 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6504 - accuracy: 0.7158 - val_loss: 0.6149 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.6982 - val_loss: 0.6331 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.7119 - val_loss: 0.6263 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.7070 - val_loss: 0.6173 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.7158 - val_loss: 0.6213 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.7090 - val_loss: 0.6488 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.7129 - val_loss: 0.6291 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6250 - accuracy: 0.7119 - val_loss: 0.6222 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6135 - accuracy: 0.7188 - val_loss: 0.6290 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.7109 - val_loss: 0.6310 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.7295 - val_loss: 0.6275 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.7197 - val_loss: 0.6191 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.7178 - val_loss: 0.6327 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.7217 - val_loss: 0.6387 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6139 - accuracy: 0.7158 - val_loss: 0.6304 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6304 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 11ms/step - loss: 0.8963 - accuracy: 0.5586 - val_loss: 0.7025 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.7165 - accuracy: 0.6494 - val_loss: 0.6271 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.7061 - val_loss: 0.6221 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6597 - accuracy: 0.6768 - val_loss: 0.6131 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.7012 - val_loss: 0.6146 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6303 - accuracy: 0.6943 - val_loss: 0.6083 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.7080 - val_loss: 0.6147 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6416 - accuracy: 0.7080 - val_loss: 0.6145 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6251 - accuracy: 0.7061 - val_loss: 0.6004 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.7051 - val_loss: 0.6044 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.7100 - val_loss: 0.6043 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.7148 - val_loss: 0.6036 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.7139 - val_loss: 0.6064 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.7217 - val_loss: 0.6098 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.7129 - val_loss: 0.6086 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.7207 - val_loss: 0.6143 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.7217 - val_loss: 0.6212 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.7188 - val_loss: 0.6143 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.7188 - val_loss: 0.6154 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.7256 - val_loss: 0.6203 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 8ms/step - loss: 0.7688 - accuracy: 0.6348 - val_loss: 0.6992 - val_accuracy: 0.6094\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7125 - accuracy: 0.6660 - val_loss: 0.6805 - val_accuracy: 0.6211\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6787 - accuracy: 0.6826 - val_loss: 0.6144 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6979 - accuracy: 0.6729 - val_loss: 0.6259 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.6953 - val_loss: 0.6163 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.7119 - val_loss: 0.6223 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6875 - val_loss: 0.6109 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.7061 - val_loss: 0.6073 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.7119 - val_loss: 0.6058 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.7061 - val_loss: 0.6032 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7139 - val_loss: 0.6019 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.7178 - val_loss: 0.6047 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.7119 - val_loss: 0.6035 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.7197 - val_loss: 0.6028 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6016 - accuracy: 0.7129 - val_loss: 0.5997 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.7188 - val_loss: 0.6051 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.7178 - val_loss: 0.6129 - val_accuracy: 0.6953\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.7246 - val_loss: 0.6032 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.7178 - val_loss: 0.6059 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.7197 - val_loss: 0.6019 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7220 - accuracy: 0.6719 - val_loss: 0.6921 - val_accuracy: 0.6250\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6991 - accuracy: 0.6934 - val_loss: 0.6936 - val_accuracy: 0.6367\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.6982 - val_loss: 0.6614 - val_accuracy: 0.6641\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.7031 - val_loss: 0.6340 - val_accuracy: 0.6719\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.7109 - val_loss: 0.6290 - val_accuracy: 0.6758\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7012 - val_loss: 0.6108 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6094 - accuracy: 0.7148 - val_loss: 0.6147 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.7090 - val_loss: 0.6323 - val_accuracy: 0.6797\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.7129 - val_loss: 0.6108 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6094 - accuracy: 0.7217 - val_loss: 0.6275 - val_accuracy: 0.6758\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.7100 - val_loss: 0.6127 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.7070 - val_loss: 0.6053 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5972 - accuracy: 0.7256 - val_loss: 0.6073 - val_accuracy: 0.6875\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.7246 - val_loss: 0.6121 - val_accuracy: 0.6836\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6125 - accuracy: 0.7236 - val_loss: 0.6157 - val_accuracy: 0.6758\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.7168 - val_loss: 0.6093 - val_accuracy: 0.6914\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.7217 - val_loss: 0.6081 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6109 - accuracy: 0.7197 - val_loss: 0.6041 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6009 - accuracy: 0.7256 - val_loss: 0.6040 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.7236 - val_loss: 0.6017 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 11ms/step - loss: 0.7964 - accuracy: 0.6406 - val_loss: 0.8610 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.6836 - val_loss: 0.7421 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6904 - val_loss: 0.6671 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.6973 - val_loss: 0.6409 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.7002 - val_loss: 0.6333 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.7148 - val_loss: 0.6237 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.7080 - val_loss: 0.6220 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.7041 - val_loss: 0.6229 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.7139 - val_loss: 0.6359 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.7227 - val_loss: 0.6225 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.7119 - val_loss: 0.6270 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6240 - accuracy: 0.7178 - val_loss: 0.6274 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.7148 - val_loss: 0.6237 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.7100 - val_loss: 0.6201 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.7168 - val_loss: 0.6244 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6150 - accuracy: 0.7217 - val_loss: 0.6167 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.7217 - val_loss: 0.6191 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.7158 - val_loss: 0.6219 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.7217 - val_loss: 0.6195 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.7188 - val_loss: 0.6209 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 9ms/step - loss: 0.6871 - accuracy: 0.6797 - val_loss: 0.6585 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6885 - val_loss: 0.7898 - val_accuracy: 0.6172\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.7012 - val_loss: 0.6595 - val_accuracy: 0.6484\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.7100 - val_loss: 0.6890 - val_accuracy: 0.6328\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6228 - accuracy: 0.7158 - val_loss: 0.6502 - val_accuracy: 0.6562\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.7090 - val_loss: 0.6289 - val_accuracy: 0.6797\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.7197 - val_loss: 0.6336 - val_accuracy: 0.6758\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.7266 - val_loss: 0.6201 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.7041 - val_loss: 0.6137 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.7188 - val_loss: 0.6198 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6201 - accuracy: 0.7227 - val_loss: 0.6135 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.7217 - val_loss: 0.6167 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.7227 - val_loss: 0.6140 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.7227 - val_loss: 0.6199 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.7275 - val_loss: 0.6132 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.7227 - val_loss: 0.6152 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.7266 - val_loss: 0.6170 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.7217 - val_loss: 0.6137 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.7236 - val_loss: 0.6170 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7246 - val_loss: 0.6208 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7368 - accuracy: 0.6201 - val_loss: 0.6416 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.6875 - val_loss: 0.6170 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.7031 - val_loss: 0.6282 - val_accuracy: 0.6836\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.7021 - val_loss: 0.6057 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.7139 - val_loss: 0.6171 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6271 - accuracy: 0.7090 - val_loss: 0.6083 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.7090 - val_loss: 0.6084 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.7139 - val_loss: 0.6063 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.7139 - val_loss: 0.6117 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.7100 - val_loss: 0.6096 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.7188 - val_loss: 0.6089 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.7178 - val_loss: 0.6048 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.7197 - val_loss: 0.6053 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.7227 - val_loss: 0.6132 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.7207 - val_loss: 0.6107 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.7168 - val_loss: 0.6061 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.7227 - val_loss: 0.6128 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.7236 - val_loss: 0.6115 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.7236 - val_loss: 0.6105 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.7227 - val_loss: 0.6174 - val_accuracy: 0.6836\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.6836\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 11ms/step - loss: 0.6920 - accuracy: 0.6895 - val_loss: 0.7124 - val_accuracy: 0.5312\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.6934 - val_loss: 0.6800 - val_accuracy: 0.6602\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.7080 - val_loss: 0.6594 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6298 - accuracy: 0.7031 - val_loss: 0.6646 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6258 - accuracy: 0.7139 - val_loss: 0.6684 - val_accuracy: 0.6875\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6101 - accuracy: 0.7109 - val_loss: 0.6447 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.7119 - val_loss: 0.6457 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.7188 - val_loss: 0.6470 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.7236 - val_loss: 0.6501 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6005 - accuracy: 0.7197 - val_loss: 0.6504 - val_accuracy: 0.6641\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5965 - accuracy: 0.7188 - val_loss: 0.6401 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5953 - accuracy: 0.7207 - val_loss: 0.6353 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6021 - accuracy: 0.7168 - val_loss: 0.6427 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.7246 - val_loss: 0.6331 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.7217 - val_loss: 0.6295 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.7197 - val_loss: 0.6406 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.7207 - val_loss: 0.6459 - val_accuracy: 0.6875\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.7197 - val_loss: 0.6470 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6010 - accuracy: 0.7236 - val_loss: 0.6515 - val_accuracy: 0.6836\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.7168 - val_loss: 0.6410 - val_accuracy: 0.6914\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6914\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7291 - accuracy: 0.7148 - val_loss: 0.7150 - val_accuracy: 0.3828\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.7041 - val_loss: 0.6763 - val_accuracy: 0.6328\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.7100 - val_loss: 0.6721 - val_accuracy: 0.6562\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.6992 - val_loss: 0.6725 - val_accuracy: 0.6562\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.7021 - val_loss: 0.6595 - val_accuracy: 0.6758\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.7100 - val_loss: 0.6947 - val_accuracy: 0.6289\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.7139 - val_loss: 0.6456 - val_accuracy: 0.6914\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.7090 - val_loss: 0.6538 - val_accuracy: 0.6367\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7090 - val_loss: 0.6230 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.7080 - val_loss: 0.6241 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.7158 - val_loss: 0.6272 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6133 - accuracy: 0.7139 - val_loss: 0.6203 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.7090 - val_loss: 0.6453 - val_accuracy: 0.6367\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.7168 - val_loss: 0.6258 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.7188 - val_loss: 0.6247 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.7207 - val_loss: 0.6276 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.7197 - val_loss: 0.6251 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7197 - val_loss: 0.6168 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6031 - accuracy: 0.7256 - val_loss: 0.6162 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.7139 - val_loss: 0.6167 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7347 - accuracy: 0.6377 - val_loss: 0.6996 - val_accuracy: 0.6602\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.6758 - val_loss: 0.6402 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 0.6982 - val_loss: 0.6410 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.7012 - val_loss: 0.6204 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6787 - accuracy: 0.6953 - val_loss: 0.6228 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.7002 - val_loss: 0.6125 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7129 - val_loss: 0.6089 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.7100 - val_loss: 0.6182 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7119 - val_loss: 0.6047 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7090 - val_loss: 0.6050 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.6973 - val_loss: 0.6045 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.7129 - val_loss: 0.6045 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.7197 - val_loss: 0.6047 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.7148 - val_loss: 0.6078 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.7266 - val_loss: 0.6054 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6160 - accuracy: 0.7080 - val_loss: 0.6027 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.7100 - val_loss: 0.6037 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.7217 - val_loss: 0.6072 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.7168 - val_loss: 0.6007 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6080 - accuracy: 0.7119 - val_loss: 0.6092 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 12ms/step - loss: 0.7587 - accuracy: 0.6016 - val_loss: 0.6400 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6898 - accuracy: 0.6865 - val_loss: 0.6421 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6597 - accuracy: 0.6992 - val_loss: 0.6374 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7002 - val_loss: 0.6327 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.7080 - val_loss: 0.6389 - val_accuracy: 0.6953\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.7080 - val_loss: 0.6274 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.7148 - val_loss: 0.6251 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.7129 - val_loss: 0.6254 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.7148 - val_loss: 0.6264 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.7178 - val_loss: 0.6282 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6102 - accuracy: 0.7119 - val_loss: 0.6281 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.7168 - val_loss: 0.6278 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.7090 - val_loss: 0.6247 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.7197 - val_loss: 0.6229 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.7256 - val_loss: 0.6186 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.7227 - val_loss: 0.6151 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.7178 - val_loss: 0.6189 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.7246 - val_loss: 0.6192 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.7227 - val_loss: 0.6184 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5941 - accuracy: 0.7158 - val_loss: 0.6203 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6992\n",
            "         frontal    central   parietal  occipital\n",
            "theta  69.921875  69.921875  69.921875  69.921875\n",
            "alpha  69.921875  69.921875  69.921875  69.921875\n",
            "beta   69.921875  69.921875  69.921875  68.359375\n",
            "gamma  69.140625  69.921875  69.921875  69.921875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"cnn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEcNSdJ25tkP",
        "outputId": "fdcde2e1-5f40-4d32-977a-d39ba5a7efba"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7227 - accuracy: 0.6631 - val_loss: 0.6681 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.7012 - val_loss: 0.6322 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.7246 - val_loss: 0.6146 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.7158 - val_loss: 0.6183 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.7334 - val_loss: 0.6124 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6252 - accuracy: 0.7227 - val_loss: 0.6057 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.7256 - val_loss: 0.6268 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.7393 - val_loss: 0.6196 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.7422 - val_loss: 0.6235 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.7412 - val_loss: 0.6372 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.7363 - val_loss: 0.6030 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.7412 - val_loss: 0.6115 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.7412 - val_loss: 0.5916 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.7432 - val_loss: 0.5988 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.7471 - val_loss: 0.5736 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.7471 - val_loss: 0.5782 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.7344 - val_loss: 0.5874 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7471 - val_loss: 0.5902 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7441 - val_loss: 0.5812 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.7461 - val_loss: 0.5946 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 8ms/step - loss: 0.8501 - accuracy: 0.5801 - val_loss: 0.9429 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7342 - accuracy: 0.6855 - val_loss: 0.6069 - val_accuracy: 0.7422\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.7188 - val_loss: 0.5908 - val_accuracy: 0.7461\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.7119 - val_loss: 0.5821 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.7188 - val_loss: 0.5826 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.7178 - val_loss: 0.5662 - val_accuracy: 0.7500\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.7324 - val_loss: 0.5717 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.7197 - val_loss: 0.5922 - val_accuracy: 0.7305\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6290 - accuracy: 0.7363 - val_loss: 0.6061 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.7344 - val_loss: 0.5726 - val_accuracy: 0.7422\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.7354 - val_loss: 0.5706 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7412 - val_loss: 0.5727 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.7402 - val_loss: 0.5765 - val_accuracy: 0.7266\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5890 - accuracy: 0.7334 - val_loss: 0.5767 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6070 - accuracy: 0.7373 - val_loss: 0.5633 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.7383 - val_loss: 0.5612 - val_accuracy: 0.7578\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7402 - val_loss: 0.5607 - val_accuracy: 0.7578\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.7393 - val_loss: 0.5760 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7402 - val_loss: 0.5792 - val_accuracy: 0.7227\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7432 - val_loss: 0.5778 - val_accuracy: 0.7266\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.7266\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 12ms/step - loss: 0.7132 - accuracy: 0.6533 - val_loss: 0.6604 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6643 - accuracy: 0.7090 - val_loss: 0.6533 - val_accuracy: 0.6523\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.7070 - val_loss: 0.6113 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6435 - accuracy: 0.7070 - val_loss: 0.5994 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.7148 - val_loss: 0.5955 - val_accuracy: 0.7383\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.7354 - val_loss: 0.5915 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6050 - accuracy: 0.7314 - val_loss: 0.5890 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6133 - accuracy: 0.7256 - val_loss: 0.5844 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6082 - accuracy: 0.7295 - val_loss: 0.6013 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.7393 - val_loss: 0.5831 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5960 - accuracy: 0.7402 - val_loss: 0.5786 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.7383 - val_loss: 0.5645 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.7373 - val_loss: 0.5726 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.7393 - val_loss: 0.5851 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.7422 - val_loss: 0.5811 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.7393 - val_loss: 0.5727 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5872 - accuracy: 0.7441 - val_loss: 0.5758 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.7451 - val_loss: 0.5696 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.7432 - val_loss: 0.5626 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.7451 - val_loss: 0.5663 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6632 - accuracy: 0.7061 - val_loss: 0.6874 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.7285 - val_loss: 0.6654 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7334 - val_loss: 0.7095 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.7354 - val_loss: 0.6424 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.7354 - val_loss: 0.6411 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.7373 - val_loss: 0.6395 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.7373 - val_loss: 0.6460 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.7412 - val_loss: 0.6350 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.7451 - val_loss: 0.5820 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.7402 - val_loss: 0.6252 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.7471 - val_loss: 0.6284 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7451 - val_loss: 0.5664 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5814 - accuracy: 0.7461 - val_loss: 0.5911 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.7412 - val_loss: 0.5778 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.7363 - val_loss: 0.5953 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.7402 - val_loss: 0.5922 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.7383 - val_loss: 0.6096 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.7432 - val_loss: 0.5813 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.7422 - val_loss: 0.5693 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.7451 - val_loss: 0.5821 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7529 - accuracy: 0.6162 - val_loss: 0.9148 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.7061 - val_loss: 0.7054 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.7207 - val_loss: 0.6451 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.7236 - val_loss: 0.6455 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.7305 - val_loss: 0.6085 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.7373 - val_loss: 0.6097 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.7344 - val_loss: 0.6243 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6051 - accuracy: 0.7305 - val_loss: 0.6078 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.7354 - val_loss: 0.6062 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.7363 - val_loss: 0.6429 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.7402 - val_loss: 0.5876 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.7441 - val_loss: 0.5781 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.7393 - val_loss: 0.6127 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.7402 - val_loss: 0.5926 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7412 - val_loss: 0.6139 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.7441 - val_loss: 0.6277 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7451 - val_loss: 0.5883 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7432 - val_loss: 0.6004 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7451 - val_loss: 0.5878 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7432 - val_loss: 0.6073 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6911 - accuracy: 0.6934 - val_loss: 0.6336 - val_accuracy: 0.7344\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6771 - accuracy: 0.7148 - val_loss: 0.6237 - val_accuracy: 0.7383\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.7246 - val_loss: 0.6010 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6419 - accuracy: 0.7158 - val_loss: 0.5912 - val_accuracy: 0.7422\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.7314 - val_loss: 0.5886 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.7266 - val_loss: 0.6167 - val_accuracy: 0.7227\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.7412 - val_loss: 0.6137 - val_accuracy: 0.7266\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6296 - accuracy: 0.7256 - val_loss: 0.5728 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6029 - accuracy: 0.7354 - val_loss: 0.6292 - val_accuracy: 0.7227\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.7285 - val_loss: 0.5653 - val_accuracy: 0.7422\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.7412 - val_loss: 0.5765 - val_accuracy: 0.7227\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.7334 - val_loss: 0.5646 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.7383 - val_loss: 0.5879 - val_accuracy: 0.7305\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.7383 - val_loss: 0.5832 - val_accuracy: 0.7305\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.7412 - val_loss: 0.5758 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5876 - accuracy: 0.7422 - val_loss: 0.5836 - val_accuracy: 0.7266\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5717 - accuracy: 0.7393 - val_loss: 0.5747 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.7432 - val_loss: 0.5830 - val_accuracy: 0.7305\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6042 - accuracy: 0.7334 - val_loss: 0.5731 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5809 - accuracy: 0.7480 - val_loss: 0.5779 - val_accuracy: 0.7227\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7227\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6722 - accuracy: 0.7158 - val_loss: 0.7376 - val_accuracy: 0.6602\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.7148 - val_loss: 0.6890 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.7236 - val_loss: 0.6759 - val_accuracy: 0.5703\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.7178 - val_loss: 0.6698 - val_accuracy: 0.6289\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.7266 - val_loss: 0.6329 - val_accuracy: 0.7305\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.7373 - val_loss: 0.6600 - val_accuracy: 0.6875\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.7344 - val_loss: 0.5986 - val_accuracy: 0.7578\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.7383 - val_loss: 0.5981 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.7402 - val_loss: 0.5908 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.7383 - val_loss: 0.6023 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.7373 - val_loss: 0.5743 - val_accuracy: 0.7500\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.7402 - val_loss: 0.5831 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5895 - accuracy: 0.7373 - val_loss: 0.5852 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.7461 - val_loss: 0.5832 - val_accuracy: 0.7344\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5980 - accuracy: 0.7422 - val_loss: 0.5749 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.7422 - val_loss: 0.5868 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.7432 - val_loss: 0.5817 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.7363 - val_loss: 0.5755 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.7432 - val_loss: 0.5725 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.7422 - val_loss: 0.5669 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7527 - accuracy: 0.6279 - val_loss: 0.8358 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6487 - accuracy: 0.7178 - val_loss: 0.7240 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7266 - val_loss: 0.6495 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.7217 - val_loss: 0.5976 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.7373 - val_loss: 0.6068 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.7314 - val_loss: 0.6002 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.7393 - val_loss: 0.5804 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.7314 - val_loss: 0.5646 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.7246 - val_loss: 0.5793 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.7354 - val_loss: 0.5669 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6050 - accuracy: 0.7344 - val_loss: 0.6101 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.7373 - val_loss: 0.6152 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.7363 - val_loss: 0.5905 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.7363 - val_loss: 0.6151 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7422 - val_loss: 0.6005 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.7412 - val_loss: 0.5795 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.7393 - val_loss: 0.5822 - val_accuracy: 0.7461\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.7412 - val_loss: 0.5972 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.7471 - val_loss: 0.5792 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7432 - val_loss: 0.5879 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7550 - accuracy: 0.6543 - val_loss: 0.8531 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.7061 - val_loss: 0.7020 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.7266 - val_loss: 0.6402 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6283 - accuracy: 0.7227 - val_loss: 0.6155 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6290 - accuracy: 0.7266 - val_loss: 0.6179 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.7354 - val_loss: 0.5964 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.7441 - val_loss: 0.6065 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.7334 - val_loss: 0.6077 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.7402 - val_loss: 0.5929 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.7344 - val_loss: 0.6121 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6025 - accuracy: 0.7402 - val_loss: 0.5720 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5885 - accuracy: 0.7422 - val_loss: 0.5852 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7461 - val_loss: 0.5812 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7432 - val_loss: 0.5868 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5748 - accuracy: 0.7451 - val_loss: 0.6109 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.7441 - val_loss: 0.5767 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.7441 - val_loss: 0.5828 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.7393 - val_loss: 0.5846 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5859 - accuracy: 0.7480 - val_loss: 0.5735 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.7422 - val_loss: 0.5815 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 14ms/step - loss: 0.7213 - accuracy: 0.6494 - val_loss: 0.6359 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6287 - accuracy: 0.7217 - val_loss: 0.6315 - val_accuracy: 0.7305\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7236 - val_loss: 0.6202 - val_accuracy: 0.7305\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.7373 - val_loss: 0.6046 - val_accuracy: 0.7305\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.7393 - val_loss: 0.5898 - val_accuracy: 0.7461\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.7285 - val_loss: 0.5753 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.7432 - val_loss: 0.5874 - val_accuracy: 0.7266\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.7314 - val_loss: 0.5723 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.7363 - val_loss: 0.5841 - val_accuracy: 0.7266\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.7314 - val_loss: 0.5705 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.7461 - val_loss: 0.5727 - val_accuracy: 0.7227\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.7354 - val_loss: 0.5631 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.7383 - val_loss: 0.5699 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.7354 - val_loss: 0.5637 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.7402 - val_loss: 0.5763 - val_accuracy: 0.7266\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.7393 - val_loss: 0.5681 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.7383 - val_loss: 0.5627 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7373 - val_loss: 0.5666 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.7422 - val_loss: 0.5691 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.7383 - val_loss: 0.5739 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6997 - accuracy: 0.6982 - val_loss: 0.7761 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7264 - accuracy: 0.7012 - val_loss: 0.6703 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.7090 - val_loss: 0.6490 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.7246 - val_loss: 0.6175 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.7275 - val_loss: 0.6060 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.7295 - val_loss: 0.5904 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7285 - val_loss: 0.5882 - val_accuracy: 0.7500\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.7344 - val_loss: 0.5906 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.7383 - val_loss: 0.5891 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.7344 - val_loss: 0.5862 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.7295 - val_loss: 0.5882 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.7344 - val_loss: 0.5919 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5879 - accuracy: 0.7383 - val_loss: 0.5899 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6025 - accuracy: 0.7402 - val_loss: 0.5851 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.7383 - val_loss: 0.5820 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.7383 - val_loss: 0.5719 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7402 - val_loss: 0.5730 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.7451 - val_loss: 0.5666 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.7373 - val_loss: 0.5724 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.7422 - val_loss: 0.5630 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7179 - accuracy: 0.6621 - val_loss: 0.6369 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.7129 - val_loss: 0.6159 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6498 - accuracy: 0.7168 - val_loss: 0.6291 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.7266 - val_loss: 0.6044 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.7256 - val_loss: 0.5940 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.7373 - val_loss: 0.5763 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6028 - accuracy: 0.7422 - val_loss: 0.5754 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.7305 - val_loss: 0.5906 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.7461 - val_loss: 0.5701 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.7344 - val_loss: 0.5688 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.7451 - val_loss: 0.5787 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.7363 - val_loss: 0.5674 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.7354 - val_loss: 0.5710 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7451 - val_loss: 0.5825 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.7354 - val_loss: 0.5893 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5828 - accuracy: 0.7441 - val_loss: 0.5661 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.7344 - val_loss: 0.5660 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7393 - val_loss: 0.5676 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.7383 - val_loss: 0.5706 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.7461 - val_loss: 0.5627 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 11ms/step - loss: 0.6558 - accuracy: 0.6943 - val_loss: 0.7101 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.6953 - val_loss: 0.6174 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.7148 - val_loss: 0.6228 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6163 - accuracy: 0.7324 - val_loss: 0.6042 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5972 - accuracy: 0.7344 - val_loss: 0.5933 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5971 - accuracy: 0.7393 - val_loss: 0.5853 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5910 - accuracy: 0.7402 - val_loss: 0.5726 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.7393 - val_loss: 0.5710 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.7363 - val_loss: 0.5692 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.7402 - val_loss: 0.5642 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6038 - accuracy: 0.7402 - val_loss: 0.5721 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.7422 - val_loss: 0.5745 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5920 - accuracy: 0.7393 - val_loss: 0.5748 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5766 - accuracy: 0.7461 - val_loss: 0.5780 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.7422 - val_loss: 0.5716 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7422 - val_loss: 0.5746 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7451 - val_loss: 0.5689 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7480 - val_loss: 0.5750 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7461 - val_loss: 0.5770 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.7432 - val_loss: 0.5710 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7156 - accuracy: 0.6914 - val_loss: 0.6391 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.7285 - val_loss: 0.6198 - val_accuracy: 0.7500\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.7148 - val_loss: 0.6169 - val_accuracy: 0.7148\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.7236 - val_loss: 0.5888 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.7432 - val_loss: 0.5887 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7256 - val_loss: 0.5782 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.7402 - val_loss: 0.5883 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.7246 - val_loss: 0.5813 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6137 - accuracy: 0.7324 - val_loss: 0.5714 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.7344 - val_loss: 0.5762 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.7373 - val_loss: 0.5713 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6012 - accuracy: 0.7363 - val_loss: 0.5672 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.7412 - val_loss: 0.5670 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.7402 - val_loss: 0.5750 - val_accuracy: 0.7422\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.7432 - val_loss: 0.5862 - val_accuracy: 0.7383\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.7402 - val_loss: 0.5766 - val_accuracy: 0.7578\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.7393 - val_loss: 0.5793 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.7373 - val_loss: 0.5831 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7422 - val_loss: 0.5734 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.7461 - val_loss: 0.5710 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.8384 - accuracy: 0.6016 - val_loss: 0.6583 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.7129 - val_loss: 0.6095 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.7100 - val_loss: 0.6318 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6215 - accuracy: 0.7197 - val_loss: 0.5814 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6283 - accuracy: 0.7168 - val_loss: 0.5678 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.7256 - val_loss: 0.5797 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.7373 - val_loss: 0.5815 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7227 - val_loss: 0.5722 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.7344 - val_loss: 0.5793 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.7344 - val_loss: 0.5723 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.7373 - val_loss: 0.5685 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.7363 - val_loss: 0.5766 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.7422 - val_loss: 0.5724 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.7383 - val_loss: 0.5850 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.7393 - val_loss: 0.5747 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.7441 - val_loss: 0.5737 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.7432 - val_loss: 0.5725 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.7412 - val_loss: 0.5708 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.7412 - val_loss: 0.5715 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.7412 - val_loss: 0.5759 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 11ms/step - loss: 0.6613 - accuracy: 0.7021 - val_loss: 0.6492 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.7227 - val_loss: 0.6412 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6428 - accuracy: 0.7363 - val_loss: 0.6156 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.7256 - val_loss: 0.5811 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6297 - accuracy: 0.7227 - val_loss: 0.5782 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6234 - accuracy: 0.7305 - val_loss: 0.5974 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.7373 - val_loss: 0.5861 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.7402 - val_loss: 0.5733 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.7334 - val_loss: 0.5952 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5875 - accuracy: 0.7441 - val_loss: 0.5837 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.7451 - val_loss: 0.5818 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5774 - accuracy: 0.7432 - val_loss: 0.5706 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5812 - accuracy: 0.7451 - val_loss: 0.5686 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.7373 - val_loss: 0.5815 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.7461 - val_loss: 0.5723 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5887 - accuracy: 0.7363 - val_loss: 0.5709 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.7441 - val_loss: 0.5697 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.7441 - val_loss: 0.5643 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5868 - accuracy: 0.7412 - val_loss: 0.5697 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.7461 - val_loss: 0.5654 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7539\n",
            "         frontal    central   parietal  occipital\n",
            "theta  75.390625  72.656250  75.390625  75.390625\n",
            "alpha  75.390625  72.265625  75.390625  75.390625\n",
            "beta   75.390625  75.390625  75.390625  75.390625\n",
            "gamma  75.390625  75.390625  75.390625  75.390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"cnn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3f2GJMB5zSf",
        "outputId": "36c4cacb-96a4-4256-c2bb-787d6a0eeb39"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7535 - accuracy: 0.6152 - val_loss: 0.5834 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.7402 - val_loss: 0.6262 - val_accuracy: 0.7578\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.7451 - val_loss: 0.5557 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.7539 - val_loss: 0.5508 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.7627 - val_loss: 0.5862 - val_accuracy: 0.7461\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7627 - val_loss: 0.5363 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.7598 - val_loss: 0.5223 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7695 - val_loss: 0.5433 - val_accuracy: 0.7773\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7656 - val_loss: 0.5241 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7637 - val_loss: 0.5208 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.7627 - val_loss: 0.5262 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7715 - val_loss: 0.5200 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7656 - val_loss: 0.5199 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7734 - val_loss: 0.5275 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.7607 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7695 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7686 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7705 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7686 - val_loss: 0.5248 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7744 - val_loss: 0.5233 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6015 - accuracy: 0.7383 - val_loss: 0.6073 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.7490 - val_loss: 0.5551 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.7549 - val_loss: 0.5886 - val_accuracy: 0.7812\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.7588 - val_loss: 0.5384 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.7705 - val_loss: 0.5393 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7656 - val_loss: 0.5394 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.7637 - val_loss: 0.5253 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7656 - val_loss: 0.5189 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7734 - val_loss: 0.5403 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.7734 - val_loss: 0.5195 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.7705 - val_loss: 0.5294 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7705 - val_loss: 0.5237 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7695 - val_loss: 0.5173 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.7725 - val_loss: 0.5322 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.7676 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7705 - val_loss: 0.5127 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7705 - val_loss: 0.5193 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7686 - val_loss: 0.5110 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7734 - val_loss: 0.5229 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7725 - val_loss: 0.5108 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 11ms/step - loss: 0.7064 - accuracy: 0.7100 - val_loss: 0.5709 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6242 - accuracy: 0.7393 - val_loss: 0.5702 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.7598 - val_loss: 0.5760 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.7373 - val_loss: 0.5419 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5865 - accuracy: 0.7441 - val_loss: 0.5526 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.7549 - val_loss: 0.5368 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7656 - val_loss: 0.5543 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.7666 - val_loss: 0.5370 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.7568 - val_loss: 0.5542 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.7568 - val_loss: 0.5309 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.7637 - val_loss: 0.5405 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.7627 - val_loss: 0.5259 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7646 - val_loss: 0.5526 - val_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.7764 - val_loss: 0.5562 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7568 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5580 - accuracy: 0.7715 - val_loss: 0.5389 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5604 - accuracy: 0.7598 - val_loss: 0.5215 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7812 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7676 - val_loss: 0.5029 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7695 - val_loss: 0.5234 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6900 - accuracy: 0.6729 - val_loss: 0.6003 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.7383 - val_loss: 0.5828 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.7344 - val_loss: 0.5558 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.7539 - val_loss: 0.5700 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.7598 - val_loss: 0.5649 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.7549 - val_loss: 0.5388 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.7627 - val_loss: 0.5312 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.7715 - val_loss: 0.5432 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7617 - val_loss: 0.5319 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.7637 - val_loss: 0.5403 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7686 - val_loss: 0.5316 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.7646 - val_loss: 0.5388 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.7617 - val_loss: 0.5469 - val_accuracy: 0.7734\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7686 - val_loss: 0.5290 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.7607 - val_loss: 0.5296 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.7715 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7744 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7656 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7695 - val_loss: 0.5252 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7705 - val_loss: 0.5290 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6327 - accuracy: 0.7393 - val_loss: 0.5975 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.7539 - val_loss: 0.5674 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.7500 - val_loss: 0.5576 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.7520 - val_loss: 0.5525 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.7646 - val_loss: 0.5564 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7559 - val_loss: 0.5334 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7686 - val_loss: 0.5371 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7686 - val_loss: 0.5415 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7744 - val_loss: 0.5387 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.7695 - val_loss: 0.5366 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.7705 - val_loss: 0.5292 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7734 - val_loss: 0.5322 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7686 - val_loss: 0.5338 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7725 - val_loss: 0.5343 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.7676 - val_loss: 0.5267 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7715 - val_loss: 0.5346 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7646 - val_loss: 0.5390 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7705 - val_loss: 0.5299 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7725 - val_loss: 0.5319 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7754 - val_loss: 0.5385 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6691 - accuracy: 0.7305 - val_loss: 0.6155 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.7441 - val_loss: 0.5483 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.7607 - val_loss: 0.5322 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.7510 - val_loss: 0.5303 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.7637 - val_loss: 0.5371 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7686 - val_loss: 0.5289 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7646 - val_loss: 0.5258 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.7568 - val_loss: 0.5432 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5530 - accuracy: 0.7656 - val_loss: 0.5531 - val_accuracy: 0.7695\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5538 - accuracy: 0.7666 - val_loss: 0.5460 - val_accuracy: 0.7617\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.7705 - val_loss: 0.5350 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5602 - accuracy: 0.7754 - val_loss: 0.5396 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5464 - accuracy: 0.7705 - val_loss: 0.5463 - val_accuracy: 0.7617\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.7734 - val_loss: 0.5313 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.7686 - val_loss: 0.5373 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7686 - val_loss: 0.5334 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7754 - val_loss: 0.5213 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.7725 - val_loss: 0.5278 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7715 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7705 - val_loss: 0.5222 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 8ms/step - loss: 0.6607 - accuracy: 0.7266 - val_loss: 0.5868 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.7559 - val_loss: 0.6528 - val_accuracy: 0.7070\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.7559 - val_loss: 0.6261 - val_accuracy: 0.7383\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.7578 - val_loss: 0.5773 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.7676 - val_loss: 0.5710 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5759 - accuracy: 0.7607 - val_loss: 0.5589 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7656 - val_loss: 0.5681 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.7676 - val_loss: 0.5637 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7637 - val_loss: 0.5444 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7705 - val_loss: 0.5481 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7617 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7715 - val_loss: 0.5491 - val_accuracy: 0.7891\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5658 - accuracy: 0.7686 - val_loss: 0.5592 - val_accuracy: 0.7578\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.7715 - val_loss: 0.5585 - val_accuracy: 0.7578\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5459 - accuracy: 0.7646 - val_loss: 0.5371 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.7607 - val_loss: 0.6020 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7754 - val_loss: 0.5712 - val_accuracy: 0.7422\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7705 - val_loss: 0.5799 - val_accuracy: 0.7305\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7754 - val_loss: 0.5734 - val_accuracy: 0.7383\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7725 - val_loss: 0.6041 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6041 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6430 - accuracy: 0.7324 - val_loss: 0.6299 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7578 - val_loss: 0.5793 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.7676 - val_loss: 0.5697 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.7490 - val_loss: 0.5525 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7637 - val_loss: 0.5605 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.7666 - val_loss: 0.5495 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7646 - val_loss: 0.5435 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.7617 - val_loss: 0.5395 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7695 - val_loss: 0.5505 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.7715 - val_loss: 0.5375 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.7695 - val_loss: 0.5363 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7686 - val_loss: 0.5380 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.7676 - val_loss: 0.5364 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7588 - val_loss: 0.5432 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7725 - val_loss: 0.5341 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7705 - val_loss: 0.5414 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7686 - val_loss: 0.5343 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.7744 - val_loss: 0.5407 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7695 - val_loss: 0.5486 - val_accuracy: 0.7852\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7705 - val_loss: 0.5392 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6959 - accuracy: 0.7295 - val_loss: 0.5739 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.7422 - val_loss: 0.5532 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.7510 - val_loss: 0.5482 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.7617 - val_loss: 0.5440 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.7607 - val_loss: 0.5410 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.7588 - val_loss: 0.5450 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.7529 - val_loss: 0.5466 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7646 - val_loss: 0.5482 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7676 - val_loss: 0.5326 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.7686 - val_loss: 0.5361 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7695 - val_loss: 0.5200 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7646 - val_loss: 0.5330 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7627 - val_loss: 0.5402 - val_accuracy: 0.7773\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7637 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7764 - val_loss: 0.5282 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7666 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7734 - val_loss: 0.5183 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7715 - val_loss: 0.5218 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.7744 - val_loss: 0.5304 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7764 - val_loss: 0.5439 - val_accuracy: 0.7734\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7734\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 10ms/step - loss: 0.6641 - accuracy: 0.7148 - val_loss: 0.5701 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.7490 - val_loss: 0.5538 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5828 - accuracy: 0.7637 - val_loss: 0.5442 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.7510 - val_loss: 0.5375 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5697 - accuracy: 0.7627 - val_loss: 0.5211 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.7656 - val_loss: 0.5158 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.7588 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5879 - accuracy: 0.7598 - val_loss: 0.5143 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.7646 - val_loss: 0.5359 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5601 - accuracy: 0.7656 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5475 - accuracy: 0.7637 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5633 - accuracy: 0.7705 - val_loss: 0.5271 - val_accuracy: 0.7891\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7666 - val_loss: 0.5367 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7676 - val_loss: 0.5288 - val_accuracy: 0.7773\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7744 - val_loss: 0.5267 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7744 - val_loss: 0.5257 - val_accuracy: 0.7891\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7725 - val_loss: 0.5303 - val_accuracy: 0.7812\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7686 - val_loss: 0.5315 - val_accuracy: 0.7578\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7676 - val_loss: 0.5235 - val_accuracy: 0.7891\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7773 - val_loss: 0.5242 - val_accuracy: 0.7812\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7812\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 9ms/step - loss: 0.7322 - accuracy: 0.6162 - val_loss: 0.5881 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.7461 - val_loss: 0.5581 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.7568 - val_loss: 0.5448 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5934 - accuracy: 0.7559 - val_loss: 0.5314 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.7510 - val_loss: 0.5302 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.7578 - val_loss: 0.5269 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.7578 - val_loss: 0.5397 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.7646 - val_loss: 0.5314 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.7656 - val_loss: 0.5363 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7637 - val_loss: 0.5251 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7666 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.7646 - val_loss: 0.5201 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.7676 - val_loss: 0.5153 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7637 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7705 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7725 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7725 - val_loss: 0.5203 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.7744 - val_loss: 0.5145 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.7744 - val_loss: 0.5232 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7676 - val_loss: 0.5228 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6751 - accuracy: 0.6738 - val_loss: 0.6064 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.7588 - val_loss: 0.5897 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.7627 - val_loss: 0.5734 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.7646 - val_loss: 0.5652 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.7676 - val_loss: 0.5549 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7656 - val_loss: 0.5465 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.7607 - val_loss: 0.5500 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7617 - val_loss: 0.5416 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5653 - accuracy: 0.7734 - val_loss: 0.5506 - val_accuracy: 0.7773\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.7617 - val_loss: 0.5347 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7676 - val_loss: 0.5405 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7666 - val_loss: 0.5393 - val_accuracy: 0.7852\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7646 - val_loss: 0.5402 - val_accuracy: 0.7891\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.7646 - val_loss: 0.5597 - val_accuracy: 0.7773\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.7754 - val_loss: 0.5430 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7754 - val_loss: 0.5287 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7676 - val_loss: 0.5342 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7744 - val_loss: 0.5320 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7676 - val_loss: 0.5357 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7705 - val_loss: 0.5352 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 11ms/step - loss: 0.6663 - accuracy: 0.7002 - val_loss: 0.5938 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.7510 - val_loss: 0.5651 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.7490 - val_loss: 0.5465 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.7598 - val_loss: 0.5459 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.7588 - val_loss: 0.5420 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.7646 - val_loss: 0.5259 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5786 - accuracy: 0.7725 - val_loss: 0.5404 - val_accuracy: 0.7773\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.7725 - val_loss: 0.5290 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.7754 - val_loss: 0.5287 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.7715 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5706 - accuracy: 0.7705 - val_loss: 0.5210 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.7627 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5551 - accuracy: 0.7676 - val_loss: 0.5237 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.7764 - val_loss: 0.5161 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.7715 - val_loss: 0.5129 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.7725 - val_loss: 0.5285 - val_accuracy: 0.7773\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7754 - val_loss: 0.5071 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.7705 - val_loss: 0.5092 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.7725 - val_loss: 0.5099 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7754 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6984 - accuracy: 0.6914 - val_loss: 0.6354 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.7529 - val_loss: 0.5660 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7646 - val_loss: 0.5901 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7598 - val_loss: 0.5378 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.7607 - val_loss: 0.5384 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.7695 - val_loss: 0.5378 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6014 - accuracy: 0.7588 - val_loss: 0.5409 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7549 - val_loss: 0.5343 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.7617 - val_loss: 0.5352 - val_accuracy: 0.7891\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7617 - val_loss: 0.5374 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.7764 - val_loss: 0.5335 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.7695 - val_loss: 0.5457 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.7686 - val_loss: 0.5362 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.7646 - val_loss: 0.5392 - val_accuracy: 0.7734\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.7686 - val_loss: 0.5432 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5447 - accuracy: 0.7686 - val_loss: 0.5324 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7725 - val_loss: 0.5413 - val_accuracy: 0.7500\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7686 - val_loss: 0.5291 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.7705 - val_loss: 0.5411 - val_accuracy: 0.7617\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7676 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7500\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 9ms/step - loss: 0.7264 - accuracy: 0.6641 - val_loss: 0.6093 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.7256 - val_loss: 0.5783 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.7500 - val_loss: 0.5583 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.7510 - val_loss: 0.5381 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.7607 - val_loss: 0.5411 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.7520 - val_loss: 0.5344 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.7617 - val_loss: 0.5455 - val_accuracy: 0.7891\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7539 - val_loss: 0.5437 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.7705 - val_loss: 0.5433 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.7578 - val_loss: 0.5396 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.7607 - val_loss: 0.5326 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7598 - val_loss: 0.5393 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.7656 - val_loss: 0.5307 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7754 - val_loss: 0.5311 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.7666 - val_loss: 0.5333 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7764 - val_loss: 0.5327 - val_accuracy: 0.7812\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7764 - val_loss: 0.5365 - val_accuracy: 0.7773\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7666 - val_loss: 0.5394 - val_accuracy: 0.7773\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7715 - val_loss: 0.5327 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.7744 - val_loss: 0.5383 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7459 - accuracy: 0.6738 - val_loss: 0.6113 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.7275 - val_loss: 0.6459 - val_accuracy: 0.7617\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6487 - accuracy: 0.7402 - val_loss: 0.5754 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.7471 - val_loss: 0.5763 - val_accuracy: 0.7812\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.7559 - val_loss: 0.5569 - val_accuracy: 0.7773\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7549 - val_loss: 0.5439 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7676 - val_loss: 0.5376 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.7617 - val_loss: 0.5338 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.7705 - val_loss: 0.5333 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5792 - accuracy: 0.7598 - val_loss: 0.5351 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7676 - val_loss: 0.5268 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.7705 - val_loss: 0.5297 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.7676 - val_loss: 0.5308 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5582 - accuracy: 0.7725 - val_loss: 0.5196 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5648 - accuracy: 0.7676 - val_loss: 0.5260 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5466 - accuracy: 0.7744 - val_loss: 0.5297 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7705 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5513 - accuracy: 0.7695 - val_loss: 0.5279 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.7725 - val_loss: 0.5317 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7705 - val_loss: 0.5302 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7930\n",
            "         frontal    central   parietal  occipital\n",
            "theta  79.296875  79.296875  79.296875  79.296875\n",
            "alpha  79.296875  79.296875  69.921875  79.296875\n",
            "beta   77.343750  78.125000  79.296875  79.296875\n",
            "gamma  79.296875  75.000000  79.296875  79.296875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"cnn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdsHvSdZ53Cs",
        "outputId": "c75daab5-4c5b-4d0b-ed0d-735c9ad24091"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 9ms/step - loss: 0.6840 - accuracy: 0.6992 - val_loss: 0.7790 - val_accuracy: 0.5898\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6222 - accuracy: 0.7314 - val_loss: 0.7386 - val_accuracy: 0.6055\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6137 - accuracy: 0.7363 - val_loss: 0.6210 - val_accuracy: 0.7305\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.7324 - val_loss: 0.5904 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.7334 - val_loss: 0.5847 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.7334 - val_loss: 0.5819 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.7412 - val_loss: 0.5793 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.7432 - val_loss: 0.5753 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7451 - val_loss: 0.5797 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.7441 - val_loss: 0.5872 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.7520 - val_loss: 0.5835 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.7480 - val_loss: 0.5827 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.7402 - val_loss: 0.5875 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.7354 - val_loss: 0.5837 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.7393 - val_loss: 0.5886 - val_accuracy: 0.7383\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7510 - val_loss: 0.5823 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7461 - val_loss: 0.5806 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.7461 - val_loss: 0.6049 - val_accuracy: 0.7266\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.7334 - val_loss: 0.5872 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.7480 - val_loss: 0.5867 - val_accuracy: 0.7500\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7500\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7583 - accuracy: 0.6484 - val_loss: 0.8662 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6564 - accuracy: 0.7100 - val_loss: 0.6533 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.7109 - val_loss: 0.7009 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.7275 - val_loss: 0.6068 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.7402 - val_loss: 0.5970 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.7334 - val_loss: 0.5910 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7441 - val_loss: 0.5725 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.7373 - val_loss: 0.5607 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7432 - val_loss: 0.5627 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.7412 - val_loss: 0.5608 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.7432 - val_loss: 0.5656 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7422 - val_loss: 0.5614 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.7422 - val_loss: 0.5606 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.7461 - val_loss: 0.5603 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.7422 - val_loss: 0.5625 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7549 - val_loss: 0.5590 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7461 - val_loss: 0.5578 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7490 - val_loss: 0.5596 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7461 - val_loss: 0.5623 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7500 - val_loss: 0.5640 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 11ms/step - loss: 0.7367 - accuracy: 0.6523 - val_loss: 0.6612 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.7031 - val_loss: 0.6492 - val_accuracy: 0.6836\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6566 - accuracy: 0.7207 - val_loss: 0.6155 - val_accuracy: 0.7109\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.7236 - val_loss: 0.5758 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6191 - accuracy: 0.7285 - val_loss: 0.5726 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.7354 - val_loss: 0.5645 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.7324 - val_loss: 0.5694 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.7256 - val_loss: 0.5677 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5923 - accuracy: 0.7529 - val_loss: 0.5703 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5934 - accuracy: 0.7344 - val_loss: 0.5644 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5812 - accuracy: 0.7383 - val_loss: 0.5625 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.7451 - val_loss: 0.5575 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7441 - val_loss: 0.5637 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.7441 - val_loss: 0.5593 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7471 - val_loss: 0.5619 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5772 - accuracy: 0.7412 - val_loss: 0.5592 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7451 - val_loss: 0.5562 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7451 - val_loss: 0.5585 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.7480 - val_loss: 0.5540 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.7490 - val_loss: 0.5597 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6759 - accuracy: 0.7178 - val_loss: 0.6858 - val_accuracy: 0.7109\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.7188 - val_loss: 0.6620 - val_accuracy: 0.7148\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6624 - accuracy: 0.7217 - val_loss: 0.6248 - val_accuracy: 0.7266\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.7441 - val_loss: 0.5938 - val_accuracy: 0.7500\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.7295 - val_loss: 0.6042 - val_accuracy: 0.7227\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.7314 - val_loss: 0.5873 - val_accuracy: 0.7344\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.7461 - val_loss: 0.5708 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.7432 - val_loss: 0.5768 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7471 - val_loss: 0.5703 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.7422 - val_loss: 0.5694 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.7422 - val_loss: 0.5662 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.7432 - val_loss: 0.5734 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7480 - val_loss: 0.5712 - val_accuracy: 0.7266\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7422 - val_loss: 0.5699 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.7520 - val_loss: 0.5730 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.7451 - val_loss: 0.5563 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.7432 - val_loss: 0.5575 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7461 - val_loss: 0.5656 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7461 - val_loss: 0.5673 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7490 - val_loss: 0.5658 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7593 - accuracy: 0.6504 - val_loss: 0.6511 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.7188 - val_loss: 0.5921 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.7305 - val_loss: 0.5795 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6256 - accuracy: 0.7256 - val_loss: 0.5779 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.7275 - val_loss: 0.5754 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.7246 - val_loss: 0.5806 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.7412 - val_loss: 0.5691 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.7363 - val_loss: 0.5704 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.7363 - val_loss: 0.5752 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.7295 - val_loss: 0.5733 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.7441 - val_loss: 0.5734 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.7383 - val_loss: 0.5749 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.7402 - val_loss: 0.5694 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.7441 - val_loss: 0.5702 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.7441 - val_loss: 0.5749 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5784 - accuracy: 0.7441 - val_loss: 0.5761 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.7471 - val_loss: 0.5749 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5792 - accuracy: 0.7451 - val_loss: 0.5758 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7402 - val_loss: 0.5791 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5876 - accuracy: 0.7412 - val_loss: 0.5767 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 8ms/step - loss: 0.9285 - accuracy: 0.5186 - val_loss: 0.8021 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7239 - accuracy: 0.7051 - val_loss: 0.6035 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.7178 - val_loss: 0.5852 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.7246 - val_loss: 0.5823 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.7256 - val_loss: 0.5778 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.7236 - val_loss: 0.6147 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.7314 - val_loss: 0.5675 - val_accuracy: 0.7305\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.7363 - val_loss: 0.5838 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.7305 - val_loss: 0.5628 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.7412 - val_loss: 0.5658 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.7324 - val_loss: 0.5647 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.7422 - val_loss: 0.5657 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5914 - accuracy: 0.7383 - val_loss: 0.5717 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.7471 - val_loss: 0.5701 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.7471 - val_loss: 0.5729 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.7422 - val_loss: 0.5713 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.7412 - val_loss: 0.5621 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5858 - accuracy: 0.7363 - val_loss: 0.5657 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.7402 - val_loss: 0.5592 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.7373 - val_loss: 0.5657 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 9ms/step - loss: 0.7680 - accuracy: 0.6855 - val_loss: 0.6584 - val_accuracy: 0.7109\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.7139 - val_loss: 0.6282 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.7080 - val_loss: 0.7194 - val_accuracy: 0.6133\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7344 - val_loss: 0.5967 - val_accuracy: 0.7461\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6256 - accuracy: 0.7178 - val_loss: 0.5977 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6221 - accuracy: 0.7295 - val_loss: 0.5794 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7373 - val_loss: 0.5798 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6005 - accuracy: 0.7432 - val_loss: 0.5785 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.7266 - val_loss: 0.5751 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.7344 - val_loss: 0.5712 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.7432 - val_loss: 0.5632 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.7402 - val_loss: 0.5564 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7412 - val_loss: 0.5680 - val_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.7383 - val_loss: 0.5539 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.7432 - val_loss: 0.5607 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.7432 - val_loss: 0.5557 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.7334 - val_loss: 0.5554 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7480 - val_loss: 0.5549 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5772 - accuracy: 0.7432 - val_loss: 0.5612 - val_accuracy: 0.7461\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.7432 - val_loss: 0.5552 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6739 - accuracy: 0.7100 - val_loss: 0.6672 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.7285 - val_loss: 0.6170 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.7314 - val_loss: 0.6028 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.7393 - val_loss: 0.5828 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.7393 - val_loss: 0.5783 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.7393 - val_loss: 0.5691 - val_accuracy: 0.7227\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7471 - val_loss: 0.5646 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.7432 - val_loss: 0.5611 - val_accuracy: 0.7500\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7402 - val_loss: 0.5631 - val_accuracy: 0.7227\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.7402 - val_loss: 0.5618 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.7344 - val_loss: 0.5656 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.7451 - val_loss: 0.5672 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.7441 - val_loss: 0.5695 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7441 - val_loss: 0.5684 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.7422 - val_loss: 0.5708 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7480 - val_loss: 0.5654 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.7412 - val_loss: 0.5659 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.7461 - val_loss: 0.5664 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7480 - val_loss: 0.5672 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.7500 - val_loss: 0.5577 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 12ms/step - loss: 0.7671 - accuracy: 0.6504 - val_loss: 0.6926 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.7139 - val_loss: 0.6335 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6561 - accuracy: 0.7197 - val_loss: 0.6020 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.7334 - val_loss: 0.5900 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6187 - accuracy: 0.7305 - val_loss: 0.6023 - val_accuracy: 0.7031\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.7236 - val_loss: 0.5774 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6233 - accuracy: 0.7275 - val_loss: 0.5752 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.7373 - val_loss: 0.5757 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.7344 - val_loss: 0.5729 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.7217 - val_loss: 0.5754 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.7383 - val_loss: 0.5719 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.7432 - val_loss: 0.5725 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.7373 - val_loss: 0.5718 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.7471 - val_loss: 0.5723 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.7363 - val_loss: 0.5764 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7432 - val_loss: 0.5739 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7461 - val_loss: 0.5718 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.7422 - val_loss: 0.5687 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.7412 - val_loss: 0.5692 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.7461 - val_loss: 0.5682 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7869 - accuracy: 0.6055 - val_loss: 0.6529 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.7334 - val_loss: 0.6191 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.7422 - val_loss: 0.6072 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.7266 - val_loss: 0.5924 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.7334 - val_loss: 0.5885 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.7383 - val_loss: 0.5902 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.7432 - val_loss: 0.5728 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.7422 - val_loss: 0.5831 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7441 - val_loss: 0.5731 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.7412 - val_loss: 0.5776 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.7402 - val_loss: 0.5769 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.7393 - val_loss: 0.5743 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.7480 - val_loss: 0.5661 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7441 - val_loss: 0.5753 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.7510 - val_loss: 0.5619 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7520 - val_loss: 0.5699 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.7461 - val_loss: 0.5700 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.7500 - val_loss: 0.5640 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.7471 - val_loss: 0.5696 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7529 - val_loss: 0.5709 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 13ms/step - loss: 0.7070 - accuracy: 0.6855 - val_loss: 0.6439 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.7256 - val_loss: 0.6238 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.7373 - val_loss: 0.6188 - val_accuracy: 0.7500\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.7363 - val_loss: 0.5958 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.7334 - val_loss: 0.5890 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5889 - accuracy: 0.7402 - val_loss: 0.5835 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.7422 - val_loss: 0.5800 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5934 - accuracy: 0.7383 - val_loss: 0.5712 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.7412 - val_loss: 0.5714 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5784 - accuracy: 0.7441 - val_loss: 0.5719 - val_accuracy: 0.7500\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.7451 - val_loss: 0.5714 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5787 - accuracy: 0.7441 - val_loss: 0.5662 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.7441 - val_loss: 0.5646 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5687 - accuracy: 0.7461 - val_loss: 0.5626 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5806 - accuracy: 0.7461 - val_loss: 0.5602 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.7500 - val_loss: 0.5565 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.7461 - val_loss: 0.5604 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5731 - accuracy: 0.7500 - val_loss: 0.5562 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.7510 - val_loss: 0.5560 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7490 - val_loss: 0.5623 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7129 - accuracy: 0.6523 - val_loss: 0.6365 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.7354 - val_loss: 0.6071 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.7373 - val_loss: 0.6154 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.7412 - val_loss: 0.5840 - val_accuracy: 0.7422\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6119 - accuracy: 0.7266 - val_loss: 0.5908 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5947 - accuracy: 0.7383 - val_loss: 0.5642 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.7412 - val_loss: 0.5755 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5914 - accuracy: 0.7412 - val_loss: 0.5625 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.7441 - val_loss: 0.5634 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7510 - val_loss: 0.5625 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.7500 - val_loss: 0.5639 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.7441 - val_loss: 0.5610 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7393 - val_loss: 0.5607 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.7510 - val_loss: 0.5584 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.7471 - val_loss: 0.5633 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7520 - val_loss: 0.5622 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7480 - val_loss: 0.5681 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7451 - val_loss: 0.5650 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7500 - val_loss: 0.5662 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.7432 - val_loss: 0.5684 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7431 - accuracy: 0.6758 - val_loss: 0.6333 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.7305 - val_loss: 0.6357 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.7246 - val_loss: 0.6197 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.7236 - val_loss: 0.5955 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.7236 - val_loss: 0.5858 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.7480 - val_loss: 0.5792 - val_accuracy: 0.7578\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.7334 - val_loss: 0.5778 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.7363 - val_loss: 0.5750 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.7344 - val_loss: 0.5746 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.7461 - val_loss: 0.5693 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.7402 - val_loss: 0.5753 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.7451 - val_loss: 0.5681 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.7461 - val_loss: 0.5700 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.7432 - val_loss: 0.5701 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7422 - val_loss: 0.5689 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.7441 - val_loss: 0.5703 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7529 - val_loss: 0.5721 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.7393 - val_loss: 0.5742 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5773 - accuracy: 0.7441 - val_loss: 0.5755 - val_accuracy: 0.7500\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7422 - val_loss: 0.5742 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 11ms/step - loss: 0.7582 - accuracy: 0.7090 - val_loss: 0.6555 - val_accuracy: 0.7344\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.7133 - accuracy: 0.7188 - val_loss: 0.7279 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.7266 - val_loss: 0.6425 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6235 - accuracy: 0.7412 - val_loss: 0.6077 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6228 - accuracy: 0.7363 - val_loss: 0.6028 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6042 - accuracy: 0.7324 - val_loss: 0.6055 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6500 - accuracy: 0.7354 - val_loss: 0.6272 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6008 - accuracy: 0.7402 - val_loss: 0.5916 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.7324 - val_loss: 0.6295 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.7432 - val_loss: 0.5816 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.7373 - val_loss: 0.5840 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.7432 - val_loss: 0.5817 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.7383 - val_loss: 0.5804 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.7422 - val_loss: 0.5889 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5837 - accuracy: 0.7422 - val_loss: 0.5617 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.7451 - val_loss: 0.5838 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5843 - accuracy: 0.7471 - val_loss: 0.5616 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.7314 - val_loss: 0.5689 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.7441 - val_loss: 0.5805 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.7539 - val_loss: 0.5652 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.8745 - accuracy: 0.5889 - val_loss: 0.6530 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.7305 - val_loss: 0.6017 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.7148 - val_loss: 0.5919 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.7109 - val_loss: 0.5857 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.7236 - val_loss: 0.5810 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.7363 - val_loss: 0.5803 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.7334 - val_loss: 0.5781 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.7285 - val_loss: 0.5604 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7412 - val_loss: 0.5627 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.7373 - val_loss: 0.5557 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.7373 - val_loss: 0.5552 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.7432 - val_loss: 0.5608 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.7441 - val_loss: 0.5554 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5978 - accuracy: 0.7412 - val_loss: 0.5567 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.7471 - val_loss: 0.5557 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.7402 - val_loss: 0.5549 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7451 - val_loss: 0.5558 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7480 - val_loss: 0.5558 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.7422 - val_loss: 0.5516 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7441 - val_loss: 0.5507 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.7230 - accuracy: 0.6484 - val_loss: 0.6555 - val_accuracy: 0.7383\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.7324 - val_loss: 0.6355 - val_accuracy: 0.7422\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.7158 - val_loss: 0.6198 - val_accuracy: 0.7383\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.7441 - val_loss: 0.6022 - val_accuracy: 0.7383\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.7373 - val_loss: 0.5845 - val_accuracy: 0.7422\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.7373 - val_loss: 0.5624 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.7256 - val_loss: 0.5651 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.7461 - val_loss: 0.5619 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.7412 - val_loss: 0.5637 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.7451 - val_loss: 0.5629 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.7383 - val_loss: 0.5626 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7471 - val_loss: 0.5671 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.7373 - val_loss: 0.5657 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.7480 - val_loss: 0.5630 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5723 - accuracy: 0.7461 - val_loss: 0.5667 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.7383 - val_loss: 0.5701 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5760 - accuracy: 0.7451 - val_loss: 0.5706 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.7480 - val_loss: 0.5780 - val_accuracy: 0.7461\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5983 - accuracy: 0.7363 - val_loss: 0.5621 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5816 - accuracy: 0.7402 - val_loss: 0.5656 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7539\n",
            "         frontal    central   parietal  occipital\n",
            "theta  75.000000  75.390625  75.390625  75.390625\n",
            "alpha  75.390625  75.390625  75.390625  75.390625\n",
            "beta   75.390625  75.390625  75.390625  75.390625\n",
            "gamma  75.390625  75.390625  75.390625  75.390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"ann\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0VmjNVR5_4X",
        "outputId": "7c021485-edcd-4b62-b8ef-24f071ddf337"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6190 - accuracy: 0.7158 - val_loss: 0.6119 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.7246 - val_loss: 0.6082 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.7256 - val_loss: 0.6130 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.7256 - val_loss: 0.6108 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.7256 - val_loss: 0.6105 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.7256 - val_loss: 0.6154 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.7256 - val_loss: 0.6139 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.7256 - val_loss: 0.6141 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.7256 - val_loss: 0.6123 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.7256 - val_loss: 0.6141 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.7256 - val_loss: 0.6122 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.7256 - val_loss: 0.6132 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7256 - val_loss: 0.6126 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.7256 - val_loss: 0.6136 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.7246 - val_loss: 0.6143 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.7256 - val_loss: 0.6118 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.7246 - val_loss: 0.6131 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7246 - val_loss: 0.6128 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5846 - accuracy: 0.7256 - val_loss: 0.6118 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.7246 - val_loss: 0.6108 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6348 - accuracy: 0.6982 - val_loss: 0.6089 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.7256 - val_loss: 0.6104 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.7256 - val_loss: 0.6091 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.7256 - val_loss: 0.6134 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.7256 - val_loss: 0.6121 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7256 - val_loss: 0.6089 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.7246 - val_loss: 0.6089 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.7246 - val_loss: 0.6083 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.7256 - val_loss: 0.6109 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7256 - val_loss: 0.6124 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7246 - val_loss: 0.6119 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7256 - val_loss: 0.6128 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7246 - val_loss: 0.6117 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7256 - val_loss: 0.6110 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7246 - val_loss: 0.6112 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7256 - val_loss: 0.6115 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7246 - val_loss: 0.6130 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.7256 - val_loss: 0.6088 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.7256 - val_loss: 0.6108 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7256 - val_loss: 0.6115 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6115 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6082 - accuracy: 0.7256 - val_loss: 0.6153 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.7256 - val_loss: 0.6119 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.7197 - val_loss: 0.6110 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.7256 - val_loss: 0.6079 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7256 - val_loss: 0.6052 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7256 - val_loss: 0.6083 - val_accuracy: 0.6953\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7246 - val_loss: 0.6042 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7256 - val_loss: 0.6023 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7227 - val_loss: 0.6053 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7256 - val_loss: 0.6025 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7256 - val_loss: 0.6010 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7256 - val_loss: 0.6006 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.7256 - val_loss: 0.5996 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7256 - val_loss: 0.5997 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7256 - val_loss: 0.6019 - val_accuracy: 0.6914\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7246 - val_loss: 0.6035 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7256 - val_loss: 0.5970 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7246 - val_loss: 0.5967 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7256 - val_loss: 0.5998 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7246 - val_loss: 0.6023 - val_accuracy: 0.6875\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.6875\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6261 - accuracy: 0.6738 - val_loss: 0.6140 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.7256 - val_loss: 0.6237 - val_accuracy: 0.6953\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.7256 - val_loss: 0.6166 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.7217 - val_loss: 0.6133 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.7256 - val_loss: 0.6121 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.7256 - val_loss: 0.6111 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7256 - val_loss: 0.6129 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.7256 - val_loss: 0.6113 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7256 - val_loss: 0.6101 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.7256 - val_loss: 0.6140 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.7256 - val_loss: 0.6140 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.7256 - val_loss: 0.6098 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7256 - val_loss: 0.6109 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7256 - val_loss: 0.6113 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7256 - val_loss: 0.6127 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.7256 - val_loss: 0.6102 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7256 - val_loss: 0.6124 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7256 - val_loss: 0.6072 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.7256 - val_loss: 0.6096 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7256 - val_loss: 0.6077 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 7ms/step - loss: 0.6319 - accuracy: 0.7002 - val_loss: 0.6111 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.7256 - val_loss: 0.6104 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5950 - accuracy: 0.7256 - val_loss: 0.6125 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.7256 - val_loss: 0.6120 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.7256 - val_loss: 0.6119 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5902 - accuracy: 0.7256 - val_loss: 0.6126 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.7256 - val_loss: 0.6117 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.7256 - val_loss: 0.6114 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7256 - val_loss: 0.6122 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7256 - val_loss: 0.6118 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.7246 - val_loss: 0.6171 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.7246 - val_loss: 0.6132 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.7256 - val_loss: 0.6111 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7246 - val_loss: 0.6135 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.7256 - val_loss: 0.6109 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5840 - accuracy: 0.7246 - val_loss: 0.6097 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.7246 - val_loss: 0.6123 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.7246 - val_loss: 0.6092 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.7256 - val_loss: 0.6127 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.7256 - val_loss: 0.6144 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6330 - accuracy: 0.6895 - val_loss: 0.6184 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5996 - accuracy: 0.7256 - val_loss: 0.6112 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.7256 - val_loss: 0.6115 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.7256 - val_loss: 0.6113 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.7256 - val_loss: 0.6153 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.7256 - val_loss: 0.6150 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7266 - val_loss: 0.6128 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.7227 - val_loss: 0.6152 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.7256 - val_loss: 0.6103 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.7256 - val_loss: 0.6148 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7256 - val_loss: 0.6126 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7256 - val_loss: 0.6143 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7256 - val_loss: 0.6130 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7275 - val_loss: 0.6165 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7256 - val_loss: 0.6204 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.7256 - val_loss: 0.6160 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7217 - val_loss: 0.6172 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.7256 - val_loss: 0.6174 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.7266 - val_loss: 0.6175 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.7266 - val_loss: 0.6190 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.7197 - val_loss: 0.6096 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.7256 - val_loss: 0.6090 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7256 - val_loss: 0.6093 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.7256 - val_loss: 0.6065 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7256 - val_loss: 0.6078 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7256 - val_loss: 0.6045 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.7236 - val_loss: 0.6064 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7256 - val_loss: 0.6039 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7256 - val_loss: 0.6027 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7246 - val_loss: 0.6026 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7256 - val_loss: 0.6025 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7256 - val_loss: 0.6015 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7256 - val_loss: 0.6031 - val_accuracy: 0.6953\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7256 - val_loss: 0.5997 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.7246 - val_loss: 0.6059 - val_accuracy: 0.6914\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7217 - val_loss: 0.6020 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7227 - val_loss: 0.6048 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7266 - val_loss: 0.5983 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7246 - val_loss: 0.6050 - val_accuracy: 0.6953\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7246 - val_loss: 0.6011 - val_accuracy: 0.6953\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.6953\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6633 - accuracy: 0.7051 - val_loss: 0.6145 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.7256 - val_loss: 0.6134 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.7256 - val_loss: 0.6150 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.7256 - val_loss: 0.6135 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7256 - val_loss: 0.6117 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.7256 - val_loss: 0.6149 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5853 - accuracy: 0.7256 - val_loss: 0.6110 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.7256 - val_loss: 0.6141 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.7256 - val_loss: 0.6132 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.7256 - val_loss: 0.6116 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.7256 - val_loss: 0.6130 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7256 - val_loss: 0.6151 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7246 - val_loss: 0.6115 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.7256 - val_loss: 0.6143 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.7256 - val_loss: 0.6145 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.7256 - val_loss: 0.6158 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.7256 - val_loss: 0.6137 - val_accuracy: 0.6953\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7256 - val_loss: 0.6132 - val_accuracy: 0.6953\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.7266 - val_loss: 0.6133 - val_accuracy: 0.6953\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7266 - val_loss: 0.6147 - val_accuracy: 0.6953\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6147 - accuracy: 0.6953\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6503 - accuracy: 0.6504 - val_loss: 0.6184 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.7256 - val_loss: 0.6123 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.7256 - val_loss: 0.6129 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.7256 - val_loss: 0.6103 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.7256 - val_loss: 0.6122 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.7256 - val_loss: 0.6108 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.7256 - val_loss: 0.6105 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.7256 - val_loss: 0.6106 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.7256 - val_loss: 0.6086 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.7256 - val_loss: 0.6102 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.7256 - val_loss: 0.6106 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.7256 - val_loss: 0.6096 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.7256 - val_loss: 0.6098 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7256 - val_loss: 0.6097 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.7256 - val_loss: 0.6092 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7256 - val_loss: 0.6101 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.7256 - val_loss: 0.6071 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7256 - val_loss: 0.6102 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7256 - val_loss: 0.6115 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.7256 - val_loss: 0.6086 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6492 - accuracy: 0.6709 - val_loss: 0.6124 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.7256 - val_loss: 0.6078 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.7256 - val_loss: 0.6069 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.7256 - val_loss: 0.6092 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.7256 - val_loss: 0.6073 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.7246 - val_loss: 0.6126 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.7256 - val_loss: 0.6108 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7256 - val_loss: 0.6095 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.7256 - val_loss: 0.6077 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7256 - val_loss: 0.6097 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7256 - val_loss: 0.6102 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.7256 - val_loss: 0.6143 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.7246 - val_loss: 0.6103 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7256 - val_loss: 0.6102 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7266 - val_loss: 0.6168 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.7256 - val_loss: 0.6131 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7246 - val_loss: 0.6152 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.7246 - val_loss: 0.6161 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7256 - val_loss: 0.6136 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7236 - val_loss: 0.6128 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6128 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6112 - accuracy: 0.7246 - val_loss: 0.6171 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.7256 - val_loss: 0.6075 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7256 - val_loss: 0.6108 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.7256 - val_loss: 0.6082 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7256 - val_loss: 0.6077 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7256 - val_loss: 0.6040 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7256 - val_loss: 0.6030 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7256 - val_loss: 0.6037 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.7256 - val_loss: 0.6056 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.7256 - val_loss: 0.6054 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7256 - val_loss: 0.6020 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.7256 - val_loss: 0.5991 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7256 - val_loss: 0.6013 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7256 - val_loss: 0.5998 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7256 - val_loss: 0.6029 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7256 - val_loss: 0.6038 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7256 - val_loss: 0.5976 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7256 - val_loss: 0.6016 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7256 - val_loss: 0.6007 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7256 - val_loss: 0.5962 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6258 - accuracy: 0.7227 - val_loss: 0.6052 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.7256 - val_loss: 0.6096 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.7256 - val_loss: 0.6113 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7256 - val_loss: 0.6104 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7256 - val_loss: 0.6088 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.7256 - val_loss: 0.6152 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7256 - val_loss: 0.6105 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7256 - val_loss: 0.6113 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.7256 - val_loss: 0.6136 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.7256 - val_loss: 0.6101 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7256 - val_loss: 0.6126 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7256 - val_loss: 0.6095 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.7256 - val_loss: 0.6101 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.7256 - val_loss: 0.6102 - val_accuracy: 0.6953\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7256 - val_loss: 0.6182 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7236 - val_loss: 0.6133 - val_accuracy: 0.6953\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.7256 - val_loss: 0.6127 - val_accuracy: 0.6914\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7256 - val_loss: 0.6108 - val_accuracy: 0.6953\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5772 - accuracy: 0.7256 - val_loss: 0.6114 - val_accuracy: 0.6953\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7256 - val_loss: 0.6169 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 5ms/step - loss: 0.6213 - accuracy: 0.7256 - val_loss: 0.6185 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.7256 - val_loss: 0.6085 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7256 - val_loss: 0.6088 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.7256 - val_loss: 0.6089 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7256 - val_loss: 0.6071 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7256 - val_loss: 0.6086 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7256 - val_loss: 0.6059 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.7256 - val_loss: 0.6120 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7266 - val_loss: 0.6091 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.7256 - val_loss: 0.6133 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7227 - val_loss: 0.6110 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7266 - val_loss: 0.6134 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.7256 - val_loss: 0.6114 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7227 - val_loss: 0.6086 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7256 - val_loss: 0.6146 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5744 - accuracy: 0.7256 - val_loss: 0.6129 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.7246 - val_loss: 0.6089 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7236 - val_loss: 0.6127 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.7256 - val_loss: 0.6139 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7256 - val_loss: 0.6135 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 9ms/step - loss: 0.6433 - accuracy: 0.6768 - val_loss: 0.6094 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.7256 - val_loss: 0.6140 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7256 - val_loss: 0.6087 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.7266 - val_loss: 0.6089 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.7266 - val_loss: 0.6084 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.7266 - val_loss: 0.6097 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.7266 - val_loss: 0.6124 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7266 - val_loss: 0.6083 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7246 - val_loss: 0.6100 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.7266 - val_loss: 0.6082 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7266 - val_loss: 0.6052 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.7256 - val_loss: 0.6064 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7285 - val_loss: 0.6105 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.7266 - val_loss: 0.6093 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7246 - val_loss: 0.6074 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7256 - val_loss: 0.6069 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.7305 - val_loss: 0.6049 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.7266 - val_loss: 0.6081 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.7285 - val_loss: 0.6085 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7275 - val_loss: 0.6165 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6131 - accuracy: 0.7236 - val_loss: 0.6182 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7256 - val_loss: 0.6138 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7256 - val_loss: 0.6130 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.7236 - val_loss: 0.6073 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.7256 - val_loss: 0.6085 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.7256 - val_loss: 0.6119 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7285 - val_loss: 0.6094 - val_accuracy: 0.7031\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.7295 - val_loss: 0.6117 - val_accuracy: 0.7031\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7285 - val_loss: 0.6153 - val_accuracy: 0.7031\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.7295 - val_loss: 0.6064 - val_accuracy: 0.7070\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.7285 - val_loss: 0.6052 - val_accuracy: 0.7109\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7285 - val_loss: 0.6051 - val_accuracy: 0.7109\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7275 - val_loss: 0.6094 - val_accuracy: 0.7109\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.7285 - val_loss: 0.6069 - val_accuracy: 0.7109\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7285 - val_loss: 0.6057 - val_accuracy: 0.7109\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7285 - val_loss: 0.6050 - val_accuracy: 0.7109\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7295 - val_loss: 0.6035 - val_accuracy: 0.7109\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7295 - val_loss: 0.6024 - val_accuracy: 0.7070\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7285 - val_loss: 0.6016 - val_accuracy: 0.7070\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7305 - val_loss: 0.6040 - val_accuracy: 0.7109\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.7109\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6121 - accuracy: 0.7217 - val_loss: 0.6086 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7256 - val_loss: 0.6100 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7256 - val_loss: 0.6067 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7256 - val_loss: 0.6131 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7256 - val_loss: 0.6062 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.7256 - val_loss: 0.6081 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7256 - val_loss: 0.6126 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.7256 - val_loss: 0.6073 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7256 - val_loss: 0.6071 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7266 - val_loss: 0.6064 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.7256 - val_loss: 0.6058 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7266 - val_loss: 0.6111 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7266 - val_loss: 0.6081 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7217 - val_loss: 0.6103 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7266 - val_loss: 0.6112 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.7246 - val_loss: 0.6065 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7275 - val_loss: 0.6071 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7266 - val_loss: 0.6124 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.7266 - val_loss: 0.6107 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7266 - val_loss: 0.6081 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.6992\n",
            "         frontal    central   parietal  occipital\n",
            "theta  69.921875  69.921875  68.750000  69.921875\n",
            "alpha  69.921875  69.921875  69.531250  69.531250\n",
            "beta   69.921875  69.921875  69.921875  69.921875\n",
            "gamma  69.921875  69.921875  71.093750  69.921875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"ann\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfDJMmfe6EIP",
        "outputId": "4b63b55d-ea64-41d0-daa6-9609f3eed0c2"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.5997 - accuracy: 0.7266 - val_loss: 0.6084 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7471 - val_loss: 0.5948 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7471 - val_loss: 0.6039 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7471 - val_loss: 0.6010 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7471 - val_loss: 0.5931 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7471 - val_loss: 0.5950 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7471 - val_loss: 0.6005 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7471 - val_loss: 0.6040 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7471 - val_loss: 0.5955 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7471 - val_loss: 0.6003 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7471 - val_loss: 0.5998 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7471 - val_loss: 0.5957 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7471 - val_loss: 0.5987 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7471 - val_loss: 0.6051 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7471 - val_loss: 0.6011 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7471 - val_loss: 0.5995 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7471 - val_loss: 0.6022 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7471 - val_loss: 0.5978 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7471 - val_loss: 0.6004 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7471 - val_loss: 0.5923 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.5923 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 7ms/step - loss: 0.6127 - accuracy: 0.7383 - val_loss: 0.6213 - val_accuracy: 0.7383\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.7451 - val_loss: 0.6106 - val_accuracy: 0.7422\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.7471 - val_loss: 0.6114 - val_accuracy: 0.7422\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7490 - val_loss: 0.6053 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7471 - val_loss: 0.6091 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7510 - val_loss: 0.6068 - val_accuracy: 0.7422\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7520 - val_loss: 0.6046 - val_accuracy: 0.7383\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7520 - val_loss: 0.6042 - val_accuracy: 0.7500\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.7520 - val_loss: 0.6034 - val_accuracy: 0.7422\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7490 - val_loss: 0.5992 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7471 - val_loss: 0.6026 - val_accuracy: 0.7422\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7510 - val_loss: 0.5985 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7490 - val_loss: 0.6020 - val_accuracy: 0.7422\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7500 - val_loss: 0.6003 - val_accuracy: 0.7461\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.7490 - val_loss: 0.5958 - val_accuracy: 0.7461\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5479 - accuracy: 0.7539 - val_loss: 0.6009 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7559 - val_loss: 0.5928 - val_accuracy: 0.7461\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7559 - val_loss: 0.6006 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7529 - val_loss: 0.6022 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7490 - val_loss: 0.5875 - val_accuracy: 0.7461\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.7461\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6085 - accuracy: 0.6992 - val_loss: 0.6327 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7471 - val_loss: 0.6121 - val_accuracy: 0.7422\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7500 - val_loss: 0.6085 - val_accuracy: 0.7422\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7451 - val_loss: 0.6152 - val_accuracy: 0.7500\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7500 - val_loss: 0.6023 - val_accuracy: 0.7383\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7520 - val_loss: 0.6041 - val_accuracy: 0.7383\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7461 - val_loss: 0.6116 - val_accuracy: 0.7422\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7500 - val_loss: 0.6179 - val_accuracy: 0.7422\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7520 - val_loss: 0.6030 - val_accuracy: 0.7500\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7500 - val_loss: 0.5983 - val_accuracy: 0.7422\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7559 - val_loss: 0.5995 - val_accuracy: 0.7227\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7529 - val_loss: 0.6158 - val_accuracy: 0.7500\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7500 - val_loss: 0.5933 - val_accuracy: 0.7422\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7578 - val_loss: 0.5909 - val_accuracy: 0.7344\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7549 - val_loss: 0.5946 - val_accuracy: 0.7383\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7500 - val_loss: 0.5927 - val_accuracy: 0.7344\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7598 - val_loss: 0.5903 - val_accuracy: 0.7266\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7559 - val_loss: 0.5961 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7578 - val_loss: 0.5909 - val_accuracy: 0.7422\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7520 - val_loss: 0.5919 - val_accuracy: 0.7227\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.7227\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 5ms/step - loss: 0.6214 - accuracy: 0.6973 - val_loss: 0.5949 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7471 - val_loss: 0.5893 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7480 - val_loss: 0.5894 - val_accuracy: 0.7422\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7451 - val_loss: 0.6021 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7490 - val_loss: 0.5896 - val_accuracy: 0.7422\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7510 - val_loss: 0.5857 - val_accuracy: 0.7422\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7490 - val_loss: 0.5875 - val_accuracy: 0.7422\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.7529 - val_loss: 0.5835 - val_accuracy: 0.7422\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7549 - val_loss: 0.5858 - val_accuracy: 0.7461\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7539 - val_loss: 0.5829 - val_accuracy: 0.7422\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7520 - val_loss: 0.5788 - val_accuracy: 0.7422\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7520 - val_loss: 0.5785 - val_accuracy: 0.7461\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7520 - val_loss: 0.5911 - val_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7520 - val_loss: 0.5919 - val_accuracy: 0.7500\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7549 - val_loss: 0.5855 - val_accuracy: 0.7500\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7549 - val_loss: 0.5775 - val_accuracy: 0.7422\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7568 - val_loss: 0.5787 - val_accuracy: 0.7461\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7549 - val_loss: 0.5905 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7539 - val_loss: 0.5753 - val_accuracy: 0.7461\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7559 - val_loss: 0.5732 - val_accuracy: 0.7461\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7461\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.5898 - accuracy: 0.7432 - val_loss: 0.6189 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7471 - val_loss: 0.5880 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7471 - val_loss: 0.5919 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7471 - val_loss: 0.5971 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7471 - val_loss: 0.5969 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7471 - val_loss: 0.5865 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7471 - val_loss: 0.5917 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7471 - val_loss: 0.5849 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7471 - val_loss: 0.5903 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7471 - val_loss: 0.5950 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7471 - val_loss: 0.5987 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7471 - val_loss: 0.5852 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7480 - val_loss: 0.5976 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7471 - val_loss: 0.5852 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7500 - val_loss: 0.5933 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7480 - val_loss: 0.5952 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7500 - val_loss: 0.5867 - val_accuracy: 0.7500\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7520 - val_loss: 0.5969 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7510 - val_loss: 0.5972 - val_accuracy: 0.7500\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7520 - val_loss: 0.5994 - val_accuracy: 0.7500\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.7500\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6282 - accuracy: 0.7129 - val_loss: 0.5923 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7471 - val_loss: 0.6043 - val_accuracy: 0.7344\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7461 - val_loss: 0.6044 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7422 - val_loss: 0.6097 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7480 - val_loss: 0.6031 - val_accuracy: 0.7383\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7490 - val_loss: 0.6050 - val_accuracy: 0.7500\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7500 - val_loss: 0.6069 - val_accuracy: 0.7383\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7529 - val_loss: 0.5999 - val_accuracy: 0.7422\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.7500 - val_loss: 0.6001 - val_accuracy: 0.7422\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7529 - val_loss: 0.5983 - val_accuracy: 0.7500\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7510 - val_loss: 0.6018 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7520 - val_loss: 0.5966 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7510 - val_loss: 0.5987 - val_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7520 - val_loss: 0.6004 - val_accuracy: 0.7422\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7520 - val_loss: 0.6017 - val_accuracy: 0.7383\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7480 - val_loss: 0.5978 - val_accuracy: 0.7422\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7520 - val_loss: 0.5963 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7510 - val_loss: 0.5981 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7539 - val_loss: 0.5956 - val_accuracy: 0.7500\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7510 - val_loss: 0.5988 - val_accuracy: 0.7500\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.7500\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 7ms/step - loss: 0.5938 - accuracy: 0.7490 - val_loss: 0.6024 - val_accuracy: 0.7383\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7490 - val_loss: 0.6102 - val_accuracy: 0.7383\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7451 - val_loss: 0.6076 - val_accuracy: 0.7500\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7510 - val_loss: 0.6086 - val_accuracy: 0.7383\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7500 - val_loss: 0.6082 - val_accuracy: 0.7383\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7529 - val_loss: 0.6096 - val_accuracy: 0.7383\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7500 - val_loss: 0.6023 - val_accuracy: 0.7383\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7549 - val_loss: 0.6016 - val_accuracy: 0.7461\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7490 - val_loss: 0.6062 - val_accuracy: 0.7344\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7480 - val_loss: 0.6036 - val_accuracy: 0.7500\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7559 - val_loss: 0.5996 - val_accuracy: 0.7461\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7568 - val_loss: 0.5992 - val_accuracy: 0.7266\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7549 - val_loss: 0.6037 - val_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7598 - val_loss: 0.6024 - val_accuracy: 0.7344\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.7510 - val_loss: 0.5996 - val_accuracy: 0.7227\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7588 - val_loss: 0.6152 - val_accuracy: 0.7461\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7539 - val_loss: 0.5974 - val_accuracy: 0.7305\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7539 - val_loss: 0.6046 - val_accuracy: 0.7461\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7578 - val_loss: 0.5980 - val_accuracy: 0.7344\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7588 - val_loss: 0.6052 - val_accuracy: 0.7422\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.7422\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6546 - accuracy: 0.6494 - val_loss: 0.6122 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7432 - val_loss: 0.5934 - val_accuracy: 0.7383\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7490 - val_loss: 0.6042 - val_accuracy: 0.7500\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7490 - val_loss: 0.5919 - val_accuracy: 0.7383\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7510 - val_loss: 0.6044 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7510 - val_loss: 0.5962 - val_accuracy: 0.7500\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7510 - val_loss: 0.5897 - val_accuracy: 0.7383\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7471 - val_loss: 0.5882 - val_accuracy: 0.7461\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7539 - val_loss: 0.5855 - val_accuracy: 0.7500\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7529 - val_loss: 0.5806 - val_accuracy: 0.7422\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7529 - val_loss: 0.5890 - val_accuracy: 0.7500\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7510 - val_loss: 0.5853 - val_accuracy: 0.7461\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7520 - val_loss: 0.5885 - val_accuracy: 0.7461\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7520 - val_loss: 0.5791 - val_accuracy: 0.7461\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7549 - val_loss: 0.5884 - val_accuracy: 0.7500\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.7510 - val_loss: 0.5775 - val_accuracy: 0.7500\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7539 - val_loss: 0.5908 - val_accuracy: 0.7500\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7539 - val_loss: 0.5798 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7529 - val_loss: 0.5780 - val_accuracy: 0.7500\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7539 - val_loss: 0.5880 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 44ms/step - loss: 0.5990 - accuracy: 0.7412 - val_loss: 0.5952 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7471 - val_loss: 0.5802 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7471 - val_loss: 0.5791 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7471 - val_loss: 0.5916 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7471 - val_loss: 0.5788 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7471 - val_loss: 0.5953 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7471 - val_loss: 0.5826 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7471 - val_loss: 0.5781 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7471 - val_loss: 0.5910 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5530 - accuracy: 0.7480 - val_loss: 0.5877 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7471 - val_loss: 0.5779 - val_accuracy: 0.7500\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.7490 - val_loss: 0.5889 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7480 - val_loss: 0.5807 - val_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7490 - val_loss: 0.5905 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.7490 - val_loss: 0.5814 - val_accuracy: 0.7500\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.7500 - val_loss: 0.5802 - val_accuracy: 0.7500\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7500 - val_loss: 0.5846 - val_accuracy: 0.7500\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7500 - val_loss: 0.5828 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7510 - val_loss: 0.5905 - val_accuracy: 0.7500\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7510 - val_loss: 0.5843 - val_accuracy: 0.7500\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.7500\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6191 - accuracy: 0.7061 - val_loss: 0.5800 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7422 - val_loss: 0.5873 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7461 - val_loss: 0.5946 - val_accuracy: 0.7500\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7471 - val_loss: 0.6021 - val_accuracy: 0.7344\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7490 - val_loss: 0.5963 - val_accuracy: 0.7500\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7490 - val_loss: 0.5970 - val_accuracy: 0.7383\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7480 - val_loss: 0.5923 - val_accuracy: 0.7383\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7441 - val_loss: 0.5903 - val_accuracy: 0.7422\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7510 - val_loss: 0.5891 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7500 - val_loss: 0.5923 - val_accuracy: 0.7383\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.7480 - val_loss: 0.5907 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7500 - val_loss: 0.5870 - val_accuracy: 0.7500\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7480 - val_loss: 0.5871 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7500 - val_loss: 0.5979 - val_accuracy: 0.7383\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7520 - val_loss: 0.5872 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7490 - val_loss: 0.5914 - val_accuracy: 0.7422\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.7520 - val_loss: 0.5913 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7500 - val_loss: 0.5955 - val_accuracy: 0.7383\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7520 - val_loss: 0.5856 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7510 - val_loss: 0.5919 - val_accuracy: 0.7422\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.7422\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6470 - accuracy: 0.6670 - val_loss: 0.5992 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.7441 - val_loss: 0.5896 - val_accuracy: 0.7461\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.7461 - val_loss: 0.5871 - val_accuracy: 0.7422\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.7500 - val_loss: 0.5920 - val_accuracy: 0.7344\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.7490 - val_loss: 0.5885 - val_accuracy: 0.7383\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5541 - accuracy: 0.7520 - val_loss: 0.5852 - val_accuracy: 0.7422\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7500 - val_loss: 0.5870 - val_accuracy: 0.7461\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.7520 - val_loss: 0.5830 - val_accuracy: 0.7383\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7510 - val_loss: 0.5841 - val_accuracy: 0.7500\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5488 - accuracy: 0.7480 - val_loss: 0.5866 - val_accuracy: 0.7383\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7520 - val_loss: 0.5853 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.7520 - val_loss: 0.5869 - val_accuracy: 0.7383\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7500 - val_loss: 0.5920 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7480 - val_loss: 0.5869 - val_accuracy: 0.7383\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7510 - val_loss: 0.5840 - val_accuracy: 0.7500\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7490 - val_loss: 0.5833 - val_accuracy: 0.7500\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7549 - val_loss: 0.5792 - val_accuracy: 0.7500\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7480 - val_loss: 0.5859 - val_accuracy: 0.7422\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7520 - val_loss: 0.5829 - val_accuracy: 0.7422\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7539 - val_loss: 0.5839 - val_accuracy: 0.7383\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.7383\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6215 - accuracy: 0.7217 - val_loss: 0.5811 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7461 - val_loss: 0.5791 - val_accuracy: 0.7383\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7471 - val_loss: 0.5932 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7500 - val_loss: 0.5900 - val_accuracy: 0.7383\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7490 - val_loss: 0.5876 - val_accuracy: 0.7383\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.7500 - val_loss: 0.5867 - val_accuracy: 0.7422\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7549 - val_loss: 0.5860 - val_accuracy: 0.7461\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5530 - accuracy: 0.7500 - val_loss: 0.5860 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7510 - val_loss: 0.5877 - val_accuracy: 0.7500\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7520 - val_loss: 0.5897 - val_accuracy: 0.7500\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7559 - val_loss: 0.5876 - val_accuracy: 0.7461\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7520 - val_loss: 0.5843 - val_accuracy: 0.7422\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7529 - val_loss: 0.5882 - val_accuracy: 0.7422\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7490 - val_loss: 0.5873 - val_accuracy: 0.7422\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7510 - val_loss: 0.5851 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7520 - val_loss: 0.5839 - val_accuracy: 0.7422\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7520 - val_loss: 0.5876 - val_accuracy: 0.7422\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7549 - val_loss: 0.5812 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7500 - val_loss: 0.5924 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7520 - val_loss: 0.5826 - val_accuracy: 0.7422\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.7422\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6103 - accuracy: 0.7441 - val_loss: 0.5754 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7471 - val_loss: 0.5665 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7471 - val_loss: 0.5701 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7471 - val_loss: 0.5711 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7471 - val_loss: 0.5686 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7471 - val_loss: 0.5703 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7471 - val_loss: 0.5730 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7471 - val_loss: 0.5696 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.7471 - val_loss: 0.5726 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7471 - val_loss: 0.5757 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7471 - val_loss: 0.5768 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7471 - val_loss: 0.5727 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.7471 - val_loss: 0.5779 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7471 - val_loss: 0.5773 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7471 - val_loss: 0.5792 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7471 - val_loss: 0.5779 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7480 - val_loss: 0.5846 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7471 - val_loss: 0.5820 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7471 - val_loss: 0.5784 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7461 - val_loss: 0.5952 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6054 - accuracy: 0.7314 - val_loss: 0.5708 - val_accuracy: 0.7344\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7461 - val_loss: 0.5699 - val_accuracy: 0.7305\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.7461 - val_loss: 0.5741 - val_accuracy: 0.7422\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7480 - val_loss: 0.5717 - val_accuracy: 0.7461\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7480 - val_loss: 0.5776 - val_accuracy: 0.7422\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7510 - val_loss: 0.5751 - val_accuracy: 0.7500\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7471 - val_loss: 0.5835 - val_accuracy: 0.7422\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7451 - val_loss: 0.5850 - val_accuracy: 0.7500\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7490 - val_loss: 0.5844 - val_accuracy: 0.7500\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7500 - val_loss: 0.5835 - val_accuracy: 0.7500\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7461 - val_loss: 0.5842 - val_accuracy: 0.7500\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7500 - val_loss: 0.5872 - val_accuracy: 0.7422\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7471 - val_loss: 0.5922 - val_accuracy: 0.7422\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7500 - val_loss: 0.5896 - val_accuracy: 0.7500\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5449 - accuracy: 0.7480 - val_loss: 0.5937 - val_accuracy: 0.7344\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7471 - val_loss: 0.5915 - val_accuracy: 0.7422\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7520 - val_loss: 0.5926 - val_accuracy: 0.7461\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7480 - val_loss: 0.5913 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7490 - val_loss: 0.5957 - val_accuracy: 0.7422\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7500 - val_loss: 0.5935 - val_accuracy: 0.7422\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.7422\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6287 - accuracy: 0.7139 - val_loss: 0.5886 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5694 - accuracy: 0.7480 - val_loss: 0.5722 - val_accuracy: 0.7422\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.7510 - val_loss: 0.5686 - val_accuracy: 0.7461\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7480 - val_loss: 0.5689 - val_accuracy: 0.7500\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.7490 - val_loss: 0.5692 - val_accuracy: 0.7422\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7529 - val_loss: 0.5670 - val_accuracy: 0.7500\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7500 - val_loss: 0.5658 - val_accuracy: 0.7422\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.7500 - val_loss: 0.5656 - val_accuracy: 0.7461\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.7510 - val_loss: 0.5655 - val_accuracy: 0.7461\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7490 - val_loss: 0.5656 - val_accuracy: 0.7422\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.7500 - val_loss: 0.5638 - val_accuracy: 0.7500\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7490 - val_loss: 0.5664 - val_accuracy: 0.7500\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7500 - val_loss: 0.5652 - val_accuracy: 0.7422\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7490 - val_loss: 0.5650 - val_accuracy: 0.7461\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7510 - val_loss: 0.5662 - val_accuracy: 0.7422\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7480 - val_loss: 0.5693 - val_accuracy: 0.7461\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.7490 - val_loss: 0.5687 - val_accuracy: 0.7422\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.7480 - val_loss: 0.5638 - val_accuracy: 0.7461\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.7471 - val_loss: 0.5671 - val_accuracy: 0.7422\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.7500 - val_loss: 0.5652 - val_accuracy: 0.7422\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.7422\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 7ms/step - loss: 0.6103 - accuracy: 0.7422 - val_loss: 0.5722 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7471 - val_loss: 0.5668 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7480 - val_loss: 0.5706 - val_accuracy: 0.7500\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7490 - val_loss: 0.5731 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7461 - val_loss: 0.5761 - val_accuracy: 0.7500\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7490 - val_loss: 0.5859 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7500 - val_loss: 0.5800 - val_accuracy: 0.7461\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7510 - val_loss: 0.5837 - val_accuracy: 0.7461\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7510 - val_loss: 0.5822 - val_accuracy: 0.7422\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7480 - val_loss: 0.5849 - val_accuracy: 0.7500\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7520 - val_loss: 0.5835 - val_accuracy: 0.7422\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7529 - val_loss: 0.5916 - val_accuracy: 0.7461\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7510 - val_loss: 0.5862 - val_accuracy: 0.7461\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7510 - val_loss: 0.5873 - val_accuracy: 0.7461\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7510 - val_loss: 0.5860 - val_accuracy: 0.7461\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7500 - val_loss: 0.5891 - val_accuracy: 0.7500\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7510 - val_loss: 0.5865 - val_accuracy: 0.7422\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7520 - val_loss: 0.5895 - val_accuracy: 0.7461\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7510 - val_loss: 0.5854 - val_accuracy: 0.7422\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7500 - val_loss: 0.5893 - val_accuracy: 0.7461\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.7461\n",
            "         frontal    central   parietal  occipital\n",
            "theta  75.390625  74.609375  72.265625  74.609375\n",
            "alpha  75.000000  75.000000  74.218750  75.390625\n",
            "beta   75.000000  74.218750  73.828125  74.218750\n",
            "gamma  75.390625  74.218750  74.218750  74.609375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"ann\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joNsxCym6HBn",
        "outputId": "632cf77d-7fc7-4efe-b54e-0c07428f601a"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.5951 - accuracy: 0.7344 - val_loss: 0.5194 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7754 - val_loss: 0.5094 - val_accuracy: 0.7891\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7773 - val_loss: 0.5075 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7754 - val_loss: 0.5009 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7783 - val_loss: 0.4993 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7764 - val_loss: 0.4979 - val_accuracy: 0.7891\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7793 - val_loss: 0.4988 - val_accuracy: 0.7891\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7744 - val_loss: 0.4999 - val_accuracy: 0.7891\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7803 - val_loss: 0.5013 - val_accuracy: 0.7891\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7783 - val_loss: 0.5004 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7773 - val_loss: 0.4983 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7803 - val_loss: 0.5011 - val_accuracy: 0.7891\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7793 - val_loss: 0.4988 - val_accuracy: 0.7891\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7773 - val_loss: 0.4991 - val_accuracy: 0.7891\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7773 - val_loss: 0.4975 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7793 - val_loss: 0.5044 - val_accuracy: 0.7891\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7803 - val_loss: 0.4998 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7773 - val_loss: 0.5045 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7783 - val_loss: 0.5014 - val_accuracy: 0.7891\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7803 - val_loss: 0.5025 - val_accuracy: 0.7891\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7891\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.5827 - accuracy: 0.7637 - val_loss: 0.5035 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7764 - val_loss: 0.5023 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7764 - val_loss: 0.5035 - val_accuracy: 0.7891\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7764 - val_loss: 0.5067 - val_accuracy: 0.7891\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7744 - val_loss: 0.5036 - val_accuracy: 0.7891\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7812 - val_loss: 0.5047 - val_accuracy: 0.7891\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7793 - val_loss: 0.5010 - val_accuracy: 0.7891\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7773 - val_loss: 0.5010 - val_accuracy: 0.7891\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7793 - val_loss: 0.4972 - val_accuracy: 0.7891\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7793 - val_loss: 0.5061 - val_accuracy: 0.7891\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7803 - val_loss: 0.5020 - val_accuracy: 0.7891\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7773 - val_loss: 0.5038 - val_accuracy: 0.7891\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7783 - val_loss: 0.5065 - val_accuracy: 0.7812\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7783 - val_loss: 0.5014 - val_accuracy: 0.7891\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7783 - val_loss: 0.5061 - val_accuracy: 0.7812\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7783 - val_loss: 0.5016 - val_accuracy: 0.7891\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7793 - val_loss: 0.5049 - val_accuracy: 0.7891\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7773 - val_loss: 0.5011 - val_accuracy: 0.7891\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7783 - val_loss: 0.5084 - val_accuracy: 0.7773\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7783 - val_loss: 0.4974 - val_accuracy: 0.7891\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7891\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.5839 - accuracy: 0.7686 - val_loss: 0.5023 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7715 - val_loss: 0.4904 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7773 - val_loss: 0.5121 - val_accuracy: 0.7852\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7783 - val_loss: 0.5017 - val_accuracy: 0.7891\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7803 - val_loss: 0.5015 - val_accuracy: 0.7891\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7744 - val_loss: 0.5198 - val_accuracy: 0.7734\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7773\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7783 - val_loss: 0.5129 - val_accuracy: 0.7773\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7764 - val_loss: 0.4980 - val_accuracy: 0.7891\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7783 - val_loss: 0.5167 - val_accuracy: 0.7734\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7793 - val_loss: 0.5115 - val_accuracy: 0.7773\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7793 - val_loss: 0.5114 - val_accuracy: 0.7773\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7773 - val_loss: 0.4991 - val_accuracy: 0.7891\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7725 - val_loss: 0.4986 - val_accuracy: 0.7891\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7783 - val_loss: 0.5042 - val_accuracy: 0.7891\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7773 - val_loss: 0.5040 - val_accuracy: 0.7891\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7783 - val_loss: 0.5016 - val_accuracy: 0.7891\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7803 - val_loss: 0.5101 - val_accuracy: 0.7852\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7793 - val_loss: 0.5084 - val_accuracy: 0.7891\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7793 - val_loss: 0.5070 - val_accuracy: 0.7891\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.7891\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 7ms/step - loss: 0.5935 - accuracy: 0.7666 - val_loss: 0.5158 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5192 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7764 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7754 - val_loss: 0.5180 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7705 - val_loss: 0.5127 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7764 - val_loss: 0.5182 - val_accuracy: 0.7812\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7764 - val_loss: 0.5128 - val_accuracy: 0.7891\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7764 - val_loss: 0.5158 - val_accuracy: 0.7812\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7783 - val_loss: 0.5120 - val_accuracy: 0.7891\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7783 - val_loss: 0.5128 - val_accuracy: 0.7812\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7773 - val_loss: 0.5100 - val_accuracy: 0.7891\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7754 - val_loss: 0.5171 - val_accuracy: 0.7812\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7793 - val_loss: 0.5140 - val_accuracy: 0.7812\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7773 - val_loss: 0.5126 - val_accuracy: 0.7812\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.7803 - val_loss: 0.5107 - val_accuracy: 0.7812\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7773 - val_loss: 0.5163 - val_accuracy: 0.7773\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7803 - val_loss: 0.5135 - val_accuracy: 0.7773\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7793 - val_loss: 0.5122 - val_accuracy: 0.7812\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7793 - val_loss: 0.5106 - val_accuracy: 0.7812\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7803 - val_loss: 0.5160 - val_accuracy: 0.7773\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7773\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.5810 - accuracy: 0.7744 - val_loss: 0.5324 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7764 - val_loss: 0.5130 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7764 - val_loss: 0.5019 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7764 - val_loss: 0.5042 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7764 - val_loss: 0.5072 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7773 - val_loss: 0.4993 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7754 - val_loss: 0.5037 - val_accuracy: 0.7891\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7793 - val_loss: 0.5013 - val_accuracy: 0.7891\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7764 - val_loss: 0.5055 - val_accuracy: 0.7891\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7783 - val_loss: 0.5034 - val_accuracy: 0.7891\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7783 - val_loss: 0.5037 - val_accuracy: 0.7852\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7773 - val_loss: 0.5106 - val_accuracy: 0.7852\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7793 - val_loss: 0.5077 - val_accuracy: 0.7852\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7793 - val_loss: 0.5046 - val_accuracy: 0.7891\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7793 - val_loss: 0.5013 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7773 - val_loss: 0.5082 - val_accuracy: 0.7773\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7793 - val_loss: 0.5074 - val_accuracy: 0.7773\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7783 - val_loss: 0.5016 - val_accuracy: 0.7891\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7803 - val_loss: 0.5063 - val_accuracy: 0.7852\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7773 - val_loss: 0.5035 - val_accuracy: 0.7891\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7891\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.5826 - accuracy: 0.7412 - val_loss: 0.5024 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7764 - val_loss: 0.5115 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7764 - val_loss: 0.5082 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7764 - val_loss: 0.5115 - val_accuracy: 0.7891\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7764 - val_loss: 0.5088 - val_accuracy: 0.7891\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7783 - val_loss: 0.5122 - val_accuracy: 0.7812\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7803 - val_loss: 0.5100 - val_accuracy: 0.7891\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7773 - val_loss: 0.5159 - val_accuracy: 0.7812\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7783 - val_loss: 0.5125 - val_accuracy: 0.7852\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7793 - val_loss: 0.5112 - val_accuracy: 0.7852\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7773 - val_loss: 0.5051 - val_accuracy: 0.7891\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7793 - val_loss: 0.5125 - val_accuracy: 0.7812\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7783 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7783 - val_loss: 0.5126 - val_accuracy: 0.7812\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7764 - val_loss: 0.5065 - val_accuracy: 0.7891\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7764 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7793 - val_loss: 0.5098 - val_accuracy: 0.7852\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7793 - val_loss: 0.5101 - val_accuracy: 0.7852\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7783 - val_loss: 0.5076 - val_accuracy: 0.7891\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7793 - val_loss: 0.5081 - val_accuracy: 0.7891\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7891\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.5744 - accuracy: 0.7656 - val_loss: 0.5088 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7783 - val_loss: 0.5065 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7764 - val_loss: 0.5072 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7764 - val_loss: 0.5093 - val_accuracy: 0.7891\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7764 - val_loss: 0.5077 - val_accuracy: 0.7891\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7783 - val_loss: 0.5049 - val_accuracy: 0.7891\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7754 - val_loss: 0.4977 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7773 - val_loss: 0.5052 - val_accuracy: 0.7891\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7783 - val_loss: 0.5060 - val_accuracy: 0.7891\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7783 - val_loss: 0.5068 - val_accuracy: 0.7891\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7793 - val_loss: 0.5026 - val_accuracy: 0.7891\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7793 - val_loss: 0.5030 - val_accuracy: 0.7891\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7754 - val_loss: 0.5051 - val_accuracy: 0.7891\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7783 - val_loss: 0.5056 - val_accuracy: 0.7891\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7793 - val_loss: 0.5014 - val_accuracy: 0.7891\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7773 - val_loss: 0.5084 - val_accuracy: 0.7891\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7793 - val_loss: 0.5100 - val_accuracy: 0.7773\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7803 - val_loss: 0.5103 - val_accuracy: 0.7773\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7793 - val_loss: 0.5018 - val_accuracy: 0.7891\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7734 - val_loss: 0.5079 - val_accuracy: 0.7852\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7852\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.5885 - accuracy: 0.7529 - val_loss: 0.5197 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7764 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7764 - val_loss: 0.5197 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7764 - val_loss: 0.5183 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7754 - val_loss: 0.5236 - val_accuracy: 0.7852\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7744 - val_loss: 0.5209 - val_accuracy: 0.7852\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7734 - val_loss: 0.5156 - val_accuracy: 0.7891\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7773 - val_loss: 0.5173 - val_accuracy: 0.7891\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7773 - val_loss: 0.5166 - val_accuracy: 0.7891\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7764 - val_loss: 0.5191 - val_accuracy: 0.7812\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7783 - val_loss: 0.5161 - val_accuracy: 0.7891\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7783 - val_loss: 0.5163 - val_accuracy: 0.7852\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7803 - val_loss: 0.5203 - val_accuracy: 0.7812\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7783 - val_loss: 0.5162 - val_accuracy: 0.7852\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7783 - val_loss: 0.5150 - val_accuracy: 0.7852\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7793 - val_loss: 0.5225 - val_accuracy: 0.7812\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7822 - val_loss: 0.5154 - val_accuracy: 0.7812\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7803 - val_loss: 0.5168 - val_accuracy: 0.7812\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7793 - val_loss: 0.5167 - val_accuracy: 0.7812\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7812\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.5612 - accuracy: 0.7744 - val_loss: 0.5106 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5335 - accuracy: 0.7764 - val_loss: 0.5135 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7725 - val_loss: 0.5066 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5108 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7764 - val_loss: 0.5122 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7686 - val_loss: 0.5046 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7764 - val_loss: 0.5112 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7764 - val_loss: 0.5069 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7764 - val_loss: 0.5059 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7764 - val_loss: 0.5131 - val_accuracy: 0.7773\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7725 - val_loss: 0.5043 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7764 - val_loss: 0.5048 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7725 - val_loss: 0.5027 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7764 - val_loss: 0.5052 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7764 - val_loss: 0.5052 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7754 - val_loss: 0.5089 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7744 - val_loss: 0.5083 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7764 - val_loss: 0.5062 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7773 - val_loss: 0.5075 - val_accuracy: 0.7852\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7754 - val_loss: 0.5068 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6295 - accuracy: 0.7129 - val_loss: 0.5159 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7764 - val_loss: 0.5196 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7744 - val_loss: 0.5127 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7764 - val_loss: 0.5118 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7705 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7764 - val_loss: 0.5143 - val_accuracy: 0.7812\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7783 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7803 - val_loss: 0.5106 - val_accuracy: 0.7891\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7754 - val_loss: 0.5128 - val_accuracy: 0.7852\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7754 - val_loss: 0.5102 - val_accuracy: 0.7891\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7783 - val_loss: 0.5137 - val_accuracy: 0.7891\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7783 - val_loss: 0.5181 - val_accuracy: 0.7773\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7656 - val_loss: 0.5121 - val_accuracy: 0.7891\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7744 - val_loss: 0.5314 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7754 - val_loss: 0.5151 - val_accuracy: 0.7812\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7754 - val_loss: 0.5125 - val_accuracy: 0.7891\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7783 - val_loss: 0.5150 - val_accuracy: 0.7852\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7783 - val_loss: 0.5110 - val_accuracy: 0.7891\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7773 - val_loss: 0.5201 - val_accuracy: 0.7734\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7764 - val_loss: 0.5155 - val_accuracy: 0.7812\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7812\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6182 - accuracy: 0.6807 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7754 - val_loss: 0.5264 - val_accuracy: 0.7891\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7764 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7773 - val_loss: 0.5283 - val_accuracy: 0.7773\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7764 - val_loss: 0.5108 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7754 - val_loss: 0.5148 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7725 - val_loss: 0.5058 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7764 - val_loss: 0.5241 - val_accuracy: 0.7773\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7773 - val_loss: 0.5229 - val_accuracy: 0.7773\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7744 - val_loss: 0.5167 - val_accuracy: 0.7891\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7891\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7773 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7754 - val_loss: 0.5161 - val_accuracy: 0.7891\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7783 - val_loss: 0.5161 - val_accuracy: 0.7891\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7754 - val_loss: 0.5234 - val_accuracy: 0.7695\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7725 - val_loss: 0.5085 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7783 - val_loss: 0.5200 - val_accuracy: 0.7812\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7773 - val_loss: 0.5131 - val_accuracy: 0.7891\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7773 - val_loss: 0.5117 - val_accuracy: 0.7891\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7891\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 5ms/step - loss: 0.5867 - accuracy: 0.7656 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7764 - val_loss: 0.5231 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7764 - val_loss: 0.5233 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7764 - val_loss: 0.5275 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7754 - val_loss: 0.5251 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7695 - val_loss: 0.5297 - val_accuracy: 0.7891\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7773 - val_loss: 0.5264 - val_accuracy: 0.7891\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7773 - val_loss: 0.5243 - val_accuracy: 0.7891\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7783 - val_loss: 0.5301 - val_accuracy: 0.7852\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7764 - val_loss: 0.5232 - val_accuracy: 0.7852\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7754 - val_loss: 0.5229 - val_accuracy: 0.7852\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7793 - val_loss: 0.5274 - val_accuracy: 0.7852\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7793 - val_loss: 0.5213 - val_accuracy: 0.7891\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7783 - val_loss: 0.5264 - val_accuracy: 0.7812\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7764 - val_loss: 0.5210 - val_accuracy: 0.7852\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7764 - val_loss: 0.5273 - val_accuracy: 0.7812\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7725 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7783 - val_loss: 0.5267 - val_accuracy: 0.7812\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7764 - val_loss: 0.5287 - val_accuracy: 0.7773\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7793 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7812\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.5867 - accuracy: 0.7695 - val_loss: 0.5312 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7764 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7764 - val_loss: 0.5195 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7676 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5092 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7764 - val_loss: 0.5143 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7666 - val_loss: 0.5078 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7773 - val_loss: 0.5153 - val_accuracy: 0.7852\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7715 - val_loss: 0.5067 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7773 - val_loss: 0.5079 - val_accuracy: 0.7891\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7773 - val_loss: 0.5109 - val_accuracy: 0.7773\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7764 - val_loss: 0.5027 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7783 - val_loss: 0.5062 - val_accuracy: 0.7891\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7783 - val_loss: 0.5079 - val_accuracy: 0.7891\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7783 - val_loss: 0.5050 - val_accuracy: 0.7891\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7754 - val_loss: 0.5069 - val_accuracy: 0.7891\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7773 - val_loss: 0.5048 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7783 - val_loss: 0.5036 - val_accuracy: 0.7891\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7783 - val_loss: 0.5084 - val_accuracy: 0.7852\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7734 - val_loss: 0.5025 - val_accuracy: 0.7891\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7891\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 5ms/step - loss: 0.5693 - accuracy: 0.7734 - val_loss: 0.5339 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7764 - val_loss: 0.5345 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7764 - val_loss: 0.5270 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7705 - val_loss: 0.5201 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7715 - val_loss: 0.5242 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7783 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7793 - val_loss: 0.5258 - val_accuracy: 0.7891\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7754 - val_loss: 0.5225 - val_accuracy: 0.7891\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7754 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7715 - val_loss: 0.5161 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7754 - val_loss: 0.5270 - val_accuracy: 0.7695\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7783 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7734 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7754 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7793 - val_loss: 0.5230 - val_accuracy: 0.7773\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7764 - val_loss: 0.5204 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7773 - val_loss: 0.5177 - val_accuracy: 0.7891\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7744 - val_loss: 0.5178 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7773 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6001 - accuracy: 0.7559 - val_loss: 0.5313 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7764 - val_loss: 0.5310 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7764 - val_loss: 0.5256 - val_accuracy: 0.7891\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7744 - val_loss: 0.5191 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7764 - val_loss: 0.5172 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7773 - val_loss: 0.5258 - val_accuracy: 0.7812\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7754 - val_loss: 0.5262 - val_accuracy: 0.7773\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7715 - val_loss: 0.5081 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7773 - val_loss: 0.5244 - val_accuracy: 0.7773\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7744 - val_loss: 0.5245 - val_accuracy: 0.7773\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7744 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7734 - val_loss: 0.5264 - val_accuracy: 0.7695\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7734 - val_loss: 0.5267 - val_accuracy: 0.7734\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7715 - val_loss: 0.5166 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7725 - val_loss: 0.5085 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7715 - val_loss: 0.5240 - val_accuracy: 0.7773\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7744 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7764 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7754 - val_loss: 0.5145 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7773 - val_loss: 0.5137 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.5907 - accuracy: 0.7764 - val_loss: 0.5282 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7734 - val_loss: 0.5272 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7773 - val_loss: 0.5302 - val_accuracy: 0.7773\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7744 - val_loss: 0.5247 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7754 - val_loss: 0.5282 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5259 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7725 - val_loss: 0.5278 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7764 - val_loss: 0.5276 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7734 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7773 - val_loss: 0.5291 - val_accuracy: 0.7812\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7764 - val_loss: 0.5248 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7764 - val_loss: 0.5294 - val_accuracy: 0.7812\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7725 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7764 - val_loss: 0.5265 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7764 - val_loss: 0.5272 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7734 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7715 - val_loss: 0.5237 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7930\n",
            "         frontal    central   parietal  occipital\n",
            "theta  78.906250  78.906250  78.906250  77.734375\n",
            "alpha  78.906250  78.906250  78.515625  78.125000\n",
            "beta   79.296875  78.125000  78.906250  78.125000\n",
            "gamma  78.906250  79.296875  79.296875  79.296875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"ann\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_AeFSMS6LMz",
        "outputId": "2a7450f1-406c-4645-db6d-28050151d6d4"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6079 - accuracy: 0.7490 - val_loss: 0.5583 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7510 - val_loss: 0.5537 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7510 - val_loss: 0.5524 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7510 - val_loss: 0.5540 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7490 - val_loss: 0.5546 - val_accuracy: 0.7500\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7520 - val_loss: 0.5502 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7461 - val_loss: 0.5501 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7490 - val_loss: 0.5475 - val_accuracy: 0.7500\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7520 - val_loss: 0.5570 - val_accuracy: 0.7500\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7490 - val_loss: 0.5485 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7480 - val_loss: 0.5528 - val_accuracy: 0.7578\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7461 - val_loss: 0.5490 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7451 - val_loss: 0.5500 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7432 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7520 - val_loss: 0.5510 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7500 - val_loss: 0.5502 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7480 - val_loss: 0.5538 - val_accuracy: 0.7500\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7500 - val_loss: 0.5517 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7480 - val_loss: 0.5521 - val_accuracy: 0.7500\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7480 - val_loss: 0.5512 - val_accuracy: 0.7500\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.5512 - accuracy: 0.7500\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 5ms/step - loss: 0.5963 - accuracy: 0.7471 - val_loss: 0.5692 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7520 - val_loss: 0.5732 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7461 - val_loss: 0.5724 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7480 - val_loss: 0.5734 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7500 - val_loss: 0.5707 - val_accuracy: 0.7578\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7510 - val_loss: 0.5720 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7520 - val_loss: 0.5699 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7529 - val_loss: 0.5714 - val_accuracy: 0.7578\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7490 - val_loss: 0.5704 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7549 - val_loss: 0.5735 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7559 - val_loss: 0.5690 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7510 - val_loss: 0.5676 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7510 - val_loss: 0.5674 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7529 - val_loss: 0.5724 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7520 - val_loss: 0.5637 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7500 - val_loss: 0.5699 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7549 - val_loss: 0.5643 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7588 - val_loss: 0.5666 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7588 - val_loss: 0.5684 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7568 - val_loss: 0.5723 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6001 - accuracy: 0.7314 - val_loss: 0.5855 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7510 - val_loss: 0.5736 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7510 - val_loss: 0.5721 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7510 - val_loss: 0.5854 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7510 - val_loss: 0.5679 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7510 - val_loss: 0.5685 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7510 - val_loss: 0.5667 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7510 - val_loss: 0.5672 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7510 - val_loss: 0.5686 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7510 - val_loss: 0.5687 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7520 - val_loss: 0.5737 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7510 - val_loss: 0.5704 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7510 - val_loss: 0.5652 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7520 - val_loss: 0.5683 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7529 - val_loss: 0.5719 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7529 - val_loss: 0.5759 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7529 - val_loss: 0.5698 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7529 - val_loss: 0.5750 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7529 - val_loss: 0.5707 - val_accuracy: 0.7500\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7520 - val_loss: 0.5666 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6145 - accuracy: 0.7334 - val_loss: 0.5571 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7510 - val_loss: 0.5523 - val_accuracy: 0.7578\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7500 - val_loss: 0.5588 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7480 - val_loss: 0.5534 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7520 - val_loss: 0.5539 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7500 - val_loss: 0.5548 - val_accuracy: 0.7578\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7500 - val_loss: 0.5560 - val_accuracy: 0.7578\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7510 - val_loss: 0.5552 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7471 - val_loss: 0.5562 - val_accuracy: 0.7617\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7500 - val_loss: 0.5581 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.7539 - val_loss: 0.5562 - val_accuracy: 0.7617\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.7520 - val_loss: 0.5572 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7510 - val_loss: 0.5586 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7549 - val_loss: 0.5569 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7549 - val_loss: 0.5591 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7539 - val_loss: 0.5592 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.7568 - val_loss: 0.5577 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.7529 - val_loss: 0.5606 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.7529 - val_loss: 0.5585 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7559 - val_loss: 0.5622 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 9ms/step - loss: 0.6380 - accuracy: 0.6787 - val_loss: 0.5545 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7480 - val_loss: 0.5516 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7510 - val_loss: 0.5536 - val_accuracy: 0.7500\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7500 - val_loss: 0.5501 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7500 - val_loss: 0.5543 - val_accuracy: 0.7500\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7480 - val_loss: 0.5514 - val_accuracy: 0.7500\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7480 - val_loss: 0.5504 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7480 - val_loss: 0.5524 - val_accuracy: 0.7500\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7510 - val_loss: 0.5509 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7490 - val_loss: 0.5553 - val_accuracy: 0.7461\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7471 - val_loss: 0.5515 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7520 - val_loss: 0.5517 - val_accuracy: 0.7500\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7510 - val_loss: 0.5612 - val_accuracy: 0.7578\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7461 - val_loss: 0.5538 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7471 - val_loss: 0.5601 - val_accuracy: 0.7578\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7402 - val_loss: 0.5557 - val_accuracy: 0.7578\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7510 - val_loss: 0.5587 - val_accuracy: 0.7617\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7490 - val_loss: 0.5529 - val_accuracy: 0.7461\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7480 - val_loss: 0.5516 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7383 - val_loss: 0.5521 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6001 - accuracy: 0.7510 - val_loss: 0.5757 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7510 - val_loss: 0.5814 - val_accuracy: 0.7617\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7490 - val_loss: 0.5766 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7500 - val_loss: 0.5724 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7510 - val_loss: 0.5795 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7480 - val_loss: 0.5672 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7520 - val_loss: 0.5757 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7559 - val_loss: 0.5717 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7520 - val_loss: 0.5755 - val_accuracy: 0.7461\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7559 - val_loss: 0.5684 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7539 - val_loss: 0.5751 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7539 - val_loss: 0.5705 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7559 - val_loss: 0.5681 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7520 - val_loss: 0.5719 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7578 - val_loss: 0.5751 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7568 - val_loss: 0.5753 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.7588 - val_loss: 0.5655 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7559 - val_loss: 0.5711 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7549 - val_loss: 0.5762 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7549 - val_loss: 0.5688 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.5771 - accuracy: 0.7510 - val_loss: 0.5867 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7510 - val_loss: 0.5815 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7510 - val_loss: 0.5795 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7510 - val_loss: 0.5798 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7510 - val_loss: 0.5759 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7510 - val_loss: 0.5771 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.7510 - val_loss: 0.5767 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7510 - val_loss: 0.5752 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7510 - val_loss: 0.5765 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7510 - val_loss: 0.5747 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7510 - val_loss: 0.5720 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7510 - val_loss: 0.5714 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7471 - val_loss: 0.5774 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7510 - val_loss: 0.5743 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7510 - val_loss: 0.5738 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7510 - val_loss: 0.5740 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7520 - val_loss: 0.5721 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7520 - val_loss: 0.5723 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7549 - val_loss: 0.5727 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7510 - val_loss: 0.5744 - val_accuracy: 0.7500\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5744 - accuracy: 0.7500\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.5841 - accuracy: 0.7520 - val_loss: 0.5607 - val_accuracy: 0.7500\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7480 - val_loss: 0.5621 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7422 - val_loss: 0.5659 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7520 - val_loss: 0.5588 - val_accuracy: 0.7617\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7471 - val_loss: 0.5611 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7520 - val_loss: 0.5607 - val_accuracy: 0.7617\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7529 - val_loss: 0.5642 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7529 - val_loss: 0.5606 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7510 - val_loss: 0.5639 - val_accuracy: 0.7500\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7441 - val_loss: 0.5630 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7559 - val_loss: 0.5617 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7549 - val_loss: 0.5638 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7559 - val_loss: 0.5663 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7549 - val_loss: 0.5620 - val_accuracy: 0.7578\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7568 - val_loss: 0.5671 - val_accuracy: 0.7578\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7588 - val_loss: 0.5659 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7568 - val_loss: 0.5645 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7578 - val_loss: 0.5679 - val_accuracy: 0.7461\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7490 - val_loss: 0.5716 - val_accuracy: 0.7461\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7559 - val_loss: 0.5639 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6164 - accuracy: 0.7441 - val_loss: 0.5751 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7510 - val_loss: 0.5640 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7520 - val_loss: 0.5631 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.7510 - val_loss: 0.5610 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7510 - val_loss: 0.5590 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7510 - val_loss: 0.5590 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7490 - val_loss: 0.5619 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.7490 - val_loss: 0.5581 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.7510 - val_loss: 0.5588 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.7480 - val_loss: 0.5588 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.7480 - val_loss: 0.5591 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7539 - val_loss: 0.5581 - val_accuracy: 0.7617\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7490 - val_loss: 0.5604 - val_accuracy: 0.7578\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.7500 - val_loss: 0.5638 - val_accuracy: 0.7617\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7490 - val_loss: 0.5598 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7500 - val_loss: 0.5599 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7539 - val_loss: 0.5623 - val_accuracy: 0.7500\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7510 - val_loss: 0.5624 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7520 - val_loss: 0.5582 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7568 - val_loss: 0.5615 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6023 - accuracy: 0.7324 - val_loss: 0.5647 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7520 - val_loss: 0.5672 - val_accuracy: 0.7500\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7461 - val_loss: 0.5714 - val_accuracy: 0.7500\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7510 - val_loss: 0.5704 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7490 - val_loss: 0.5659 - val_accuracy: 0.7617\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7490 - val_loss: 0.5678 - val_accuracy: 0.7617\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7539 - val_loss: 0.5625 - val_accuracy: 0.7578\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7529 - val_loss: 0.5712 - val_accuracy: 0.7578\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7471 - val_loss: 0.5689 - val_accuracy: 0.7500\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7520 - val_loss: 0.5694 - val_accuracy: 0.7578\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7549 - val_loss: 0.5656 - val_accuracy: 0.7578\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7539 - val_loss: 0.5652 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7549 - val_loss: 0.5634 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.7549 - val_loss: 0.5638 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7510 - val_loss: 0.5629 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7539 - val_loss: 0.5658 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7549 - val_loss: 0.5693 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7559 - val_loss: 0.5617 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7549 - val_loss: 0.5644 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7529 - val_loss: 0.5738 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.5987 - accuracy: 0.7500 - val_loss: 0.5934 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7510 - val_loss: 0.5858 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7510 - val_loss: 0.5841 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7510 - val_loss: 0.5828 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7510 - val_loss: 0.5793 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7510 - val_loss: 0.5796 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7510 - val_loss: 0.5758 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7510 - val_loss: 0.5779 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7510 - val_loss: 0.5858 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7510 - val_loss: 0.5761 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7510 - val_loss: 0.5751 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7510 - val_loss: 0.5744 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7510 - val_loss: 0.5771 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7510 - val_loss: 0.5796 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7500 - val_loss: 0.5724 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7510 - val_loss: 0.5755 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7510 - val_loss: 0.5791 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7510 - val_loss: 0.5704 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7510 - val_loss: 0.5711 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7510 - val_loss: 0.5810 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.5991 - accuracy: 0.7451 - val_loss: 0.5657 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7471 - val_loss: 0.5598 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7480 - val_loss: 0.5551 - val_accuracy: 0.7617\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7490 - val_loss: 0.5550 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.7520 - val_loss: 0.5555 - val_accuracy: 0.7578\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7520 - val_loss: 0.5576 - val_accuracy: 0.7578\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7520 - val_loss: 0.5559 - val_accuracy: 0.7617\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7520 - val_loss: 0.5556 - val_accuracy: 0.7617\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7529 - val_loss: 0.5585 - val_accuracy: 0.7578\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7549 - val_loss: 0.5575 - val_accuracy: 0.7578\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7549 - val_loss: 0.5558 - val_accuracy: 0.7578\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7490 - val_loss: 0.5562 - val_accuracy: 0.7578\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7549 - val_loss: 0.5581 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7559 - val_loss: 0.5601 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7559 - val_loss: 0.5582 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7549 - val_loss: 0.5607 - val_accuracy: 0.7578\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7568 - val_loss: 0.5613 - val_accuracy: 0.7578\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7559 - val_loss: 0.5614 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7559 - val_loss: 0.5598 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7559 - val_loss: 0.5598 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 0.6054 - accuracy: 0.7441 - val_loss: 0.5599 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5753 - accuracy: 0.7432 - val_loss: 0.5597 - val_accuracy: 0.7422\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7529 - val_loss: 0.5559 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7471 - val_loss: 0.5553 - val_accuracy: 0.7578\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7559 - val_loss: 0.5532 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7559 - val_loss: 0.5538 - val_accuracy: 0.7500\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7549 - val_loss: 0.5519 - val_accuracy: 0.7578\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7559 - val_loss: 0.5516 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7559 - val_loss: 0.5522 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.7568 - val_loss: 0.5506 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.7549 - val_loss: 0.5516 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.7578 - val_loss: 0.5504 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.7578 - val_loss: 0.5529 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7607 - val_loss: 0.5545 - val_accuracy: 0.7500\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7529 - val_loss: 0.5555 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.7559 - val_loss: 0.5521 - val_accuracy: 0.7500\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7578 - val_loss: 0.5529 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7578 - val_loss: 0.5538 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7598 - val_loss: 0.5520 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.7568 - val_loss: 0.5537 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6009 - accuracy: 0.7451 - val_loss: 0.5754 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7520 - val_loss: 0.5663 - val_accuracy: 0.7578\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.7559 - val_loss: 0.5713 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7588 - val_loss: 0.5635 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7588 - val_loss: 0.5623 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7607 - val_loss: 0.5719 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7607 - val_loss: 0.5628 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7607 - val_loss: 0.5562 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7607 - val_loss: 0.5604 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7627 - val_loss: 0.5597 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7617 - val_loss: 0.5524 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7607 - val_loss: 0.5617 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.7627 - val_loss: 0.5546 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7627 - val_loss: 0.5608 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7637 - val_loss: 0.5581 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7607 - val_loss: 0.5574 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7617 - val_loss: 0.5550 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7607 - val_loss: 0.5572 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7637 - val_loss: 0.5624 - val_accuracy: 0.7500\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7607 - val_loss: 0.5611 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.5963 - accuracy: 0.7510 - val_loss: 0.5809 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7510 - val_loss: 0.5713 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7510 - val_loss: 0.5692 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7510 - val_loss: 0.5693 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7490 - val_loss: 0.5716 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7510 - val_loss: 0.5643 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7510 - val_loss: 0.5652 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7510 - val_loss: 0.5679 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7510 - val_loss: 0.5678 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7510 - val_loss: 0.5678 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7510 - val_loss: 0.5649 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7500 - val_loss: 0.5740 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7510 - val_loss: 0.5674 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7510 - val_loss: 0.5731 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7510 - val_loss: 0.5655 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7510 - val_loss: 0.5747 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7510 - val_loss: 0.5650 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7510 - val_loss: 0.5669 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7510 - val_loss: 0.5748 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7500 - val_loss: 0.5732 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 1s 6ms/step - loss: 0.6299 - accuracy: 0.7344 - val_loss: 0.5780 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.7529 - val_loss: 0.5583 - val_accuracy: 0.7578\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7539 - val_loss: 0.5594 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7559 - val_loss: 0.5616 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7588 - val_loss: 0.5611 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7598 - val_loss: 0.5635 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7617 - val_loss: 0.5607 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7588 - val_loss: 0.5693 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7627 - val_loss: 0.5629 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7588 - val_loss: 0.5639 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.7617 - val_loss: 0.5640 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7607 - val_loss: 0.5664 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7627 - val_loss: 0.5637 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7588 - val_loss: 0.5628 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7607 - val_loss: 0.5668 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7617 - val_loss: 0.5651 - val_accuracy: 0.7500\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7588 - val_loss: 0.5678 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7617 - val_loss: 0.5689 - val_accuracy: 0.7500\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7627 - val_loss: 0.5651 - val_accuracy: 0.7500\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7500\n",
            "         frontal    central   parietal  occipital\n",
            "theta  75.000000  75.390625  75.390625  75.390625\n",
            "alpha  75.390625  75.390625  75.000000  75.390625\n",
            "beta   75.390625  75.390625  75.390625  75.390625\n",
            "gamma  75.390625  75.390625  75.390625  75.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HAHV\",\"lstm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnnNa1K76OJ0",
        "outputId": "0757caba-40dd-448f-9f80-5f992ab8f0df"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 4s 16ms/step - loss: 0.7728 - accuracy: 0.5215 - val_loss: 0.6184 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.6855 - val_loss: 0.6212 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.6816 - val_loss: 0.6170 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.6973 - val_loss: 0.6156 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.7109 - val_loss: 0.6162 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.7236 - val_loss: 0.6165 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.7188 - val_loss: 0.6191 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.7217 - val_loss: 0.6184 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.7217 - val_loss: 0.6174 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.7246 - val_loss: 0.6159 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.7256 - val_loss: 0.6146 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.7266 - val_loss: 0.6146 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.7246 - val_loss: 0.6155 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.7246 - val_loss: 0.6139 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.7256 - val_loss: 0.6145 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.7256 - val_loss: 0.6148 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.7256 - val_loss: 0.6172 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.7256 - val_loss: 0.6163 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.7256 - val_loss: 0.6159 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.7256 - val_loss: 0.6169 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 17ms/step - loss: 0.6841 - accuracy: 0.5850 - val_loss: 0.6232 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.7021 - val_loss: 0.6162 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.7188 - val_loss: 0.6136 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.7217 - val_loss: 0.6134 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.7256 - val_loss: 0.6146 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.7256 - val_loss: 0.6150 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.7256 - val_loss: 0.6144 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.7256 - val_loss: 0.6150 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5904 - accuracy: 0.7256 - val_loss: 0.6143 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.7256 - val_loss: 0.6146 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.7256 - val_loss: 0.6141 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.7256 - val_loss: 0.6145 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5876 - accuracy: 0.7256 - val_loss: 0.6144 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7256 - val_loss: 0.6162 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5865 - accuracy: 0.7256 - val_loss: 0.6156 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.7256 - val_loss: 0.6167 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.7256 - val_loss: 0.6163 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.7256 - val_loss: 0.6171 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.7256 - val_loss: 0.6167 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5921 - accuracy: 0.7256 - val_loss: 0.6177 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6177 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 16ms/step - loss: 0.6864 - accuracy: 0.5869 - val_loss: 0.6113 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6201 - accuracy: 0.7139 - val_loss: 0.6121 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.7051 - val_loss: 0.6112 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.7178 - val_loss: 0.6138 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.7246 - val_loss: 0.6151 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6070 - accuracy: 0.7217 - val_loss: 0.6143 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.7236 - val_loss: 0.6155 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5960 - accuracy: 0.7256 - val_loss: 0.6146 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5960 - accuracy: 0.7256 - val_loss: 0.6137 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.7256 - val_loss: 0.6122 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.7256 - val_loss: 0.6122 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5989 - accuracy: 0.7256 - val_loss: 0.6119 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.7256 - val_loss: 0.6116 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5960 - accuracy: 0.7246 - val_loss: 0.6115 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.7256 - val_loss: 0.6121 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.7256 - val_loss: 0.6121 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.7256 - val_loss: 0.6130 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.7256 - val_loss: 0.6139 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7256 - val_loss: 0.6125 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.7256 - val_loss: 0.6126 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.7891 - accuracy: 0.5205 - val_loss: 0.6116 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.6670 - val_loss: 0.6099 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.6904 - val_loss: 0.6091 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6297 - accuracy: 0.6855 - val_loss: 0.6082 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6128 - accuracy: 0.7061 - val_loss: 0.6134 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6171 - accuracy: 0.7051 - val_loss: 0.6100 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.7168 - val_loss: 0.6104 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.7188 - val_loss: 0.6104 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6171 - accuracy: 0.7227 - val_loss: 0.6135 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.7236 - val_loss: 0.6122 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6042 - accuracy: 0.7197 - val_loss: 0.6136 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6024 - accuracy: 0.7207 - val_loss: 0.6127 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5947 - accuracy: 0.7266 - val_loss: 0.6129 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6038 - accuracy: 0.7236 - val_loss: 0.6115 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5960 - accuracy: 0.7227 - val_loss: 0.6120 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.7246 - val_loss: 0.6109 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6008 - accuracy: 0.7256 - val_loss: 0.6111 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5924 - accuracy: 0.7256 - val_loss: 0.6123 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5933 - accuracy: 0.7256 - val_loss: 0.6107 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.7256 - val_loss: 0.6114 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6633 - accuracy: 0.6221 - val_loss: 0.6134 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.7236 - val_loss: 0.6148 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.7148 - val_loss: 0.6153 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.7109 - val_loss: 0.6164 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7188 - val_loss: 0.6155 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.7197 - val_loss: 0.6153 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.7256 - val_loss: 0.6156 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5983 - accuracy: 0.7246 - val_loss: 0.6155 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.7246 - val_loss: 0.6152 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.7236 - val_loss: 0.6179 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.7256 - val_loss: 0.6174 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.7246 - val_loss: 0.6170 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6010 - accuracy: 0.7256 - val_loss: 0.6155 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.7256 - val_loss: 0.6157 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.7256 - val_loss: 0.6152 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.7256 - val_loss: 0.6151 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.7256 - val_loss: 0.6163 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.7246 - val_loss: 0.6154 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.7256 - val_loss: 0.6164 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.7256 - val_loss: 0.6151 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6709 - accuracy: 0.6025 - val_loss: 0.6121 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.7217 - val_loss: 0.6112 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.7168 - val_loss: 0.6119 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6064 - accuracy: 0.7197 - val_loss: 0.6129 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5949 - accuracy: 0.7236 - val_loss: 0.6142 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6030 - accuracy: 0.7246 - val_loss: 0.6139 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6015 - accuracy: 0.7236 - val_loss: 0.6141 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.7256 - val_loss: 0.6146 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5975 - accuracy: 0.7246 - val_loss: 0.6143 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.7256 - val_loss: 0.6150 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.7246 - val_loss: 0.6149 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.7256 - val_loss: 0.6144 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.7246 - val_loss: 0.6153 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.7256 - val_loss: 0.6159 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5980 - accuracy: 0.7256 - val_loss: 0.6152 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.7256 - val_loss: 0.6154 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5987 - accuracy: 0.7256 - val_loss: 0.6159 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5887 - accuracy: 0.7256 - val_loss: 0.6158 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.7256 - val_loss: 0.6155 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.7256 - val_loss: 0.6163 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6439 - accuracy: 0.6719 - val_loss: 0.6128 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.7246 - val_loss: 0.6120 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6059 - accuracy: 0.7236 - val_loss: 0.6114 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.7227 - val_loss: 0.6134 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.7266 - val_loss: 0.6138 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.7256 - val_loss: 0.6117 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.7256 - val_loss: 0.6120 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.7246 - val_loss: 0.6127 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.7256 - val_loss: 0.6131 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.7256 - val_loss: 0.6136 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7256 - val_loss: 0.6143 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.7256 - val_loss: 0.6128 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5934 - accuracy: 0.7256 - val_loss: 0.6120 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7256 - val_loss: 0.6114 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5885 - accuracy: 0.7256 - val_loss: 0.6116 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5881 - accuracy: 0.7256 - val_loss: 0.6116 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.7256 - val_loss: 0.6107 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5941 - accuracy: 0.7256 - val_loss: 0.6128 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.7256 - val_loss: 0.6119 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.7256 - val_loss: 0.6119 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6531 - accuracy: 0.6494 - val_loss: 0.6129 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.7109 - val_loss: 0.6113 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.7246 - val_loss: 0.6097 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6089 - accuracy: 0.7217 - val_loss: 0.6087 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.7256 - val_loss: 0.6089 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.7227 - val_loss: 0.6093 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5987 - accuracy: 0.7256 - val_loss: 0.6085 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5973 - accuracy: 0.7256 - val_loss: 0.6082 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.7246 - val_loss: 0.6084 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5956 - accuracy: 0.7256 - val_loss: 0.6079 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5925 - accuracy: 0.7256 - val_loss: 0.6078 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5962 - accuracy: 0.7256 - val_loss: 0.6084 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.7256 - val_loss: 0.6083 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5878 - accuracy: 0.7256 - val_loss: 0.6086 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5954 - accuracy: 0.7256 - val_loss: 0.6096 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5968 - accuracy: 0.7256 - val_loss: 0.6095 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5881 - accuracy: 0.7256 - val_loss: 0.6095 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5868 - accuracy: 0.7256 - val_loss: 0.6092 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5895 - accuracy: 0.7256 - val_loss: 0.6097 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5899 - accuracy: 0.7256 - val_loss: 0.6095 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6538 - accuracy: 0.6533 - val_loss: 0.6172 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.7100 - val_loss: 0.6113 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7119 - val_loss: 0.6110 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6240 - accuracy: 0.7119 - val_loss: 0.6116 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.7178 - val_loss: 0.6108 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.7227 - val_loss: 0.6094 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.7207 - val_loss: 0.6084 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.7217 - val_loss: 0.6103 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.7256 - val_loss: 0.6124 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7236 - val_loss: 0.6119 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5978 - accuracy: 0.7256 - val_loss: 0.6117 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.7266 - val_loss: 0.6118 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.7256 - val_loss: 0.6108 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.7256 - val_loss: 0.6103 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.7256 - val_loss: 0.6112 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.7256 - val_loss: 0.6124 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.7256 - val_loss: 0.6123 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.7256 - val_loss: 0.6112 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.7256 - val_loss: 0.6107 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.7256 - val_loss: 0.6111 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 16ms/step - loss: 0.6267 - accuracy: 0.6787 - val_loss: 0.6160 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.7236 - val_loss: 0.6156 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.7246 - val_loss: 0.6158 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6071 - accuracy: 0.7217 - val_loss: 0.6175 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.7246 - val_loss: 0.6153 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.7256 - val_loss: 0.6170 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.7266 - val_loss: 0.6156 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.7256 - val_loss: 0.6158 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.7256 - val_loss: 0.6154 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.7256 - val_loss: 0.6157 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.7256 - val_loss: 0.6161 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5868 - accuracy: 0.7266 - val_loss: 0.6159 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5886 - accuracy: 0.7256 - val_loss: 0.6158 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.7256 - val_loss: 0.6157 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.7256 - val_loss: 0.6165 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.7256 - val_loss: 0.6157 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.7256 - val_loss: 0.6167 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5915 - accuracy: 0.7256 - val_loss: 0.6162 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5888 - accuracy: 0.7256 - val_loss: 0.6162 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5875 - accuracy: 0.7256 - val_loss: 0.6168 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6877 - accuracy: 0.5947 - val_loss: 0.6107 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7051 - val_loss: 0.6084 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.7188 - val_loss: 0.6079 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.7197 - val_loss: 0.6087 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.7217 - val_loss: 0.6081 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.7217 - val_loss: 0.6070 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.7256 - val_loss: 0.6070 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.7246 - val_loss: 0.6069 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.7217 - val_loss: 0.6067 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.7256 - val_loss: 0.6075 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.7246 - val_loss: 0.6068 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.7256 - val_loss: 0.6087 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.7266 - val_loss: 0.6074 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.7256 - val_loss: 0.6087 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.7256 - val_loss: 0.6086 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5974 - accuracy: 0.7256 - val_loss: 0.6073 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.7256 - val_loss: 0.6064 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.7246 - val_loss: 0.6083 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.7256 - val_loss: 0.6074 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5959 - accuracy: 0.7256 - val_loss: 0.6075 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 17ms/step - loss: 0.7334 - accuracy: 0.5254 - val_loss: 0.6145 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.7002 - val_loss: 0.6121 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.7041 - val_loss: 0.6117 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6112 - accuracy: 0.7227 - val_loss: 0.6116 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.7246 - val_loss: 0.6132 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.7178 - val_loss: 0.6120 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6157 - accuracy: 0.7217 - val_loss: 0.6123 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6142 - accuracy: 0.7246 - val_loss: 0.6132 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6022 - accuracy: 0.7236 - val_loss: 0.6119 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5898 - accuracy: 0.7256 - val_loss: 0.6100 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5968 - accuracy: 0.7236 - val_loss: 0.6104 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.7275 - val_loss: 0.6108 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5975 - accuracy: 0.7256 - val_loss: 0.6117 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5921 - accuracy: 0.7256 - val_loss: 0.6110 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6008 - accuracy: 0.7256 - val_loss: 0.6105 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.7246 - val_loss: 0.6102 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5972 - accuracy: 0.7266 - val_loss: 0.6112 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.7246 - val_loss: 0.6117 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5937 - accuracy: 0.7246 - val_loss: 0.6106 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5892 - accuracy: 0.7256 - val_loss: 0.6094 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 14ms/step - loss: 0.6262 - accuracy: 0.6904 - val_loss: 0.6149 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.7031 - val_loss: 0.6137 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.7158 - val_loss: 0.6114 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.7217 - val_loss: 0.6117 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.7227 - val_loss: 0.6117 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.7314 - val_loss: 0.6124 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.7217 - val_loss: 0.6129 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.7217 - val_loss: 0.6124 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.7207 - val_loss: 0.6110 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.7236 - val_loss: 0.6094 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5861 - accuracy: 0.7266 - val_loss: 0.6077 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5926 - accuracy: 0.7236 - val_loss: 0.6086 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.7217 - val_loss: 0.6083 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.7266 - val_loss: 0.6073 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.7256 - val_loss: 0.6076 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.7236 - val_loss: 0.6094 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.7256 - val_loss: 0.6090 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.7256 - val_loss: 0.6084 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.7256 - val_loss: 0.6061 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.7256 - val_loss: 0.6069 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 3s 16ms/step - loss: 0.6438 - accuracy: 0.6787 - val_loss: 0.6172 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.7090 - val_loss: 0.6177 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.7178 - val_loss: 0.6175 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5991 - accuracy: 0.7207 - val_loss: 0.6165 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5970 - accuracy: 0.7256 - val_loss: 0.6151 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5939 - accuracy: 0.7266 - val_loss: 0.6152 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5963 - accuracy: 0.7256 - val_loss: 0.6161 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5948 - accuracy: 0.7256 - val_loss: 0.6169 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.7256 - val_loss: 0.6155 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5893 - accuracy: 0.7246 - val_loss: 0.6160 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5884 - accuracy: 0.7256 - val_loss: 0.6149 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6018 - accuracy: 0.7256 - val_loss: 0.6141 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5981 - accuracy: 0.7256 - val_loss: 0.6151 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.7256 - val_loss: 0.6157 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5870 - accuracy: 0.7256 - val_loss: 0.6134 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5924 - accuracy: 0.7256 - val_loss: 0.6152 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5921 - accuracy: 0.7256 - val_loss: 0.6163 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5938 - accuracy: 0.7256 - val_loss: 0.6149 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5828 - accuracy: 0.7256 - val_loss: 0.6135 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5881 - accuracy: 0.7256 - val_loss: 0.6140 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 16ms/step - loss: 0.6635 - accuracy: 0.6221 - val_loss: 0.6118 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6298 - accuracy: 0.7061 - val_loss: 0.6086 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6160 - accuracy: 0.7109 - val_loss: 0.6092 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.7148 - val_loss: 0.6080 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.7217 - val_loss: 0.6084 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.7217 - val_loss: 0.6083 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.7236 - val_loss: 0.6091 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.7197 - val_loss: 0.6092 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.7246 - val_loss: 0.6094 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.7236 - val_loss: 0.6103 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.7246 - val_loss: 0.6097 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.7256 - val_loss: 0.6096 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.7256 - val_loss: 0.6096 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.7256 - val_loss: 0.6099 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.7227 - val_loss: 0.6088 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.7246 - val_loss: 0.6088 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.7256 - val_loss: 0.6076 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.7246 - val_loss: 0.6085 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.7256 - val_loss: 0.6080 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.7256 - val_loss: 0.6085 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.6992\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 16ms/step - loss: 0.6336 - accuracy: 0.6807 - val_loss: 0.6149 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.7188 - val_loss: 0.6102 - val_accuracy: 0.6992\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.7139 - val_loss: 0.6101 - val_accuracy: 0.6992\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.7178 - val_loss: 0.6096 - val_accuracy: 0.6992\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.7188 - val_loss: 0.6094 - val_accuracy: 0.6992\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.7246 - val_loss: 0.6087 - val_accuracy: 0.6992\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.7207 - val_loss: 0.6089 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.7266 - val_loss: 0.6088 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.7246 - val_loss: 0.6089 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.7256 - val_loss: 0.6096 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.7246 - val_loss: 0.6092 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.7246 - val_loss: 0.6090 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.7217 - val_loss: 0.6095 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.7266 - val_loss: 0.6094 - val_accuracy: 0.6992\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.7227 - val_loss: 0.6078 - val_accuracy: 0.6992\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.7256 - val_loss: 0.6075 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.7256 - val_loss: 0.6084 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.7256 - val_loss: 0.6090 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.7246 - val_loss: 0.6097 - val_accuracy: 0.6992\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5847 - accuracy: 0.7246 - val_loss: 0.6089 - val_accuracy: 0.6992\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6089 - accuracy: 0.6992\n",
            "         frontal    central   parietal  occipital\n",
            "theta  69.921875  69.921875  69.921875  69.921875\n",
            "alpha  69.921875  69.921875  69.921875  69.921875\n",
            "beta   69.921875  69.921875  69.921875  69.921875\n",
            "gamma  69.921875  69.921875  69.921875  69.921875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LAHV\",\"lstm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EqqV3s_6Q4A",
        "outputId": "d425622e-4ad2-4fdd-ef13-3014f3c7011d"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6847 - accuracy: 0.6260 - val_loss: 0.5606 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.7139 - val_loss: 0.5596 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.7197 - val_loss: 0.5620 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.7305 - val_loss: 0.5622 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.7412 - val_loss: 0.5629 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7422 - val_loss: 0.5638 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.7441 - val_loss: 0.5652 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.7461 - val_loss: 0.5669 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.7432 - val_loss: 0.5674 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7461 - val_loss: 0.5673 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7471 - val_loss: 0.5678 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7461 - val_loss: 0.5675 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.7441 - val_loss: 0.5701 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.7451 - val_loss: 0.5704 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.7451 - val_loss: 0.5697 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7451 - val_loss: 0.5658 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.7471 - val_loss: 0.5691 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.7471 - val_loss: 0.5717 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.7461 - val_loss: 0.5659 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7471 - val_loss: 0.5688 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6522 - accuracy: 0.6553 - val_loss: 0.5664 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.7383 - val_loss: 0.5635 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.7441 - val_loss: 0.5678 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5948 - accuracy: 0.7363 - val_loss: 0.5682 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.7480 - val_loss: 0.5639 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.7451 - val_loss: 0.5647 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.7480 - val_loss: 0.5654 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.7412 - val_loss: 0.5638 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.7451 - val_loss: 0.5638 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5795 - accuracy: 0.7441 - val_loss: 0.5641 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.7451 - val_loss: 0.5633 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7471 - val_loss: 0.5642 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5772 - accuracy: 0.7480 - val_loss: 0.5646 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7471 - val_loss: 0.5644 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.7471 - val_loss: 0.5636 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.7471 - val_loss: 0.5641 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7471 - val_loss: 0.5660 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.7471 - val_loss: 0.5647 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7471 - val_loss: 0.5634 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7471 - val_loss: 0.5641 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 3s 25ms/step - loss: 0.6958 - accuracy: 0.5586 - val_loss: 0.5786 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5851 - accuracy: 0.7314 - val_loss: 0.5582 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7363 - val_loss: 0.5561 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.7393 - val_loss: 0.5567 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.7441 - val_loss: 0.5561 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7441 - val_loss: 0.5556 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5854 - accuracy: 0.7451 - val_loss: 0.5558 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.7461 - val_loss: 0.5561 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7471 - val_loss: 0.5564 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7471 - val_loss: 0.5567 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.7471 - val_loss: 0.5589 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7471 - val_loss: 0.5596 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.7471 - val_loss: 0.5592 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.7471 - val_loss: 0.5644 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.7471 - val_loss: 0.5610 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.7471 - val_loss: 0.5601 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.7471 - val_loss: 0.5596 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.7471 - val_loss: 0.5610 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7471 - val_loss: 0.5616 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7471 - val_loss: 0.5600 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6883 - accuracy: 0.5938 - val_loss: 0.5817 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.7178 - val_loss: 0.5734 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.7393 - val_loss: 0.5741 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5889 - accuracy: 0.7432 - val_loss: 0.5719 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.7451 - val_loss: 0.5719 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.7471 - val_loss: 0.5701 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7471 - val_loss: 0.5672 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.7471 - val_loss: 0.5727 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.7461 - val_loss: 0.5701 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.7461 - val_loss: 0.5663 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7471 - val_loss: 0.5660 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7471 - val_loss: 0.5703 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7471 - val_loss: 0.5690 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.7471 - val_loss: 0.5707 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7471 - val_loss: 0.5717 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7471 - val_loss: 0.5710 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7471 - val_loss: 0.5682 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.7471 - val_loss: 0.5604 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7461 - val_loss: 0.5633 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.7471 - val_loss: 0.5650 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 20ms/step - loss: 0.6530 - accuracy: 0.6572 - val_loss: 0.5588 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.7070 - val_loss: 0.5604 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6207 - accuracy: 0.7109 - val_loss: 0.5679 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6142 - accuracy: 0.7246 - val_loss: 0.5624 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6033 - accuracy: 0.7314 - val_loss: 0.5692 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.7422 - val_loss: 0.5675 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5895 - accuracy: 0.7451 - val_loss: 0.5689 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.7412 - val_loss: 0.5666 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5736 - accuracy: 0.7471 - val_loss: 0.5657 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5772 - accuracy: 0.7461 - val_loss: 0.5650 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.7490 - val_loss: 0.5679 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.7480 - val_loss: 0.5686 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7471 - val_loss: 0.5706 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.7471 - val_loss: 0.5696 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.7471 - val_loss: 0.5676 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.7471 - val_loss: 0.5678 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.7471 - val_loss: 0.5673 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5754 - accuracy: 0.7471 - val_loss: 0.5704 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7471 - val_loss: 0.5678 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.7471 - val_loss: 0.5655 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.8336 - accuracy: 0.4561 - val_loss: 0.6156 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.7256 - val_loss: 0.5636 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.7402 - val_loss: 0.5611 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5829 - accuracy: 0.7373 - val_loss: 0.5597 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.7461 - val_loss: 0.5622 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.7373 - val_loss: 0.5678 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.7422 - val_loss: 0.5634 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5853 - accuracy: 0.7461 - val_loss: 0.5623 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7441 - val_loss: 0.5600 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7471 - val_loss: 0.5614 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5784 - accuracy: 0.7480 - val_loss: 0.5621 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5825 - accuracy: 0.7471 - val_loss: 0.5614 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7471 - val_loss: 0.5614 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5761 - accuracy: 0.7471 - val_loss: 0.5627 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.7471 - val_loss: 0.5599 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5773 - accuracy: 0.7461 - val_loss: 0.5597 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.7471 - val_loss: 0.5601 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7471 - val_loss: 0.5601 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.7471 - val_loss: 0.5597 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7471 - val_loss: 0.5604 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6558 - accuracy: 0.6621 - val_loss: 0.5555 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6168 - accuracy: 0.7188 - val_loss: 0.5544 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6205 - accuracy: 0.7285 - val_loss: 0.5588 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.7344 - val_loss: 0.5570 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5960 - accuracy: 0.7412 - val_loss: 0.5613 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.7344 - val_loss: 0.5632 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5827 - accuracy: 0.7441 - val_loss: 0.5624 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5865 - accuracy: 0.7461 - val_loss: 0.5639 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.7451 - val_loss: 0.5630 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.7461 - val_loss: 0.5609 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5783 - accuracy: 0.7451 - val_loss: 0.5632 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.7471 - val_loss: 0.5594 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7461 - val_loss: 0.5646 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5727 - accuracy: 0.7471 - val_loss: 0.5643 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.7471 - val_loss: 0.5662 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5771 - accuracy: 0.7471 - val_loss: 0.5663 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5772 - accuracy: 0.7471 - val_loss: 0.5649 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.7471 - val_loss: 0.5633 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.7471 - val_loss: 0.5664 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5691 - accuracy: 0.7471 - val_loss: 0.5698 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 16ms/step - loss: 0.6333 - accuracy: 0.6592 - val_loss: 0.5595 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.7334 - val_loss: 0.5627 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.7266 - val_loss: 0.5641 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.7402 - val_loss: 0.5665 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7451 - val_loss: 0.5640 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.7461 - val_loss: 0.5657 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.7471 - val_loss: 0.5710 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7480 - val_loss: 0.5704 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.7471 - val_loss: 0.5660 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7461 - val_loss: 0.5696 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7471 - val_loss: 0.5721 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7471 - val_loss: 0.5696 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.7471 - val_loss: 0.5667 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7471 - val_loss: 0.5705 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.7471 - val_loss: 0.5681 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.7471 - val_loss: 0.5712 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.7471 - val_loss: 0.5675 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.7471 - val_loss: 0.5680 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.7471 - val_loss: 0.5642 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.7471 - val_loss: 0.5666 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 16ms/step - loss: 0.6490 - accuracy: 0.6758 - val_loss: 0.5714 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.7188 - val_loss: 0.5699 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.7197 - val_loss: 0.5670 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.7324 - val_loss: 0.5658 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.7285 - val_loss: 0.5658 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7432 - val_loss: 0.5641 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.7441 - val_loss: 0.5632 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7451 - val_loss: 0.5660 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7422 - val_loss: 0.5627 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5868 - accuracy: 0.7471 - val_loss: 0.5667 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7471 - val_loss: 0.5680 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.7461 - val_loss: 0.5676 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5824 - accuracy: 0.7471 - val_loss: 0.5692 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7471 - val_loss: 0.5682 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.7461 - val_loss: 0.5701 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7471 - val_loss: 0.5692 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7471 - val_loss: 0.5695 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7471 - val_loss: 0.5719 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.7471 - val_loss: 0.5697 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7471 - val_loss: 0.5699 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 20ms/step - loss: 0.7309 - accuracy: 0.5312 - val_loss: 0.5752 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5970 - accuracy: 0.7207 - val_loss: 0.5622 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6060 - accuracy: 0.7373 - val_loss: 0.5587 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.7432 - val_loss: 0.5602 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5956 - accuracy: 0.7451 - val_loss: 0.5616 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5815 - accuracy: 0.7490 - val_loss: 0.5630 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5845 - accuracy: 0.7432 - val_loss: 0.5642 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5791 - accuracy: 0.7461 - val_loss: 0.5609 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5770 - accuracy: 0.7471 - val_loss: 0.5619 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5776 - accuracy: 0.7461 - val_loss: 0.5605 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5648 - accuracy: 0.7480 - val_loss: 0.5603 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5830 - accuracy: 0.7480 - val_loss: 0.5597 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5782 - accuracy: 0.7471 - val_loss: 0.5605 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5702 - accuracy: 0.7471 - val_loss: 0.5604 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.7471 - val_loss: 0.5605 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.7480 - val_loss: 0.5600 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.7471 - val_loss: 0.5596 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.7471 - val_loss: 0.5596 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.7471 - val_loss: 0.5590 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5745 - accuracy: 0.7471 - val_loss: 0.5597 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6411 - accuracy: 0.6494 - val_loss: 0.5549 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.7295 - val_loss: 0.5539 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.7363 - val_loss: 0.5560 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.7383 - val_loss: 0.5578 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7471 - val_loss: 0.5562 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.7471 - val_loss: 0.5587 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.7461 - val_loss: 0.5652 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.7461 - val_loss: 0.5616 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.7471 - val_loss: 0.5586 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.7471 - val_loss: 0.5585 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7471 - val_loss: 0.5580 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7471 - val_loss: 0.5589 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.7471 - val_loss: 0.5574 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7471 - val_loss: 0.5625 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.7461 - val_loss: 0.5583 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.7471 - val_loss: 0.5612 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.7471 - val_loss: 0.5598 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7471 - val_loss: 0.5568 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7471 - val_loss: 0.5603 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7471 - val_loss: 0.5605 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 17ms/step - loss: 0.9028 - accuracy: 0.4658 - val_loss: 0.5616 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.6855 - val_loss: 0.5664 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6172 - accuracy: 0.7129 - val_loss: 0.5612 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.7246 - val_loss: 0.5591 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6134 - accuracy: 0.7158 - val_loss: 0.5577 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5934 - accuracy: 0.7354 - val_loss: 0.5578 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.7324 - val_loss: 0.5589 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5873 - accuracy: 0.7412 - val_loss: 0.5594 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5956 - accuracy: 0.7383 - val_loss: 0.5609 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5853 - accuracy: 0.7412 - val_loss: 0.5601 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.7471 - val_loss: 0.5596 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.7471 - val_loss: 0.5609 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5809 - accuracy: 0.7441 - val_loss: 0.5602 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.7490 - val_loss: 0.5592 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5836 - accuracy: 0.7471 - val_loss: 0.5596 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5729 - accuracy: 0.7461 - val_loss: 0.5594 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5739 - accuracy: 0.7461 - val_loss: 0.5585 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5751 - accuracy: 0.7480 - val_loss: 0.5571 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.7471 - val_loss: 0.5587 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5792 - accuracy: 0.7461 - val_loss: 0.5604 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 4s 15ms/step - loss: 0.6269 - accuracy: 0.6758 - val_loss: 0.5683 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.7393 - val_loss: 0.5666 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5895 - accuracy: 0.7432 - val_loss: 0.5697 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5949 - accuracy: 0.7432 - val_loss: 0.5729 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.7480 - val_loss: 0.5693 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.7471 - val_loss: 0.5674 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7471 - val_loss: 0.5699 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7471 - val_loss: 0.5666 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5731 - accuracy: 0.7471 - val_loss: 0.5690 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5744 - accuracy: 0.7471 - val_loss: 0.5680 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.7471 - val_loss: 0.5667 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.7461 - val_loss: 0.5688 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.7471 - val_loss: 0.5686 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.7471 - val_loss: 0.5687 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7471 - val_loss: 0.5674 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7471 - val_loss: 0.5657 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.7471 - val_loss: 0.5677 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.7471 - val_loss: 0.5677 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.7471 - val_loss: 0.5694 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5748 - accuracy: 0.7471 - val_loss: 0.5657 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 20ms/step - loss: 0.6793 - accuracy: 0.5918 - val_loss: 0.5648 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6074 - accuracy: 0.7217 - val_loss: 0.5618 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.7432 - val_loss: 0.5620 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6007 - accuracy: 0.7432 - val_loss: 0.5631 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5827 - accuracy: 0.7441 - val_loss: 0.5618 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.7461 - val_loss: 0.5617 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.7461 - val_loss: 0.5626 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5804 - accuracy: 0.7471 - val_loss: 0.5625 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5761 - accuracy: 0.7471 - val_loss: 0.5616 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5804 - accuracy: 0.7471 - val_loss: 0.5623 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5874 - accuracy: 0.7471 - val_loss: 0.5647 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5747 - accuracy: 0.7471 - val_loss: 0.5630 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5755 - accuracy: 0.7471 - val_loss: 0.5628 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5746 - accuracy: 0.7471 - val_loss: 0.5613 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5613 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5775 - accuracy: 0.7471 - val_loss: 0.5631 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5713 - accuracy: 0.7471 - val_loss: 0.5628 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5727 - accuracy: 0.7471 - val_loss: 0.5645 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5705 - accuracy: 0.7471 - val_loss: 0.5631 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.7471 - val_loss: 0.5632 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 16ms/step - loss: 0.6606 - accuracy: 0.6348 - val_loss: 0.5645 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.7324 - val_loss: 0.5634 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6072 - accuracy: 0.7363 - val_loss: 0.5644 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.7432 - val_loss: 0.5621 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.7461 - val_loss: 0.5626 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.7480 - val_loss: 0.5640 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.7441 - val_loss: 0.5649 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5821 - accuracy: 0.7471 - val_loss: 0.5631 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5816 - accuracy: 0.7461 - val_loss: 0.5636 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.7471 - val_loss: 0.5622 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.7471 - val_loss: 0.5634 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7471 - val_loss: 0.5637 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.7471 - val_loss: 0.5623 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7471 - val_loss: 0.5653 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5772 - accuracy: 0.7471 - val_loss: 0.5640 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.7471 - val_loss: 0.5639 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5773 - accuracy: 0.7471 - val_loss: 0.5637 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7471 - val_loss: 0.5634 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7471 - val_loss: 0.5629 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7471 - val_loss: 0.5618 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6327 - accuracy: 0.6787 - val_loss: 0.5697 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5930 - accuracy: 0.7383 - val_loss: 0.5678 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.7441 - val_loss: 0.5656 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5949 - accuracy: 0.7373 - val_loss: 0.5667 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7402 - val_loss: 0.5647 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7441 - val_loss: 0.5636 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.7441 - val_loss: 0.5646 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7480 - val_loss: 0.5627 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.7471 - val_loss: 0.5639 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.7480 - val_loss: 0.5624 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7471 - val_loss: 0.5610 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7471 - val_loss: 0.5667 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5734 - accuracy: 0.7471 - val_loss: 0.5619 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7471 - val_loss: 0.5612 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.7471 - val_loss: 0.5596 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7471 - val_loss: 0.5597 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7471 - val_loss: 0.5614 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.7471 - val_loss: 0.5628 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7471 - val_loss: 0.5595 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5667 - accuracy: 0.7471 - val_loss: 0.5600 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7539\n",
            "         frontal    central   parietal  occipital\n",
            "theta  75.390625  75.390625  75.390625  75.390625\n",
            "alpha  75.390625  75.390625  75.390625  75.390625\n",
            "beta   75.390625  75.390625  75.390625  75.390625\n",
            "gamma  75.390625  75.390625  75.390625  75.390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"lstm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVmj0QBE6UC7",
        "outputId": "ef3692f2-9847-458d-8cdc-cbd9af511fed"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6325 - accuracy: 0.6641 - val_loss: 0.5091 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.7617 - val_loss: 0.5078 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.7676 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7695 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7764 - val_loss: 0.5153 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7725 - val_loss: 0.5079 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7764 - val_loss: 0.5134 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7764 - val_loss: 0.5090 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.7754 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5146 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.7764 - val_loss: 0.5128 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7773 - val_loss: 0.5103 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7764 - val_loss: 0.5115 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7754 - val_loss: 0.5176 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7754 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7773 - val_loss: 0.5271 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7754 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7764 - val_loss: 0.5203 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6280 - accuracy: 0.6729 - val_loss: 0.5292 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.7686 - val_loss: 0.5153 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7725 - val_loss: 0.5201 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.7734 - val_loss: 0.5170 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.7754 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7764 - val_loss: 0.5167 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.7744 - val_loss: 0.5170 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7754 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.7764 - val_loss: 0.5166 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7764 - val_loss: 0.5157 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5409 - accuracy: 0.7764 - val_loss: 0.5145 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7764 - val_loss: 0.5167 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7764 - val_loss: 0.5187 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7764 - val_loss: 0.5145 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7764 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7764 - val_loss: 0.5109 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5390 - accuracy: 0.7764 - val_loss: 0.5128 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7764 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7764 - val_loss: 0.5144 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 16ms/step - loss: 0.6022 - accuracy: 0.7119 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.7549 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7666 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.7627 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5638 - accuracy: 0.7646 - val_loss: 0.5176 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7734 - val_loss: 0.5144 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7725 - val_loss: 0.5148 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7754 - val_loss: 0.5162 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7695 - val_loss: 0.5166 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7754 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7754 - val_loss: 0.5184 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7764 - val_loss: 0.5159 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7764 - val_loss: 0.5124 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5390 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7764 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7764 - val_loss: 0.5158 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7764 - val_loss: 0.5161 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7764 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7764 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7764 - val_loss: 0.5162 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6788 - accuracy: 0.5938 - val_loss: 0.5756 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7725 - val_loss: 0.5242 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7744 - val_loss: 0.5214 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7764 - val_loss: 0.5241 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7764 - val_loss: 0.5205 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7764 - val_loss: 0.5205 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7764 - val_loss: 0.5214 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7764 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7764 - val_loss: 0.5171 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7764 - val_loss: 0.5220 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7764 - val_loss: 0.5209 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7764 - val_loss: 0.5159 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7764 - val_loss: 0.5170 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.7764 - val_loss: 0.5147 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7764 - val_loss: 0.5152 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7764 - val_loss: 0.5178 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.7764 - val_loss: 0.5173 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7764 - val_loss: 0.5162 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 16ms/step - loss: 0.7229 - accuracy: 0.5225 - val_loss: 0.5385 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.7627 - val_loss: 0.5079 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.7666 - val_loss: 0.5061 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7764 - val_loss: 0.5041 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.7734 - val_loss: 0.5062 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7734 - val_loss: 0.5055 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7734 - val_loss: 0.5080 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7764 - val_loss: 0.5043 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.7764 - val_loss: 0.5043 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7764 - val_loss: 0.5049 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7764 - val_loss: 0.5051 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7754 - val_loss: 0.5033 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7764 - val_loss: 0.5061 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7764 - val_loss: 0.5082 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5049 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7764 - val_loss: 0.5053 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7764 - val_loss: 0.5050 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7764 - val_loss: 0.5041 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7764 - val_loss: 0.5047 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7764 - val_loss: 0.5035 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 17ms/step - loss: 0.6065 - accuracy: 0.7002 - val_loss: 0.5194 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5972 - accuracy: 0.7441 - val_loss: 0.5180 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5753 - accuracy: 0.7646 - val_loss: 0.5214 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.7627 - val_loss: 0.5187 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7646 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7744 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.7695 - val_loss: 0.5216 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7764 - val_loss: 0.5232 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5526 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5495 - accuracy: 0.7764 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7754 - val_loss: 0.5257 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7764 - val_loss: 0.5202 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7764 - val_loss: 0.5215 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7764 - val_loss: 0.5211 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7764 - val_loss: 0.5211 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7764 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7764 - val_loss: 0.5196 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7764 - val_loss: 0.5184 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7764 - val_loss: 0.5194 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.5833 - accuracy: 0.7490 - val_loss: 0.5209 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.7617 - val_loss: 0.5260 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7617 - val_loss: 0.5187 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7666 - val_loss: 0.5218 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7754 - val_loss: 0.5252 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.7725 - val_loss: 0.5288 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7773 - val_loss: 0.5260 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7754 - val_loss: 0.5208 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.7764 - val_loss: 0.5220 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7754 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7754 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5345 - accuracy: 0.7764 - val_loss: 0.5195 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7754 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7764 - val_loss: 0.5215 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7764 - val_loss: 0.5209 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7764 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7764 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.7764 - val_loss: 0.5266 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7764 - val_loss: 0.5265 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6519 - accuracy: 0.6279 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.7695 - val_loss: 0.5199 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7725 - val_loss: 0.5257 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5673 - accuracy: 0.7725 - val_loss: 0.5283 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7764 - val_loss: 0.5264 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.7764 - val_loss: 0.5272 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7764 - val_loss: 0.5267 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7764 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7764 - val_loss: 0.5265 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7764 - val_loss: 0.5310 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.7764 - val_loss: 0.5308 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7764 - val_loss: 0.5317 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5268 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5281 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7764 - val_loss: 0.5311 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5373 - accuracy: 0.7764 - val_loss: 0.5302 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7764 - val_loss: 0.5300 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7764 - val_loss: 0.5269 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5405 - accuracy: 0.7764 - val_loss: 0.5265 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6321 - accuracy: 0.7178 - val_loss: 0.5215 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.7627 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.7627 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7705 - val_loss: 0.5238 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7764 - val_loss: 0.5200 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.7744 - val_loss: 0.5242 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7734 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5539 - accuracy: 0.7754 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7754 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7754 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7773 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.7764 - val_loss: 0.5196 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.7764 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7764 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7764 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7764 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7764 - val_loss: 0.5127 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5072 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7764 - val_loss: 0.5051 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7764 - val_loss: 0.5085 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 16ms/step - loss: 0.7137 - accuracy: 0.5742 - val_loss: 0.5108 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5859 - accuracy: 0.7500 - val_loss: 0.5105 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5829 - accuracy: 0.7666 - val_loss: 0.5127 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5741 - accuracy: 0.7559 - val_loss: 0.5143 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7666 - val_loss: 0.5134 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.7695 - val_loss: 0.5158 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.7764 - val_loss: 0.5204 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.7764 - val_loss: 0.5184 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7754 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7754 - val_loss: 0.5174 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7764 - val_loss: 0.5179 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7764 - val_loss: 0.5156 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7764 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7754 - val_loss: 0.5170 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.7764 - val_loss: 0.5196 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7764 - val_loss: 0.5176 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7764 - val_loss: 0.5185 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5361 - accuracy: 0.7764 - val_loss: 0.5174 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5311 - accuracy: 0.7764 - val_loss: 0.5158 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5386 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 16ms/step - loss: 0.6033 - accuracy: 0.6963 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7734 - val_loss: 0.5204 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7666 - val_loss: 0.5266 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7725 - val_loss: 0.5237 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7744 - val_loss: 0.5290 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.7773 - val_loss: 0.5286 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7754 - val_loss: 0.5289 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7754 - val_loss: 0.5285 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7764 - val_loss: 0.5281 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.7764 - val_loss: 0.5300 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7783 - val_loss: 0.5254 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7764 - val_loss: 0.5304 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7764 - val_loss: 0.5279 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.7764 - val_loss: 0.5259 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7764 - val_loss: 0.5266 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5345 - accuracy: 0.7764 - val_loss: 0.5269 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7764 - val_loss: 0.5247 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7764 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7764 - val_loss: 0.5286 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7764 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 14ms/step - loss: 0.7365 - accuracy: 0.5635 - val_loss: 0.5127 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.7412 - val_loss: 0.5112 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5853 - accuracy: 0.7383 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5762 - accuracy: 0.7588 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5638 - accuracy: 0.7559 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.7646 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5653 - accuracy: 0.7676 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5548 - accuracy: 0.7666 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5537 - accuracy: 0.7725 - val_loss: 0.5213 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7744 - val_loss: 0.5223 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.7754 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7744 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7744 - val_loss: 0.5234 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7734 - val_loss: 0.5313 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5515 - accuracy: 0.7754 - val_loss: 0.5247 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5497 - accuracy: 0.7764 - val_loss: 0.5304 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7764 - val_loss: 0.5301 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7754 - val_loss: 0.5311 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5437 - accuracy: 0.7764 - val_loss: 0.5276 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7764 - val_loss: 0.5258 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6429 - accuracy: 0.6699 - val_loss: 0.5246 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7695 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.7646 - val_loss: 0.5157 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.7744 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7764 - val_loss: 0.5130 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7754 - val_loss: 0.5115 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7734 - val_loss: 0.5085 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7734 - val_loss: 0.5046 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7734 - val_loss: 0.5052 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7773 - val_loss: 0.5031 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7764 - val_loss: 0.5071 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7764 - val_loss: 0.5068 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7744 - val_loss: 0.5074 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7754 - val_loss: 0.5064 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7744 - val_loss: 0.5061 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7764 - val_loss: 0.5051 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7764 - val_loss: 0.5058 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7764 - val_loss: 0.5045 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7764 - val_loss: 0.5041 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7764 - val_loss: 0.5030 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 16ms/step - loss: 0.6182 - accuracy: 0.6719 - val_loss: 0.5218 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5706 - accuracy: 0.7705 - val_loss: 0.5189 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.7695 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.7764 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.7715 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7754 - val_loss: 0.5157 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7764 - val_loss: 0.5166 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5458 - accuracy: 0.7754 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.7764 - val_loss: 0.5170 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7725 - val_loss: 0.5162 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7764 - val_loss: 0.5157 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5385 - accuracy: 0.7773 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5159 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5407 - accuracy: 0.7764 - val_loss: 0.5172 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7754 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5325 - accuracy: 0.7764 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5357 - accuracy: 0.7764 - val_loss: 0.5173 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5292 - accuracy: 0.7764 - val_loss: 0.5157 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7764 - val_loss: 0.5176 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 4s 17ms/step - loss: 0.6321 - accuracy: 0.6748 - val_loss: 0.5247 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7715 - val_loss: 0.5269 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5565 - accuracy: 0.7676 - val_loss: 0.5229 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.7695 - val_loss: 0.5290 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.7734 - val_loss: 0.5257 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7754 - val_loss: 0.5268 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7764 - val_loss: 0.5276 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5489 - accuracy: 0.7764 - val_loss: 0.5263 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.7744 - val_loss: 0.5282 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7754 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7764 - val_loss: 0.5254 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7764 - val_loss: 0.5252 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7764 - val_loss: 0.5267 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7764 - val_loss: 0.5200 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7764 - val_loss: 0.5240 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.7764 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7764 - val_loss: 0.5265 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7764 - val_loss: 0.5213 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7930\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.7130 - accuracy: 0.5869 - val_loss: 0.5347 - val_accuracy: 0.7930\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.7715 - val_loss: 0.5237 - val_accuracy: 0.7930\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5878 - accuracy: 0.7529 - val_loss: 0.5252 - val_accuracy: 0.7930\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7617 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.7715 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.7725 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7744 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7744 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7715 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.7734 - val_loss: 0.5218 - val_accuracy: 0.7930\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7734 - val_loss: 0.5238 - val_accuracy: 0.7930\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7754 - val_loss: 0.5215 - val_accuracy: 0.7930\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7754 - val_loss: 0.5240 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7754 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7764 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7764 - val_loss: 0.5240 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5455 - accuracy: 0.7764 - val_loss: 0.5244 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7764 - val_loss: 0.5235 - val_accuracy: 0.7930\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.7764 - val_loss: 0.5203 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7930\n",
            "         frontal    central   parietal  occipital\n",
            "theta  79.296875  79.296875  79.296875  79.296875\n",
            "alpha  79.296875  79.296875  79.296875  79.296875\n",
            "beta   79.296875  79.296875  79.296875  79.296875\n",
            "gamma  79.296875  79.296875  79.296875  79.296875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"lstm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOm0SD0q6Vkf",
        "outputId": "e6373e04-1e00-44d4-f9d2-5e9335a40c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.7305 - accuracy: 0.5986 - val_loss: 0.5570 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6632 - accuracy: 0.6914 - val_loss: 0.5536 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.7256 - val_loss: 0.5552 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.7324 - val_loss: 0.5538 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.7363 - val_loss: 0.5568 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.7305 - val_loss: 0.5601 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.7451 - val_loss: 0.5579 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5858 - accuracy: 0.7480 - val_loss: 0.5627 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.7480 - val_loss: 0.5603 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7490 - val_loss: 0.5571 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.7471 - val_loss: 0.5681 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.7480 - val_loss: 0.5669 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7500 - val_loss: 0.5676 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7510 - val_loss: 0.5669 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7510 - val_loss: 0.5665 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.7510 - val_loss: 0.5744 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7510 - val_loss: 0.5639 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5659 - accuracy: 0.7510 - val_loss: 0.5634 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.7510 - val_loss: 0.5638 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7510 - val_loss: 0.5641 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 22ms/step - loss: 0.6977 - accuracy: 0.6035 - val_loss: 0.5570 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6248 - accuracy: 0.7246 - val_loss: 0.5559 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5944 - accuracy: 0.7295 - val_loss: 0.5636 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6035 - accuracy: 0.7275 - val_loss: 0.5633 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5857 - accuracy: 0.7500 - val_loss: 0.5653 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.7490 - val_loss: 0.5620 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5805 - accuracy: 0.7471 - val_loss: 0.5703 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.7480 - val_loss: 0.5713 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.7500 - val_loss: 0.5718 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.7520 - val_loss: 0.5682 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7510 - val_loss: 0.5679 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7500 - val_loss: 0.5714 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.7510 - val_loss: 0.5714 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.7510 - val_loss: 0.5719 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.7500 - val_loss: 0.5780 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7510 - val_loss: 0.5759 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.7510 - val_loss: 0.5747 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5754 - accuracy: 0.7510 - val_loss: 0.5762 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7510 - val_loss: 0.5727 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5715 - accuracy: 0.7510 - val_loss: 0.5721 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7539\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.6363 - accuracy: 0.6680 - val_loss: 0.5613 - val_accuracy: 0.7539\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.7354 - val_loss: 0.5640 - val_accuracy: 0.7539\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.7314 - val_loss: 0.5658 - val_accuracy: 0.7539\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.7412 - val_loss: 0.5646 - val_accuracy: 0.7539\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.7451 - val_loss: 0.5670 - val_accuracy: 0.7539\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5934 - accuracy: 0.7490 - val_loss: 0.5709 - val_accuracy: 0.7539\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.7520 - val_loss: 0.5682 - val_accuracy: 0.7539\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7510 - val_loss: 0.5697 - val_accuracy: 0.7539\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7490 - val_loss: 0.5675 - val_accuracy: 0.7539\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7510 - val_loss: 0.5668 - val_accuracy: 0.7539\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.7510 - val_loss: 0.5666 - val_accuracy: 0.7539\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7510 - val_loss: 0.5683 - val_accuracy: 0.7539\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5720 - accuracy: 0.7500 - val_loss: 0.5698 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7510 - val_loss: 0.5652 - val_accuracy: 0.7539\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7510 - val_loss: 0.5713 - val_accuracy: 0.7539\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.7510 - val_loss: 0.5701 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.7510 - val_loss: 0.5723 - val_accuracy: 0.7539\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.7510 - val_loss: 0.5657 - val_accuracy: 0.7539\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7510 - val_loss: 0.5653 - val_accuracy: 0.7539\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.7510 - val_loss: 0.5670 - val_accuracy: 0.7539\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7539\n",
            "Epoch 1/20\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}